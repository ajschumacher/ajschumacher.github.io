# Asimov's Three Laws of Robotics


1. A robot may not injure a human being or, through inaction, allow a
   human being to come to harm.
2. A robot must obey the orders given it by human beings except where
   such orders would conflict with the First Law.
3. A robot must protect its own existence as long as such protection
   does not conflict with the First or Second Law.


I was reminded of the [Three Laws][] while looking at Scout Laws.
They're not so different, in many ways, from a lot of these codes.
Apparently Asimov was explicit in thinking that humans should follow
the Three Laws as well.

[Three Laws]: https://en.wikipedia.org/wiki/Three_Laws_of_Robotics
