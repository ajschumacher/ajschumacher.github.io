<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/styles/csshake.min.css">
    <link rel="stylesheet" type="text/css" href="/styles/zenburn.css">
    <link rel="stylesheet" type="text/css" href="/styles/planspace.css">
    <script defer data-domain="planspace.org" src="https://plausible.io/js/script.js"></script>
    <title>Hearing Data with Sonic Histograms</title>
  </head>
  <body>
    <article>
<h1>Hearing Data with Sonic Histograms</h1>
<p class="date">Monday December 14, 2015</p>
<p>You can see an iris, and you can smell an iris, and you can measure the <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">length and width of 150 iris sepals and petals</a>... but can you <em>hear</em> the iris data?</p>
<p><audio controls preload="auto" autobuffer>
    <source src="yes.mp3" type="audio/mpeg" />
    <source src="yes.ogg" type="audio/ogg" />
</audio></p>
<p><a href="https://en.wikipedia.org/wiki/Iris_flower_data_set"><img alt="iris" src="iris.jpg" /></a></p>
<p><a href="https://en.wikipedia.org/wiki/Histogram">Histograms</a> are a great way to get a sense for the distribution of a set of values. The view you get depends on how wide your bars are.</p>
<p><img alt="two histograms" src="two_histograms.png" /></p>
<p>Both those histograms look pretty good, but audio isn't so boxy. A cousin of the histogram, <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density estimation</a> (KDE) seems more like audio. Like a histogram, it can be more or less "smooth".</p>
<p><img alt="two KDEs" src="two_kdes.png" /></p>
<p>Stealing the idea of KDE, we can adapt it for audio. We'll just add up audio pulses that are positioned in time to represent values.</p>
<p>We can use "wide" audio points <audio controls preload="auto" autobuffer><source src="sonic_point_wide.mp3" type="audio/mpeg" /><source src="sonic_point_wide.ogg" type="audio/ogg" /></audio> or "narrow" audio points <audio controls preload="auto" autobuffer><source src="sonic_point_narrow.mp3" type="audio/mpeg" /><source src="sonic_point_narrow.ogg" type="audio/ogg" /></audio>.</p>
<p>Combining a bunch of wide audio points, we get a "smoother" audio histogram. <audio controls preload="auto" autobuffer><source src="sonic_sepal_length_wide.mp3" type="audio/mpeg" /><source src="sonic_sepal_length_wide.ogg" type="audio/ogg" /></audio> And if we combine narrow audio points, we get a more "discrete" sounding histogram. <audio controls preload="auto" autobuffer><source src="sonic_sepal_length_narrow.mp3" type="audio/mpeg" /><source src="sonic_sepal_length_narrow.ogg" type="audio/ogg" /></audio></p>
<p>Adding an audio axis label and some sonic tick marks, we get serviceable audio histograms that you can compare to their visible counterparts.</p>
<p><audio controls preload="auto" autobuffer><source src="sonic_sepal_length.mp3" type="audio/mpeg" /><source src="sonic_sepal_length.ogg" type="audio/ogg" /></audio> <img alt="sepal length histogram" src="sepal_length.png" /></p>
<p><audio controls preload="auto" autobuffer><source src="sonic_sepal_width.mp3" type="audio/mpeg" /><source src="sonic_sepal_width.ogg" type="audio/ogg" /></audio> <img alt="sepal width histogram" src="sepal_width.png" /></p>
<p><audio controls preload="auto" autobuffer><source src="sonic_petal_length.mp3" type="audio/mpeg" /><source src="sonic_petal_length.ogg" type="audio/ogg" /></audio> <img alt="petal length histogram" src="petal_length.png" /></p>
<p><audio controls preload="auto" autobuffer><source src="sonic_petal_width.mp3" type="audio/mpeg" /><source src="sonic_petal_width.ogg" type="audio/ogg" /></audio> <img alt="petal width histogram" src="petal_width.png" /></p>
<p>So yes, it kind of works! You can certainly hear bimodality, and even differentiate between the first two distributions if you listen carefully. I probably won't switch from visualizations to sonifications, but it's a fun things to explore!</p>
<hr />
<p>Thanks to <a href="https://www.spotify.com/">Spotify</a>'s <a href="http://monthlymusichackathon.org/">Monthly Music Hackathon NYC</a> (<a href="https://twitter.com/musichackathon">@musichackathon</a>) <a href="http://monthlymusichackathon.org/post/133438271112/viz-son">Sound Visualization &amp; Data Sonification Hackathon</a> for providing the push to do this. There's <a href="http://livestream.com/accounts/5176069/events/4582831">video on Livestream</a> (I'm on from about 5:30 to 10:30) but ironically the audio doesn't seem to be working. Thanks also to <a href="https://thomaslevine.com/">Thomas Levine</a> for showing me the <a href="https://cran.r-project.org/web/packages/tuneR/index.html">tuneR</a> library for <a href="https://www.r-project.org/">R</a> which let me jump in and start making sounds really quickly.</p>
<hr />
<p>This code was hacked together quickly and is not what you'd call "production grade". It uses the Mac <code>say</code> and also <code>ffmpeg</code> via <code>system</code>, but it's otherwise <a href="play.R">R that might work for you</a> if you want to try it.</p>
<pre><code class="language-r"># install.packages("tuneR")  # install if not installed
library("tuneR")
setWavPlayer('/usr/bin/afplay')  # on Mac


point_at &lt;- function(value,  # data value
                     lowest,  # data range min
                     highest,  # data range max
                     duration,  # seconds
                     point_width,  # seconds for +/- 3 SD (points are normal)
                     point_freq=440, sample_rate=44100) {
  point_width_samples &lt;- point_width * sample_rate
  point &lt;- sine(point_freq, point_width_samples, stereo=TRUE)
  filter &lt;- dnorm(seq_along(point), mean = length(point)/2, sd = length(point)/6)
  filter &lt;- filter / max(filter)
  point &lt;- point * filter
  duration &lt;- duration * sample_rate
  data_range &lt;- highest - lowest
  left_offset &lt;- value - lowest
  peak_position &lt;- (left_offset / data_range) * duration
  left_padding_duration &lt;- peak_position - length(point)/2
  if (left_padding_duration > 0) {
    result &lt;- bind(silence(left_padding_duration, stereo=TRUE), point)
  } else {
    result &lt;- point[abs(left_padding_duration):length(point)]
  }
  if (length(result) &lt; duration) {
    result &lt;- bind(result, silence(duration - length(result), stereo=TRUE))
  } else {
    result &lt;- result[1:duration]
  }
  result
}

points_at &lt;- function(values,  # data values
                      lowest,  # data range min
                      highest,  # data range max
                      duration,  # seconds
                      point_width,  # seconds for +/- 3 SD (points are normal)
                      point_freq=440, sample_rate=44100) {
  result &lt;- silence(duration * sample_rate, stereo = TRUE)
  for (value in values) {
    result &lt;- result + point_at(value, lowest, highest, duration, point_width,
                                point_freq, sample_rate)
  }
  result
}

low_high &lt;- function(values) {
  breakpoints &lt;- pretty(values)
  lowest &lt;- breakpoints[1]
  highest &lt;- breakpoints[length(breakpoints)]
  c(lowest, highest)
}

normalized_sonic_hist_content &lt;- function(values,  # data values
                                          duration=4,  # seconds
                                          point_width=0.2,  # seconds for +/1 3 SD (points are normal)
                                          point_freq=440, sample_rate=44100) {
  breakpoints &lt;- low_high(values)
  lowest &lt;- breakpoints[1]
  highest &lt;- breakpoints[2]
  content &lt;- points_at(values, lowest, highest, duration, point_width,
                       point_freq, sample_rate)
  normalize(content)
}

sonic_hist &lt;- function(values,  # data values
                       main,  # "title" of variable
                       duration=4,  # seconds
                       point_width=0.2,  # seconds for +/1 3 SD (points are normal)
                       point_freq=440,
                       legend=TRUE,
                       units="",
                       edge=TRUE, edge_freq=880, edge_duration=1000,
                       sample_rate=44100) {
  if (missing(main)) {
    main &lt;- deparse(substitute(values))
  }
  breakpoints &lt;- low_high(values)
  lowest &lt;- breakpoints[1]
  highest &lt;- breakpoints[2]
  content &lt;- normalized_sonic_hist_content(values, duration, point_width, point_freq, sample_rate)
  edge_sound &lt;- sine(edge_freq, duration=edge_duration, stereo=TRUE)
  if (edge) {
    content &lt;- bind(edge_sound, content, edge_sound)
  }
  if (legend) {
    system(paste("say", main, "in", duration, "seconds from", lowest, "to", highest, units, "-o t"))
    system("ffmpeg -i t.aiff -ar 44100 t.wav")
    legend_mono &lt;- normalize(readWave("t.wav"), pcm=FALSE)
    legend_stereo &lt;- stereo(legend_mono, legend_mono)
    system("rm t.aiff t.wav")
    content &lt;- bind(legend_stereo, content)
  }
  content
}

triple_save &lt;- function(some_wav) {
  name_prefix &lt;- deparse(substitute(some_wav))
  wav_name &lt;- paste(name_prefix, ".wav", sep='')
  mp3_name &lt;- paste(name_prefix, ".mp3", sep='')
  ogg_name &lt;- paste(name_prefix, ".ogg", sep='')
  writeWave(some_wav, wav_name)
  system(paste("ffmpeg -i", wav_name, mp3_name))
  system(paste("ffmpeg -i", wav_name, ogg_name))
  system(paste("rm", wav_name))
}

data("iris")

iris$Sepal.Length


png('two_histograms.png', width=800, height=380)
par(mfrow=c(1, 2))
hist(iris$Sepal.Length, main="sepal length histogram, default breaks")
hist(iris$Sepal.Length, breaks=100, xlim=c(4, 8), main="sepal length histogram, 100 breaks")
dev.off()

png('two_kdes.png', width=800, height=380)
par(mfrow=c(1, 2))
plot(density(iris$Sepal.Length), main="sepal length kernel density, default binwidth")
plot(density(iris$Sepal.Length, bw=0.01), main="sepal length kernel density, 0.01 binwidth")
dev.off()

sonic_point_wide &lt;- point_at(value=4, lowest=0, highest=8, duration=2, point_width=0.5)
triple_save(sonic_point_wide)
sonic_point_narrow &lt;- point_at(value=4, lowest=0, highest=8, duration=2, point_width=0.05)
triple_save(sonic_point_narrow)

sonic_sepal_length_wide &lt;- sonic_hist(iris$Sepal.Width, legend=F, edge=F, point_width=0.4)
triple_save(sonic_sepal_length_wide)
sonic_sepal_length_narrow &lt;- sonic_hist(iris$Sepal.Width, point_width=0.05, legend=F, edge=F)
triple_save(sonic_sepal_length_narrow)

sonic_tick_mark &lt;- sine(880, duration=1000, stereo=TRUE)
triple_save(sonic_tick_mark)

png("sepal_length.png", height=380, width=480)
hist(iris$Sepal.Length, main="sepal length, centimeters")
dev.off()
sonic_sepal_length &lt;- sonic_hist(iris$Sepal.Length, main="sepal length", units="centimeters")
triple_save(sonic_sepal_length)

png("sepal_width.png", height=380, width=480)
hist(iris$Sepal.Width, main="sepal width, centimeters")
dev.off()
sonic_sepal_width &lt;- sonic_hist(iris$Sepal.Width, main="sepal width", units="centimeters")
triple_save(sonic_sepal_width)

png("petal_length.png", height=380, width=480)
hist(iris$Petal.Length, main="petal length, centimeters")
dev.off()
sonic_petal_length &lt;- sonic_hist(iris$Petal.Length, main="petal length", units="centimeters")
triple_save(sonic_petal_length)

png("petal_width.png", height=380, width=480)
hist(iris$Petal.Width, main="petal width, centimeters")
dev.off()
sonic_petal_width &lt;- sonic_hist(iris$Petal.Width, main="petal width", units="centimeters")
triple_save(sonic_petal_width)</code></pre>

<hr />
<p>If you're having any problems with your sonic histograms, you can adjust them with a <a href="https://en.wikipedia.org/wiki/Sonic_screwdriver">sonic screwdriver</a>.</p>
<p><img alt="sonic screwdriver" src="sonic_screwdriver.png" /></p>    </article>
    <footer>
      <hr />
<p><a name="contact"></a><form class="email_updates">
  <input type="email" name="email" placeholder="your@email.address" style="width: 49%" />
  <input type="submit" value="Get monthly updates" style="width: 49%" />
  <input type="hidden" name="_subject" value="planspace.org updates list" />
  <input type="text" name="_honey" style="display:none" />
  <input type="hidden" name="_captcha" value="false" />
</form></p>
<p><a id="back_link2" href="/">This site</a> also has <a href="/rss.xml">RSS</a>. You can connect with <a id="aaron_link2" href="/aaron/">me</a> via <a href="https://twitter.com/planarrowspace">Twitter</a>, <a href="https://www.linkedin.com/in/ajschumacher">LinkedIn</a>, <a href="https://github.com/ajschumacher">GitHub</a>, and <a href="mailto:aaron@planspace.org">email</a>.</p>

      <hr />
    </footer>

<!-- my weird stuff -->
<script src="/scripts/planspace.js"></script>

<!-- syntax highlighting -->
<script src="/scripts/highlight.pack.js"></script>
<script type="text/javascript">hljs.initHighlightingOnLoad();</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-44351009-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Disqus comments -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'planspace';
  (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  </body>
</html>
