<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>plan ➔ space</title>
    <link>http://planspace.org/</link>
    <description>plan space from outer nine</description>
    <language>en-us</language>
    <atom:link href="http://planspace.org/rss.xml" rel="self" type="application/rss+xml" />
<item>
<title>The flow metaphor for matrix multiplication</title>
<description><![CDATA[

<blockquote>
<p><em>“I cannot believe that anything so ugly as multiplication of
matrices is an essential part of the scheme of nature.” (Arthur
Eddington, 1936)</em></p>
</blockquote>
<p>Even <a href="https://smile.amazon.com/Linear-Algebra-Its-Applications-4th/dp/0030105676/">Strang</a> introduces matrix multiplication by saying “there is
only one possible rule, and I am not sure who discovered it. It makes
everything work.” This is not satisfying or helpful for understanding.
The flow metaphor of graphical linear algebra makes matrix
multiplication seem natural and helps provide intuition for
understanding linear algebra.</p>
<ul>
<li><a href="#diagram">A simple diagram style</a></li>
<li><a href="#mult">Matrix multiplication</a></li>
<li><a href="#directions">Aligning directions</a></li>
<li><a href="#sources">Sources</a></li>
</ul>
<hr>
<h3><a name="diagram" href="#diagram">A simple diagram style</a></h3>
<p>The inputs <em>x</em> and <em>y</em> pass from left to right along the arrow
paths—getting multiplied by <em>a</em>, <em>b</em>, <em>c</em>, and <em>d</em>, respectively—and
then adding up to outputs <em>i</em> and <em>j</em>.</p>
<p><img alt="vector - matrix multiplication" src="vec_mat_mult.png"></p>
<p>The diagram is equivalent to the usual notation for a simple
vector-matrix multiplication.</p>
<p>\[ \begin{bmatrix} i \\ j \end{bmatrix} =
    \begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}
    \begin{bmatrix} x \\ y \end{bmatrix} =
    \begin{bmatrix} ax+by \\ cx+dy \end{bmatrix} \]</p>
<p>You can visualize inputs entering at the top and outputs going out the
side. For example, the <em>x</em> enters the 2-by-2 matrix over the <em>a</em>, and
then exits to the left to contribute <em>ax</em> to <em>i</em>. The <em>y</em> enters over
the <em>b</em> and exits to the left to contribute <em>by</em> to <em>i</em>.</p>
<hr>
<h3><a name="mult" href="#mult">Matrix multiplication</a></h3>
<p>To compose two matrix diagrams, follow the paths from inputs to
outputs. For example, to go from <em>x</em> to <em>u</em>, there's the <em>ae</em> path
that goes via <em>i</em>, and there's the <em>cf</em> path that goes via <em>j</em>, so the
simplified single path from <em>x</em> to <em>u</em> is <em>ae + cf</em>.</p>
<p><img alt="matrix - matrix multiplication" src="mat_mat_mult.png"></p>
<p>This is matrix multiplication that makes sense. After the input-output
behavior <a href="#diagram">above</a> is established, there's no other way for matrix
multiplication to come out.</p>
<p>\[ \begin{bmatrix} e &amp; f \\ g &amp; h \end{bmatrix}
    \begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix} =
    \begin{bmatrix} ae+cf &amp; be+df \\ ag+ch &amp; bg+dh \end{bmatrix} \]</p>
<p>Why do the inner dimensions need to be the same for two matrices
you're multiplying? Because you have to match up outputs from one with
inputs for the other.</p>
<p>I find this <a href="https://en.wikipedia.org/wiki/Where_Mathematics_Comes_From" title="Where Mathematics Comes From: How the Embodied Mind Brings Mathematics into Being">metaphor</a> really helpful, and I suspect it could help
people learning linear algebra for the first time as well. I think it
can be complementary with thinking about (and <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab" title="Essence of linear algebra, from 3Blue1Brown">visualizing</a>) vector
spaces. Exposition might proceed from introducing the idea of linear
combinations, to the diagram form, to the matrix notation, for
example.</p>
<hr>
<h3><a name="directions" href="#directions">Aligning directions</a></h3>
<p>I think it's a good thing that the diagrams make it obvious that order
matters. I'd rather have both the diagrams and matrix notation read
naturally from left to right, but I don't think everybody will change
how they write their linear algebra.</p>
<p>There's nothing special about the usual orientation. Both directions
are “on” by default. You can multiply a row vector and matrix, which
is like going right to left along the diagram for the matrix. You can
see the result isn't equivalent unless you transpose.</p>
<p>Transpose is the operation that swaps inputs with outputs For example,
\( (A B)^T = B^T A^T \). Visualize rotating two connected pieces of
pipe.</p>
<p>For a given order, sometimes it feels more natural to think about
going left to right rather than right to left. For example, in the \(
y = X \beta \) of linear regression, it feels better to me to think
of moving a row of the data matrix \( X \) through the coefficient
transformation \( \beta \), rather than thinking of the data \( X
\) as transforming the coefficients. Either way.</p>
<p>Note also that a column vector is not the same as a row vector, and
neither are the same as a vector. We probably shouldn't say a vector
<em>is</em> any particular matrix.</p>
<hr>
<h3><a name="sources" href="#sources">Sources</a></h3>
<p>I started thinking about this based on §3.2.2.4 in Spivak's <em>Category
Theory for the Sciences</em>. A complete, rigorous formulation as
Graphical Linear Algebra is nicely introduced in
<a href="https://graphicallinearalgebra.net/">Sobocinski's blog</a>. The best brief introduction I've seen is in a
<a href="https://www.youtube.com/watch?v=ptWK8ehQvyw&amp;t=3379s">presentation from Paixão</a>. (Thanks to Spivak and Sobocinski for
helpful pointers over email as well!)</p>
<p>The quote at top from <a href="https://en.wikipedia.org/wiki/Arthur_Eddington">Sir Eddington</a> about the ugliness of matrix
multiplication is from page 36 of his <em>Relativity Theory of Electrons
and Protons</em>, published in 1936 by Cambridge University Press, as
quoted in Macedo and Oliveira's <a href="https://arxiv.org/abs/1312.4818">Typing linear algebra</a>.</p>
<blockquote>
<p>“So the way we normally teach linear algebra to students is we write
down the formula for multiplying a matrix. Where does this formula
come from? I mean everyone learns it in first year, right, so we
don't question it, but it's actually very difficult to explain. I
mean I have to teach linear algebra to first-year students and, you
know, it takes them quite a bit of time to get it. And they learn
it, they get it by memorizing, you know, these kinds of algorithms
in their heads, but this is not the way we should teach maths. We
shouldn't teach maths, you know, by telling people to memorize
algorithms.” (<a href="https://www.youtube.com/watch?v=yHUp23AyF2A">Sobocinski</a>)</p>
</blockquote>
<!-- mathjax for formulas -->

    ]]></description>
<link>http://planspace.org/20210915-flow_metaphor_for_matrix_multiplication/</link>
<guid>http://planspace.org/20210915-flow_metaphor_for_matrix_multiplication/</guid>
<pubDate>Wed, 15 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Didau's 2019 book: Plagiarism and one main bad idea</title>
<description><![CDATA[

<p>Former English teacher David Didau seems to have <a href="#plagiarism">plagiarised</a>
Wikipedia in his book called <em>Making kids cleverer</em>. At least it's
less into eugenics than his <a href="/20210914-david_didaus_2015_book_endorses_eugenics/" title="David Didau's 2015 book endorses eugenics">older book</a>. The main bad idea is a
central desire to shape curriculum so as to perpetuate existing
systems of power.</p>
<p>Didau's titular thesis is that the goal of schools is to make kids
cleverer, in the sense of <a href="https://en.wikipedia.org/wiki/Fluid_and_crystallized_intelligence">crystallized intelligence</a>, by teaching
knowledge, broadly construed. When it comes time to discuss <em>which</em>
knowledge, he pivots from arguing in support of cleverness to arguing
in support of dead white men on the grounds that this knowledge is
culturally valued—implicitly, valued by the culture he values.</p>
<p>I think it's <a href="https://www.theatlantic.com/politics/archive/2015/07/what-every-american-should-know/397334/">possible</a> to make an argument for some shared
knowledge, in the tradition of <a href="https://en.wikipedia.org/wiki/E._D._Hirsch">Hirsch</a>, but I think it's a
different argument than arguing for knowledge that best helps students
think more effectively in the sense of moving toward a global maximum.
Similarly, the <a href="https://en.wikipedia.org/wiki/Lindy_effect">Lindy effect</a> is about longevity, but not
necessarily quality. I think it would be much more interesting to look
at curriculum design by taking seriously the idea of giving students
the best mental toolkit possible. This is not what Didau does.</p>
<p>Didau discusses the <a href="https://en.wikipedia.org/wiki/Flynn_effect">Flynn effect</a>, and subscribes to the
"scientific spectacles" interpretation that general skills with
scientific abstraction explain increases in average IQ over time, but
at the same time argues one-sidedly for teaching concrete knowledge,
not general skills.</p>
<p>I do think that students can and probably should learn and remember
much more, generally, than they sometimes do, but Didau is a
problematic advocate, and I don't think his obsession with IQ is
useful.</p>
<p><img alt="cover" src="cleverer_cover.jpg"></p>
<hr>
<p>While this is always the case, I feel like it's especially important
with a book like this for me to point out that selected quotes below
do not indicate my agreement with or support for any particular quote.</p>
<hr>
<blockquote>
<p>"Over the course of this book, I will explain that, unlike many
other qualities we might value, intelligence has the advantages of
being malleable, measurable and meaningful." (page 7)</p>
</blockquote>
<hr>
<blockquote>
<p>"By 'making cleverer' what I really mean, of course, is raising
intelligence—increasing children's intellectual capacity." (page 7)</p>
</blockquote>
<hr>
<blockquote>
<p>"Arthur Scargill, tub-thumping leader of the National Union of
Mineworkers, who led the opposition to Margaret Thatcher's struggle
to break the power of the trade unions, wrote, "My father still
reads the dictionary every day. He says your life depends on your
power to master words."" (page 9)</p>
</blockquote>
<hr>
<blockquote>
<p>"Trying to develop children's ability by teaching generic skills
directly is fundamentally unfair. Children with higher fluid
intelligence and those from more advantaged backgrounds will be
further privileged." (page 11)</p>
</blockquote>
<hr>
<blockquote>
<p>"This is the central thesis of the book: more knowledge equals more
intelligence." (page 11)</p>
</blockquote>
<hr>
<blockquote>
<p>"It's my view that '21st century skills' depend on knowing things
rather than on simply being able to look stuff up on the internet."
(page 12)</p>
</blockquote>
<hr>
<blockquote>
<p>"Developing children's character depends ont on attempting to
explicitly teach some ephemeral set of 'non-cognitive' skills but on
a combination of high expectations, accountability and modeling. As
Kalenze suggests, probably the best way to teach resilience is to
give children challenging work to do; the best way to teach respect
and politeness is to model it; and the best way to teach children
how to be functional, happy citizens is to set up systems which hold
them to account for their behaviour." (page 25)</p>
</blockquote>
<hr>
<blockquote>
<p>"[Kevin] Laland points out that "Humanity's success is sometimes
attributed to our cleverness, but culture is actually what makes us
smart. Intelligence is not irrelevant of course, but what singles
out our species is an ability to pool our insights and knowledge and
build on each other's solutions."" (page 43)</p>
</blockquote>
<hr>
<blockquote>
<p>"Some children may be born with a greater capacity for solving
problems and thinking critically than others. These children are
lucky. At the same time, some children will possess more (and more
useful) knowledge of the world on which to apply these skills. These
children will tend to be from more privileged backgrounds. What
happens in school matters far less to both these groups of children
than it does to the less fortunate and the less advantaged. The
killer argument against a curriculum that focuses on 21st century
skills—or any other kind of generic competencies—is that it is
inherently iniquitous." (page 45)</p>
</blockquote>
<hr>
<blockquote>
<p>"The purpose of schools, as much as anything else, is to provide an
environment where children are made to attend to what they would
otherwise prefer to avoid." (page 53)</p>
</blockquote>
<hr>
<blockquote>
<p>"... the position I will advance in this book is that intelligence
is as much a product of what we know as it is a mechanism for
acquiring knowledge." (page 57)</p>
</blockquote>
<hr>
<blockquote>
<p>"Although we might perceive some children to be more 'able' than
others, this is unimportant because there's not really anything we
can do about it. We can, however, do an awful lot about developing
the quantity and quality of what children know." (page 60)</p>
</blockquote>
<hr>
<blockquote>
<p>"While correlation is not proof that one thing causes another,
causation is implied." (page 65)</p>
</blockquote>
<p>This follows shortly after a section called "Correlation ≠ causation"...</p>
<hr>
<p><a href="https://www.danielnettle.org.uk/download/023.pdf">Intelligence and class mobility in the British population</a> by
Nettle is cited on page 67.</p>
<hr>
<blockquote>
<p>"Using the environment to increase crystallised intelligence is
central to making kids cleverer; fluid intelligence, and its
associated individual differences, is largely a distraction." (page
77)</p>
</blockquote>
<hr>
<p><a href="https://thepsychologist.bps.org.uk/volume-11/edition-2/can-iq-change">Can IQ change?</a> by Howe is cited on page 77.</p>
<hr>
<blockquote>
<p>"The difference of natural talents in different men is, in reality,
much less than we are aware of ... The difference between the most
dissimilar characters, between a philosopher and a common street
porter, for example, seems to arise not so much from nature as from
habit, custom, and education." (page 85, quoting Adam Smith, The
Wealth of Nations)</p>
</blockquote>
<hr>
<p><a href="https://www.aft.org/periodical/american-educator/spring-2013/schooling-makes-you-smarter">Schooling Makes You Smarter: What Teachers Need to Know about IQ</a>
by Nisbett is cited on page 88. Decent?</p>
<hr>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/14629696/">Socioeconomic status modifies heritability of IQ in young children</a>
by Turkheimer et al. is cited on page 89.</p>
<hr>
<p><a href="http://www1.udel.edu/educ/gottfredson/reprints/1997mainstream.pdf">Mainstream Science on Intelligence: An Editorial With 52 Signatories, History, and Bibliography</a> by Gottfredson is cited on page 95.</p>
<hr>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/17100793/">Black Americans reduce the racial IQ gap: evidence from standardization samples</a>
by Dickens and Flynn is cited on page 97.</p>
<hr>
<blockquote>
<p>"The IQ score of the same person taking a test on different days
would produce a correlation of about 0.87." (pages 100-101)</p>
</blockquote>
<p>And this is <em>good</em> reliability? Hmm.</p>
<hr>
<blockquote>
<p>"Whether or not this [set of recommendations for schools] results in
a measurable increase in IQ is largely irrelevant. I think we can
all agree that intellectual curiosity and a lifelong love of
learning are things we want for all children, and these suggestions
seems like a reasonable bet for getting what we want." (page 111)</p>
</blockquote>
<p>But the title of the book is "Making kids cleverer"... that was the
whole goal you were working on!</p>
<hr>
<blockquote>
<p>"The rule seems to be that education raises crystallised
intelligence but not fluid intelligence." (page 118)</p>
</blockquote>
<hr>
<p><a href="http://www.iapsych.com/iqmr/fe/LinkedDocuments/wongupparaj2015.pdf">A Cross-Temporal Meta-Analysis of Raven's Progressive Matrices: Age groups and developing versus developed countries</a> by Wongupparaj et al. is cited on page 128.</p>
<hr>
<p><a href="https://www.pnas.org/content/115/26/6674">Flynn effect and its reversal are both environmentally caused</a> by Bratsberg and Rogeberg is referenced on page 129.</p>
<hr>
<blockquote>
<p>"It's much more likely that a growth mindset follows from
experiencing success." (page 131)</p>
<p>"As we've seen, motivation is a product of being successful." (page
267)</p>
</blockquote>
<p>The earlier bit has no reference. The later cites <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1056.1518&amp;rep=rep1&amp;type=pdf">The Relation of Academic Self-Concept to Motivation among University EFL Students</a>, but that paper is reporting correlation, not causation. The closest they get to causation is actually in the reverse direction:</p>
<blockquote>
<p>"results support numerous research findings that academic
self-concept is an important determinant of students’ academic
performance"</p>
</blockquote>
<hr>
<blockquote>
<p>"Beliefs about the malleability of basic ability appear to be
largely irrelevant: achievement is all about work." (page 135)</p>
</blockquote>
<hr>
<blockquote>
<p>"However, if you want to, you can take an A level <a href="https://www.cambridgeinternational.org/images/164766-2016-syllabus.pdf">course</a> in
thinking skills." (140)</p>
</blockquote>
<hr>
<blockquote>
<p>"<a href="https://en.wikipedia.org/wiki/Cognitive_acceleration">Cognitive Acceleration through Science Education (CASE)</a>"
(page 140)</p>
</blockquote>
<hr>
<blockquote>
<p>"The main reason children end up not learning what they're taught in
school isn't that they're not capable of remembering it; it's that
their teachers don't sufficiently value kids knowing stuff and don't
use the sorts of consolidation strategies which would help them to
remember." (page 157)</p>
</blockquote>
<hr>
<blockquote>
<p>"I have to show you how to use a comma in a wide variety of contexts
and then get you to practise writing correctly punctuated
sentences." (page 179)</p>
</blockquote>
<p>So his focus on "knowledge" includes skills and application; not just
memorization.</p>
<hr>
<blockquote>
<p>"The general rule is that expert knowledge always trumps raw
ability." (page 180)</p>
</blockquote>
<hr>
<blockquote>
<p>"Knowledge is most truly flexible when it is automatised." (page
183)</p>
</blockquote>
<hr>
<p>On page 183, Didau references a student's test response as "empty and
worthless". His book doesn't include the question prompt visible in
<a href="https://i2.wp.com/www.learningspy.co.uk/wp-content/uploads/2016/11/Screen-Shot-2016-11-09-at-15.12.38.png">the original</a>. With that context, the answer doesn't seem so crazy
to me. Doesn't seem like a very good question, really.</p>
<hr>
<blockquote>
<p>"So what does it mean to be skilled at making inferences? Nothing:
it is indistinguishable from being knowledgeable." (page 186)</p>
</blockquote>
<hr>
<blockquote>
<p>"We are unable to think with anything that we are dependent on
looking up." (page 191)</p>
</blockquote>
<hr>
<blockquote>
<p>"It's only when people ask us to explain what we think we know that
we find out whether we know it." (page 197)</p>
</blockquote>
<hr>
<p>Many references to Michael Young's "powerful knowledge" idea. Here's
one <a href="https://files.eric.ed.gov/fulltext/EJ1085994.pdf">applied explainer</a> I found. I also stumbled on this
<a href="https://www.researchgate.net/publication/323587483_The_Weakness_of_Powerful_Knowledge">critique</a>, which includes in its abstract: "The first part of the
article focuses on the definitional connection that Young makes
between 'powerful knowledge' and systematic relationships between
concepts. It argues that most of the school subjects that Young sees
as providing 'powerful knowledge' fall short on this requirement."</p>
<hr>
<blockquote>
<p>"Being able to quote Shakespeare or knowing Pythagoras' theorem may
seem like trivia, but it enables us to access society in a way which
would be impossible if we didn't know any of this." (page 209)</p>
</blockquote>
<hr>
<blockquote>
<p>"One much chewed bone of contention is who gets to decide what
knowledge children should learn. The assumption seems to be that
there's some shadowy elite inflicting their preferences on the rest
of us. This is nonsense. No one chooses; we all choose. No one
person knows enough to make this choice but collectively we have
access to the vast accumulation of human culture. The most important
things to know are those things that last and which most influence
other cultural developments; those things that inspire the most
'conversations' backwards and forwards through time and across
space; those things that allow us to trace our cultural inheritance
through threads of thought from the discoveries of modern science
and the synthesis of modern art back to their ancient origins."
(page 210)</p>
</blockquote>
<p>This is a mess on multiple levels. Leaving aside the most obvious
issues around who he means by "we", he's abandoned his original claim
of arguing for making children cleverer: lasting a long time and being
culturally popular does not imply useful for thought, and then we're
back to who he means when he says "our cultural inheritance".</p>
<hr>
<blockquote>
<p>"On the face of it, building a curriculum around the thoughts and
deeds of historically marginalised groups looks like a really good
idea. Who wouldn't want children to know about the achievements of
women and people of colour? The trouble is, this isn't shared
knowledge. It doesn't allow access to the 'knowledge of power', and,
crucially, it doesn't provide much cultural capital." (page 211)</p>
</blockquote>
<p>What happened to making children cleverer? Say, by giving them access
to the powerful idea that everyone can contribute to society, not just
historically dominant (not to say oppressive) people?</p>
<p>Maybe he's arguing against a curriculum based <em>only</em> on historically
marginalised groups, to the exclusion of his buddy Shakespeare, say?</p>
<hr>
<blockquote>
<p>"Does it add to children's knowledge of what others in society
consider to be valuable?" (page 218)</p>
</blockquote>
<p>This is the <em>first</em> in Didau's list of desiderata for what to teach.</p>
<hr>
<blockquote>
<p>"The epistemology of most sciences, for example, is often based upon
experimentation and discovery and, since this is so, experimentation
and discovery should be apart of any curriculum aimed at 'producing'
future scientists. But this does not mean that experimentation and
discovery should also be the basis for curriculum organization and
learning-environment designing." (quoting Paul Kirschner, page 223)</p>
</blockquote>
<p>I think the opposite (not teaching students <em>about</em> experimentation
and discovery, and letting them try it <em>at least a little</em>) is also a
mistake.</p>
<hr>
<blockquote>
<p>"We've already seen that the best way to learn the solutions to
problems is not by solving problems. Problem solving is the means by
which new knowledge might be added to the domain; it is not an
effective means of learning the knowledge already within the
domain." (page 224)</p>
<p>"Solving problems is an inefficient way to get better at problem
solving." (page 236)</p>
</blockquote>
<p>This sounds very strange from a math teacher's perspective, where the
goal is often to teach students <em>to solve problems</em>, and some even say
the only way to learn it is to solve problems. Here's Lockhart:
"Mental acuity of any kind comes from solving problems yourself, not
from being told how to solve them."</p>
<hr>
<p>Didau's second requirement for a curriculum is that it is "Culturally
rich. (Does the selected content conform to shared cultural agreements
of what is considered valuable to know?)" (page 224)</p>
<p>On page 225 he summarizes "Some knowledge is more culturally rich than
other knowledge — that is, more valued within society."</p>
<p>There is a separate case to be made, maybe, for knowing what other
people know so that you can communicate with them, walk the halls of
power, etc. But it is not, in my opinion, the same as a case for some
knowledge making you cleverer. The argument that historically dominant
knowledge is the best knowledge is problematic.</p>
<hr>
<blockquote>
<p>"As experts, we often assume that others share the same background
knowledge as us and so it often goes unsaid. And where expert
knowledge is stated, all too often it isn't understood. Experts are
unaware of the extent of their knowledge and end up speaking in
maxims. As we saw in Chapter 7, such maxims are easily understood by
other experts but are meaningless to novices. Where a novice will be
confused and frustrated by gaps in explanation, an expert fills them
within even realising they're doing it. Such is the curse of
knowledge. This lack of insight into the source of expertise can
lead us into neglecting the teaching of the vital nuts and bolts on
which our expert performances depend." (page 234)</p>
</blockquote>
<hr>
<blockquote>
<p>"It's worth noting that we can't create mental representations just
through study — we have to get our hands dirty by trying to do the
thing we want to improve at." (page 240)</p>
</blockquote>
<hr>
<h3><a name="plagiarism" href="#plagiarism">Plagiarism</a></h3>
<p>I happened to look up the <a href="https://en.wikipedia.org/wiki/Expertise_reversal_effect">expertise reversal effect</a> on Wikipedia.
I'll put in bold parts that correspond word for word.</p>
<p>Here's what Didau's book includes on page 245:</p>
<blockquote>
<p>"<strong><em>The worked-example effect</em></strong> — <strong>worked examples</strong> (<strong>a problem
statement followed by a step-by-step demonstration of how to solve
it</strong>) <strong>are often contrasted with open-ended problem solving in
which the learner is responsible for providing the step-by-step
solution.</strong> Although novices <strong>benefit more from studying structured
worked examples than from solving problems on their own, as
knowledge increases, open-ended problem solving becomes more
effective.</strong>"</p>
</blockquote>
<p>Here's Wikipedia:</p>
<blockquote>
<p>"Interactions between levels of knowledge and <strong>the worked-example
effect</strong>: <strong>Worked examples</strong> provide <strong>a problem statement followed
by a step-by-step demonstration of how to solve it</strong>. Worked
examples <strong>are often contrasted with open-ended problem solving in
which the learner is responsible for providing the step-by-step
solution.</strong> Low-knowledge learners <strong>benefit more from studying
structured worked</strong>-out <strong>examples than from solving problems on
their own</strong>. However, <strong>as knowledge increases, open-ended problem
solving becomes</strong> the <strong>more effective</strong> learning activity."</p>
</blockquote>
<p>I think a teacher grading a paper would have to call this plagiarism.</p>
<hr>
<p><a href="https://www.jstor.org/stable/43549795">Domain-Specific Knowledge and Why Teaching Generic Skills Does Not Work</a> by André Tricot and John Sweller is cited on page 245.</p>
<hr>
<blockquote>
<p>"We should always remember that novices are not less intelligent,
they are less knowledgeable. Everyone gets cleverer the more they
know and the more they practise." (page 246)</p>
</blockquote>
<hr>
<blockquote>
<p>"The point of these desirable difficulties is to confront us with
the illusion of knowledge and reveal the true extent of our
ignorance." (page 254)</p>
</blockquote>
<hr>
<blockquote>
<p>"If students simply struggle they will learn to hate school. If they
struggle too much, or too soon, this will also be undesirable.
Struggle is only desirable after success has been encoded." (page
254)</p>
</blockquote>
<hr>
<blockquote>
<p>"<em>The point is not that children should sink or swim, it's that they
should all swim.</em>" (page 255)</p>
</blockquote>
<hr>
<blockquote>
<ol>
<li>"Encode success.</li>
<li>Promote internalisation.</li>
<li>Increase challenge.</li>
<li>Repeat." (page 255)</li>
</ol>
</blockquote>
<hr>
<blockquote>
<p>"Developing good explanations and accurate analogies is probably the
key area of subject specialist knowledge teachers most need to
develop." (page 257)</p>
</blockquote>
<hr>
<blockquote>
<p>"Attempting to follow along in their own copy of a text while
simultaneously having to listen as the text is read aloud is
impossible. Children are forced to task switch between the printed
material and the sound of the teacher's voice, meaning they lose
track of what it is they're supposed to be reading and remember far
less than if they had either read or listened without trying to do
both at once." (page 261)</p>
</blockquote>
<p>This is presented without citation. It would be interesting if it was
supported by some evidence. I feel like I remember plenty of following
along in texts while others read in my early education at least, and I
don't recall it being difficult. References welcome.</p>
<hr>
<blockquote>
<p>"And thinking about what we teach is enhanced by remembering that
our aim is to help children become more creative, be better problem
solvers, think more critically and be more collaborative." (page
269)</p>
</blockquote>
<hr>
<blockquote>
<p>"Some knowledge is both more powerful (allows for thinking more
thoughts) and more culturally rich (has a higher cultural value)
than other kinds of knowledge; as such, it results in more useful
schemas." (page 276)</p>
</blockquote>
<p>Here at least he recognizes a distinction.</p>    
    ]]></description>
<link>http://planspace.org/20210914-didaus_2019_book_plagiarism_and_one_main_bad_idea/</link>
<guid>http://planspace.org/20210914-didaus_2019_book_plagiarism_and_one_main_bad_idea/</guid>
<pubDate>Tue, 14 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>David Didau's 2015 book endorses eugenics</title>
<description><![CDATA[

<p>The most salient thing about Didau's <em>What if everything you knew
about education was wrong?</em> turns out to be that it has an appendix by
<a href="https://www.theguardian.com/politics/2020/feb/17/andrew-sabisky-boris-johnsons-ex-adviser-in-his-own-words">Andrew Sabisky</a> which recommends as an "excellent and readable
introduction to behavior genetics" an <a href="https://files.eric.ed.gov/fulltext/ED023722.pdf">infamous article</a> by
eugenicist <a href="https://www.splcenter.org/fighting-hate/extremist-files/individual/arthur-jensen">Arthur Jensen</a>, among other more and less explicitly
racist, backward things.</p>
<p>This harmful propaganda was not only published, but also hasn't been
corrected since. The book is still for sale. Didau's <a href="https://learningspy.co.uk/featured/have-you-read-the-wrongbook/">site</a> still
says "Andrew Sabisky has elegantly debunked a series of the most
enduring edu-myths about intelligence" in it. While in a
<a href="/20210914-didaus_2019_book_plagiarism_and_one_main_bad_idea/">later book</a> Didau describes eugenics as "an unpleasant and
inherently racist ideology" (page 96) he hasn't disavowed the contents
of his earlier book, including when asked directly (<a href="https://twitter.com/planarrowspace/status/1432060069961736204">1</a>, <a href="https://twitter.com/planarrowspace/status/1433458397647708163">2</a>).</p>
<p>Didau's chapters themselves dog-whistle a little more subtly, as when
he smirks at political correctness by referencing an
<a href="https://metro.co.uk/2008/06/20/dont-brainstorm-take-a-thought-shower-204354/">obscure incident</a> (page 76) or (in his <a href="/20210914-didaus_2019_book_plagiarism_and_one_main_bad_idea/">later book</a>) disparages a
feminist paper without considering its contents (page 204).</p>
<p>The book otherwise advocates for explicit instruction and trying to
get kids to remember things via, for example, spaced repetition. Didau
supports a knowledge-rich curriculum like <a href="https://en.wikipedia.org/wiki/E._D._Hirsch">Hirsch</a> and wants
everybody to stop hassling teachers so much. His thinking here reminds
me of a <a href="https://knowyourmeme.com/memes/iq-bell-curve-midwit">meme</a> from
<a href="https://www.lesswrong.com/posts/F6ZTtBXn2cFLmWPdM/seven-years-of-spaced-repetition-software-in-the-classroom-1">Seven Years of Spaced Repetition Software in the Classroom</a>.</p>
<p><img alt="cartoon" src="just_show_em_stuff.jpg"></p>
<p>Approach with caution.</p>
<p><img alt="cover" src="eugenics_book_cover.jpg"></p>
<hr>
<p>While this is always the case, I feel like it's especially important
with a book like this for me to point out that selected quotes below
do not indicate my agreement with or support for any particular quote.</p>
<hr>
<blockquote>
<p>"To make things even more challenging for us as learners and/or
teachers, conditions of instruction or practice that appear to
result in rapid progress and learning can fail to produce good
long-term retention of skills and knowledge, or transfer of such
skills or knowledge to new situations where they are relevant,
whereas other conditions that pose challenges for the learner — and
appear to slow the learning process — can enhance such long-term
retention and transfer. Conditions of the latter type, which I have
labelled "desirable difficulties", include spacing, rather than
massing, repeated study opportunities; interleaving, rather than
blocking, instruction or practice on the separate components of a
given task; providing intermittent, rather than continuous, feedback
to learners; varying the conditions of learning, rather than keeping
them constant and predictable; and using tests, rather than
re-presentations, as learning opportunities." (pages iv-v)</p>
</blockquote>
<hr>
<blockquote>
<p>"These are the <em>threshold concepts</em> of the book:</p>
<ul>
<li>Seeing shouldn't always result in believing (Chapter 1).</li>
<li>We are all victims of cognitive bias (Chapter 2).</li>
<li>Compromise doesn't always result in effective solutions (Chapter
    4).</li>
<li>Evidence is not the same as proof (Chapter 5).</li>
<li>Progress is a gradual, non-linear process (Chapters 6 and 7).</li>
<li>Learning is invisible (Chapter 8).</li>
<li>Current performance is not only a poor indication of learning, it
    actually seems to prevent it (Chapters 8 and 9).</li>
<li>Forgetting aids learning (Chapter 9).</li>
<li>Experts and novices learn diffferently (Chapter 10).</li>
<li>Making learning more difficult can make it more durable (Chapter
    11)." (page 2)</li>
</ul>
</blockquote>
<hr>
<blockquote>
<p>"Because curriculum time is always limited, we need to decide which
is more important: teaching or learning." (page 3)</p>
</blockquote>
<hr>
<blockquote>
<p>"This leads us to <a href="https://en.wikipedia.org/wiki/Na%C3%AFve_realism_(psychology)">naive realism</a> — the belief that our senses
provide us with an objective and reliable awareness of the world."
(page 16)</p>
</blockquote>
<hr>
<blockquote>
<p>"For the most part 'anecdotal evidence' is an oxymoron." (page 18)</p>
</blockquote>
<hr>
<blockquote>
<p>"The fusion of these beliefs is <em>enactivism</em>: there really is an
objective reality out there, but we cannot perceive it directly.
Instead we share in the generation of meaning; we don't just
exchange information and ideas, we change the world by our
participation in it. We take the evidence of our senses and
construct our own individual models of the world. But because we
start with the same objective reality, our individual constructed
realities have lots of points of contact." (page 21)</p>
</blockquote>
<p>I'm not sure that's quite what others mean by <a href="https://en.wikipedia.org/wiki/Enactivism">enactivism</a>...</p>
<hr>
<blockquote>
<p>"This is what Michael Shermer calls "patternicity": the tendency to
find meaningful patterns in random noise." (page 26)</p>
</blockquote>
<p>This is citing "The Believing Brain: From Ghosts and Gods to Politics
and Conspiracies—How We Construct Beliefs and Reinforce Them as
Truths".</p>
<p>See also: <a href="https://en.wikipedia.org/wiki/Apophenia">apophenia</a>.</p>
<hr>
<blockquote>
<p>"Our inability to think statistically causes us to routinely
misinterpret what data tells us. In a survey of school results in
Pennsylvania, many of the top performing schools were very small.
Intuitively this makes sense — in a small school teachers will
better know their students and will be able to give much more
tailored support. This finding encouraged the Bill and Melinda Gates
Foundation to make a $1.7 billion investment in founding a string of
small schools. Sadly the project was a failure. The finding that
smaller schools do better was a confound; the worst schools in the
Pennsylvania survey were also small schools. Statistically small
schools are not better. In fact, larger schools tend to produce
better results due to the diversity of curriculum options they can
offer. OUr desire to find patterns and explanations trips us up. We
ignore the statistical fact that small populations tend to yield
more extreme results than larger populations, and we focus instead
on causes and narratives." (page 27)</p>
</blockquote>
<p>This cites "Evidence That Smaller Schools Do Not Improve Student
Achievement" by Wainer and Zwerling.</p>
<hr>
<p>On page 55 he talks about the British system of "target grades", which
is surprising and weird to me. Every student gets some explicit target
grade for their big exams at the end of high school. Wacky. He cites a
<a href="https://othmarstrombone.wordpress.com/2014/07/18/how-to-eat-50-hot-dogs-in-12-minutes-and-why-setting-targets-may-hold-back-progress/">blog post</a>.</p>
<p>After talking to Jay about this, it's possible having "target grades"
isn't so different from how things often play out in the US, when
student performance on standardized tests sorts them into tracked
classes... Not exactly the same thing, but maybe not <em>so</em> foreign.</p>
<hr>
<blockquote>
<p>"Assigning numerical values to our preferences and biases gives them
the power of data, but they're still just made up." (page 58)</p>
</blockquote>
<hr>
<blockquote>
<p>"The philosopher Bertrand Russell pointed out, "in the modern world
the stupid are cocksure while the intelligent are full of doubt"."
(page 62)</p>
</blockquote>
<p>The citation is Russell's "<a href="https://russell-j.com/0583TS.HTM">The Triumph of Stupidity</a>".</p>
<hr>
<p>I hadn't heard of "thought-showering" instead of "brain-storming"...
The phrase seems to have had a <a href="https://metro.co.uk/2008/06/20/dont-brainstorm-take-a-thought-shower-204354/">short history</a>. The citation of
<a href="https://www.tandfonline.com/doi/abs/10.1207/s15324834basp1201_1">Productivity Loss in Brainstorming Groups: A Meta-Analytic Integration</a>
is more relevant. (page 76)</p>
<hr>
<blockquote>
<p>"Rushing students into situations where they are expected to behave
like experts misses the fact that they don't yet know enough to do
so. Simply making students work in groups will not create better
workers." (page 77)</p>
</blockquote>
<hr>
<blockquote>
<p>"The point of collaboration is that it opens us up to the ideas of
others. But so does reading books." (page 77)</p>
</blockquote>
<hr>
<blockquote>
<p>"If the evidence tells us that teacher led instruction is an
effective way to teach and discovery learning is an ineffective way
of teaching (and it does), why would you do a bit of both?" (101)</p>
</blockquote>
<p>That highly opinionated bit contrasts with this nearby selection:</p>
<blockquote>
<p>"Teaching cannot be child centered and teacher led at the same time.
You have to make a choice. I'm not arguing that one position is
better than the other, just that they are mutually exclusive." (page
102)</p>
</blockquote>
<p>He's trying to make an argument here, and it might even be right, but
he isn't making it very well.</p>
<hr>
<blockquote>
<p>"My own suspicion is that most teachers put on a child-centered show
when observed and then revert to teaching from the front when the
classroom door is closed. The only real effect that being told
teaching should be relevant, active and collaborative has had is to
make us feel guilty for teaching." (page 109)</p>
</blockquote>
<p>This is quite a claim.</p>
<hr>
<p>On page 111, I was interested to see the
<a href="https://en.wikipedia.org/wiki/Edgar_Dale#Cone_of_Experience">Cone of Experience</a>/"Learning Pyramid" ("people remember X% of what
they Y") debunked. I remember seeing a poster version back in middle
school, and I never questioned it. Didau cites
<a href="https://www.cisco.com/c/dam/en_us/solutions/industries/docs/education/Multimodal-Learning-Through-Media.pdf">Multimodal Learning Through Media</a>, which opens with a good
critique of the "Learning Pyramid" thing.</p>
<hr>
<blockquote>
<p>"Making it harder to learn is more effective than making it easy."
(page 115)</p>
</blockquote>
<hr>
<blockquote>
<p>"Instead of endlessly seeking to find out new things, we should
think more carefully about the things we've already found out."
(page 127)</p>
</blockquote>
<p>I like this, but maybe it's not an "instead of" but "in addition
to"...</p>
<hr>
<blockquote>
<p>"It's not clear whether 'direct instruction' refers to generic
teacher-led whole-class teaching or Siegfried Engelmann's
<a href="https://www.nifdi.org/">Direct Instruction</a>, in which lessons are scripted and which
outperformed all other teaching methods in the largest and most
expensive education study ever undertaken, Project Follow Through."
(page 131)</p>
</blockquote>
<p>If scripted lessons are so great, why is video not so great?</p>
<hr>
<blockquote>
<p>"Education researcher and author Geoff Petty <a href="https://geoffpetty.com/geoffs-books/evidence-based-teaching-ebt/">says</a>, "This
strategy of top-down diktat does not work, it has been carefully
evaluated and it fails. So if you are forced to do “evidence based
teaching”, you are not doing Evidence Based Teaching! You are being
bullied with an ineffective management strategy!"" (page 133)</p>
</blockquote>
<hr>
<blockquote>
<p>"Coe has <a href="https://img1.wsimg.com/blobby/go/ede177f2-5088-4fee-a850-d64ccdf72d47/downloads/Improving%20Education%20Coe%20Inaugural%20June%202013.pdf?ver=1621348419849">suggested</a> this axiom: "Learning happens when people
have to think hard.""</p>
</blockquote>
<hr>
<blockquote>
<p>"Understanding and recognizing the most important conceptual areas
of our subjects upon which all else rests might help us to make
better decisions about both what and how to teach." (page 164)</p>
</blockquote>
<hr>
<blockquote>
<p>"The notion of ability is as much about how we see ourselves and how
others see us as it is about intelligence." (page 172)</p>
</blockquote>
<hr>
<blockquote>
<p>"We want our students to have an understanding of the deep structure
of a domain of knowledge, but we have to be patient. If we want
someone to have an insight, simply telling them what the insight is
'meant to be' robs them of seeing it for themselves. Instead, we can
tell them as much about the surface features of a problem as we can
and wait for them to join our dots. Mimicry is a necessary waiting
room in the chaos of liminal space. Feeling frustrated that children
know, say, their times tables, but are unable to do long division,
is silly. As they learn more facts, see more examples and get more
practice, they will slowly but surely move towards an expert's
understanding of the subject." (page 201)</p>
</blockquote>
<p>For someone who doesn't like discovery learning, this seems similar to
discovery learning...</p>
<hr>
<blockquote>
<p>"The path to mastery isn't smooth, but it becomes a lot less bumpy
when we accept that it's hard and that we're supposed to struggle."
(page 209)</p>
</blockquote>
<hr>
<blockquote>
<p>"Testing can (and should) include some of the tricks and techniques
we've been misusing and misunderstanding as Formative Assessment. In
fact, it doesn't really matter how we test students as long as our
emphasis changes. Testing should not be used primarily to assess the
efficacy of your teaching and students' learning; it should be used
as a powerful tool in your pedagogical armory to <em>help</em> them learn."
(page 234)</p>
</blockquote>
<hr>
<blockquote>
<p>"Trying harder makes a big difference. Getting students to
understand what they should be doing is hard enough, but motivating
them to actually do it is the master skill." (page 256)</p>
</blockquote>
<p>For something that's "the master skill", this topic isn't given much
attention... There is some though...</p>
<hr>
<blockquote>
<p>"The fourth reason
[for students to decide to invest effort, "To improve their performance"]
is the one we should seek to develop. How can we give feedback which
harnesses students' desire to improve their performance? ... What we
want is for students to see their success as being directly causes
by their effort. ... The point of all this, as William concludes, is
for students to believe that "It's up to me" (internal) and "I can
do something about it" (stable)." (pages 259-261)</p>
</blockquote>
<hr>
<p>Quoting Dylan William:</p>
<blockquote>
<p>"So, as a general rule, I advise teachers not to give feedback
unless the first 10 to 15 minutes of the next lesson is allocated to
students responding to the feedback." (page 267)</p>
</blockquote>
<hr>
<blockquote>
<p>"One of my favorite models for classroom observation is the one
taken by Doug Lemov and the Uncommon Schools network. The idea is
ridiculously simple: you look at the data to find out which teachers
have the best results and then you observe them to find out what
they're doing. Lemov's teaching manual, <em>Teach Like A Champion</em>, is
a compendium of some of the strategies common to these über-teachers
which can be practiced and replicated by us mere mortals." (page
302)</p>
</blockquote>
<hr>
<blockquote>
<p>"As we know, children are complex and classrooms more complex still.
We're probably interested in more than students 'merely' acquiring
new skills and knowledge within the domains of the subjects we
teach. We may also have an interest in fostering a 'love of
learning' and turning students into 'lifelong learners'. Whatever
the current trend might be, we want our students to somehow be
changed and improved by their experiences in school." (page 309)</p>
</blockquote>
<hr>
<p>Quoting <a href="https://journals.sagepub.com/doi/abs/10.1177/1948550610385872" title="Deliberate Practice Spells Success: Why Grittier Competitors Triumph at the National Spelling Bee">Duckworth et al.</a>:</p>
<blockquote>
<p>"Grittier spellers engaged in deliberate practice more so than their
less gritty counterparts, and hours of deliberate practice fully
mediated the prospective association between grit and spelling
performance." (page 310)</p>
</blockquote>
<hr>
<p>Quoting <a href="https://en.wikipedia.org/wiki/The_Craftsman_(book)">Richard Sennett</a>:</p>
<blockquote>
<p>"We share in common and in roughly equal measure the raw abilities
that allow us to become good craftsmen: it is the motivation and
aspiration for quality that takes people along different paths in
their lives. Social conditions shape these motivations." (page 320)</p>
</blockquote>
<hr>
<p>(From here on is from Appendix 2: "Five myths about intelligence" by
Andrew Sabisky, who seems to be <a href="https://www.theguardian.com/politics/2020/feb/17/andrew-sabisky-boris-johnsons-ex-adviser-in-his-own-words">a monster</a>.)</p>
<hr>
<blockquote>
<p>"Differential psychology — the science that investigates the nature
and causes of differences between individuals in their cognition
..." (page 391)</p>
</blockquote>
<hr>
<blockquote>
<p>"Throughout the 19th century, most commentators on mental abilities
assumed they were independent — a school of thought called 'faculty
psychology'. [in the sense of multiple intelligences] Such a model
remained untested until an English psychologist, Charles Spearman,
found that boys' grades in school subjects were highly correlated;
the boys who excelled at math were likely to be better than average
in English and Latin. Spearman developed a novel statistical
technique called factor analysis to analyze his data and proposed
that one common factor, <em>g</em>, explained most of the variance in a
battery of mental tests, but that each subtest also had its own
specific variance (Spearman called this non-shared variation <em>s</em>
factor). Spearman's original finding has since been modified by
later analyses and the factors derived from analyses of mental tests
are best thought to fit into a pyramidal structure, with <em>g</em> at the
top (see Figure A2.1). The finding that all mental tests positively
inter-correlate is probably the most replicated result in all of
psychology, and factor analyses is now an extremely popular
statistical tool used widely across the social and biological
sciences." (pages 392-393)</p>
</blockquote>
<hr>
<blockquote>
<p>"<em>G</em> does not appear to be a chimerical statistical artefact, as has
sometimes been alleged by Stephen J. Gould and others, but a
biological reality fundamental to cognition." (page 393)</p>
</blockquote>
<hr>
<p>Sabisky references, as an "excellent and readable introduction to
behavior genetics", the article
<a href="https://files.eric.ed.gov/fulltext/ED023722.pdf">How much can we boost IQ and scholastic achievement?</a> by
<a href="https://www.splcenter.org/fighting-hate/extremist-files/individual/arthur-jensen">Arthur Jensen</a>. So while Sabisky is a little racist and eugenicist
in his appendix, he's citing (and recommending, even) very racist,
very eugenicist sources.</p>
<hr>
<blockquote>
<p>"The assumption is taken for granted that all groups are exactly
equal in their ability and that any differences between them result
from biased tests." (page 402)</p>
</blockquote>
<p>I'm not commenting everywhere, but this is so egregious a straw man I
couldn't skip it.</p>
<hr>
<blockquote>
<p>"The tests that best predict job performance also discriminate the
most against non-Asian ethnic minorities, and especially blacks. The
dilemma this gives rise to is known in industrial-organizational
psychology as the <em>diversity-validity trade-off</em>." (page 403)</p>
</blockquote>
<hr>
<blockquote>
<p>"Do we want to assess the intellectual ability of our students? Such
tests are certainly of great value to universities and even more to
many employers. Or do we want to assess the competence of our
teachers by making sure that our students have in fact learned, with
some reasonable proficiency, a core stock of knowledge that we value
as a society?" (page 406)</p>
</blockquote>
<hr>
<p>I didn't know quite what "<a href="https://www.bbc.com/news/education-34538222">grammar school</a>" means in the UK...</p>
<hr>
<blockquote>
<p>"Large, permanent individual differences in talent are a fact of
life and are not going to go away for the foreseeable future." (page
408)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210914-david_didaus_2015_book_endorses_eugenics/</link>
<guid>http://planspace.org/20210914-david_didaus_2015_book_endorses_eugenics/</guid>
<pubDate>Tue, 14 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Simple short number notation</title>
<description><![CDATA[

<p>Scientific notation is great, but "67B" is easier for most people than
"6.7e10". I whipped up a quick Python function that does this for
numbers up into the trillions. It always gives you back four
characters, like this:</p>
<pre><code>                   1.1 -&gt; '  1 '
                  98.2 -&gt; ' 98 '
                 111.7 -&gt; '112 '
               9_876   -&gt; '9.9K'
          12_345_678   -&gt; ' 12M'
     123_456_789_012   -&gt; '123B'
 999_123_456_789_012   -&gt; '999T'</code></pre>

<p>Thousands as "K" might be a little unfamiliar for some audiences, but
overall I think this is pretty good, for example for labeling axes.
Here's the code:</p>
<pre><code class="language-python">def tdn(number):
    """Short (Three-Digit Number) string representation"""
    assert 0 &lt;= number &lt; 9.995e14, 'outside range of defined behavior'
    if number &lt; 1000:
        return f'{round(number):3d} '
    number /= 1000
    for symbol in 'KMBT':
        if number &gt;= 1000:
            number /= 1000
            continue
        if number &gt;= 10:
            return f'{number:3.0f}{symbol}'
        return f'{number:1.1f}{symbol}'
    return result</code></pre>

<p>There's probably a nicer way to do it; feedback (and pull requests
<a href="https://github.com/ajschumacher/three_digit_numbers">on GitHub</a>) welcome!</p>    
    ]]></description>
<link>http://planspace.org/20210908-simple_short_number_notation/</link>
<guid>http://planspace.org/20210908-simple_short_number_notation/</guid>
<pubDate>Wed, 08 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Spaced repetition is O(log n) sustainable</title>
<description><![CDATA[

<p>If you use <a href="https://en.wikipedia.org/wiki/Spaced_repetition">spaced repetition</a> software like <a href="https://apps.ankiweb.net/">Anki</a> for a long
time, will you have to spend more and more time studying every day?
Yes, but the increase is <a href="https://en.wikipedia.org/wiki/Time_complexity#Logarithmic_time">logarithmic</a> with time, which is a very
slow increase. If you add ten cards a day, then after a year you do 85
reviews per day. After ten years, that goes to 118 reviews per day,
and even after 100 years, it's 152 reviews per day—still only half an
hour or so each day.</p>
<p>The major simplifying assumption here is that review delays double, so
that after <em>n</em> days, the number of days that are contributing their
cards to today's review is <em>log<sub>2</sub>(n)</em>.</p>
<p>Your review delays won't be exactly that, and you won't add cards
evenly across days. For me, the estimate is close but slightly high
after 336 days of using Anki.</p>
<p>The average number of cards added per day is an important
multiplicative factor; my average is currently 11.3 cards per day and
trending lower. It might be higher for full-time students, but I'd be
surprised if many people stayed much above ten cards per day over
multiple years. When you stop adding so many cards, daily reviews
decrease rapidly.</p>
<p>I think spaced repetition study could reasonably be a lifelong
practice, like daily exercise.</p>    
    ]]></description>
<link>http://planspace.org/20210908-spaced_repetition_is_o_log_n_sustainable/</link>
<guid>http://planspace.org/20210908-spaced_repetition_is_o_log_n_sustainable/</guid>
<pubDate>Wed, 08 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Try a table instead of a Pareto chart</title>
<description><![CDATA[

<p>I thought <a href="https://en.wikipedia.org/wiki/Pareto_chart">Pareto charts</a> might be fine if they didn't use multiple
vertical axes, but I was wrong. Pareto charts have lots of problems,
especially with many items and long labels. Pareto chart information
is better presented horizontally, as in a table.</p>
<div style="display: flex; align-items: start;">
<img src="pareto_budget.png" width="49%">
<img src="table_budget.png" width="49%">
</div>

<p>The Pareto chart image at left is the same width as the table image
shown at right.</p>
<hr>
<ul>
<li><a href="#multi_vert">Multiple vertical axes?</a></li>
<li><a href="#cumulative_bad">The cumulative percentage line is bad</a></li>
<li><a href="#labeling_pie">Pie charts are also bad for labeling</a></li>
<li><a href="#labeling_bar">Stacked bar charts are also hard to label</a></li>
<li><a href="#label_bar">Bar charts: Hard to label</a></li>
<li><a href="#table">Just make a table</a></li>
<li><a href="#categories">Categories are problematic</a></li>
<li><a href="#change">Change over time?</a></li>
<li><a href="#data">Data for this example</a></li>
<li><a href="#code">Code for this example</a></li>
</ul>
<hr>
<h3><a name="multi_vert" href="#multi_vert">Multiple vertical axes?</a></h3>
<p>Here's an example I <a href="https://medium.com/swlh/pareto-chart-with-python-5200459ee65c">found</a> of a Pareto chart where both the
individual bars and cumulative line use all the vertical space, which
looks nice visually.</p>
<p><img alt="Pareto chart with two different vertical axes" src="multi_vertical_pareto_chart.png"></p>
<p>In my opinion the confusion introduced by having two different
vertical axes is unacceptable.</p>
<p>This particular example is especially egregious because the right hand
cumulative percentage scale starts at 20% rather than 0%, which makes
it look like the leftmost category somehow accounts for almost none of
the cumulative total.</p>
<p>This example also shows how text on visualizations can become a
disaster by getting tiny. Don't make people squint.</p>
<p>The problem of having two vertical scales isn't necessary; the same
scale can be used, and presented as both raw value and percent of
total. But often, this introduces a lot of whitespace.</p>
<p><img alt="Pareto chart with lots of whitespace" src="pareto_whitespace.png"></p>
<p>The vertical axis labels could be improved here, but the main visual
effect is to foreground the cumulative percentage line, squishing the
bars. Is the cumulative percentage line worth it?</p>
<hr>
<h3><a name="cumulative_bad" href="#cumulative_bad">The cumulative percentage line is bad</a></h3>
<p>Ordering things by size is interesting and useful for understanding
what components are largest, but it isn't really a natural ordering.
It could change, for example. So while there is a cumulative value in
the sense of "the top 5 items account for X% of the total", these
values aren't cumulative in the sense of summing over a natural order
the way you might to get the probability of rolling a 3 or lower, for
example.</p>
<p>There's also no meaning to the cumulative value "between" two
categories, generally. Using a line to connect the cumulative sums
suggests a smoothness of transition which is misleading.</p>
<p>The main use you might put the cumulative line to is identifying the
number of categories that add up to some percentage of the total, like
50% or 80%. This leads immediately to trying to do this using the
figure's axes, which is clumsy. Better to include the values, and if
you do this via direct labeling, your figure is becoming a table with
awkward alignment.</p>
<hr>
<h3><a name="labeling_pie" href="#labeling_pie">Pie charts are also bad for labeling</a></h3>
<p>The main thing people love to hate about pie charts is the difficulty
we have interpreting relative sizes of pieces of pie, and this is
valid. But it's also a huge pain to label those slices.</p>
<p>If you take the easy way out with a separate legend, as in this
<a href="https://en.wikipedia.org/wiki/File:Fy2010_spending_by_category.jpg">extreme example</a>, you create a miserable game of hide and seek for
the viewer.</p>
<p><img alt="horrible pie chart" src="horrible_pie.jpg"></p>
<p>This example struggles even to label the percentages of the tiny
slices, and matching labels to slices is very difficult.</p>
<p>Attempting direct labeling with a pie chart is better, as in this
<a href="https://commons.wikimedia.org/wiki/File:Military_Expenditures_by_Country_2019.svg">example</a> comparing military spending.</p>
<p><img alt="labeled war pie" src="labeled_war_pie.png"></p>
<p>There are two reasons direct labeling is possible here: country names
tend to be short, and most countries get tossed into "Rest of World".
In general, pie chart labeling won't work as well as this.</p>
<p>And of course the problems with using a circular representation remain
as well.</p>
<hr>
<h3><a name="labeling_bar" href="#labeling_bar">Stacked bar charts are also hard to label</a></h3>
<p>A stacked bar chart should be better than a pie chart in that it
allows viewers to compare linear distances, but it's still hard to
label. I tried a couple different ways.</p>
<p>I tried mocking up direct labeling on a stacked bar, but I gave up
before I finished adding all the lines because it was just a
nightmare. Too many lines, too close together.</p>
<p><img alt="directly labeled stacked bar" src="direct_bar.png"></p>
<p>The alternative then is to use proximity. But what do you do with the
labels that won't fit?</p>
<p>Here's one clumsy answer, just stacking the labels once there isn't
space to put them in the right places. It starts to just look like a
table with wasted space.</p>
<p><img alt="some direct labeling on a bar" src="list_bar.png"></p>
<p>A variation puts all the unlabelable categories into a catch-all,
which I don't really love either.</p>
<p><img alt="catch-all on a bar" src="glom_bar.png"></p>
<p>The horizontal text is at least readable, and it isn't a pie chart,
but it's also still not really so easy to compare lengths between
segments at the top and the bottom of the stacked bar.</p>
<hr>
<h3><a name="label_bar" href="#label_bar">Bar charts: Hard to label</a></h3>
<p>With languages that write left-to-right or right-to-left, it's
difficult to label a bunch of vertical bars. Especially with longer
labels, it can get ridiculous.</p>
<p><img alt="as a Pareto chart" src="pareto_budget.png"></p>
<p>Arguably, a big part of the value of a Pareto chart <em>is the labels</em>
because they've been put in order so that the biggest factors come
first. Readability is important. The Pareto chart generally fails to
have highly readable labeling.</p>
<hr>
<h3><a name="table" href="#table">Just make a table</a></h3>
<p>A horizontal bar chart with the cumulative line dropped could make for
a better Pareto chart. You could adjust orientation and add numeric
labeling so that viewers can read off useful values. At this point
what you have is really a table with one column of <a href="https://support.google.com/docs/answer/3093289">SPARKLINE</a> bars.</p>
<p><img alt="as a table" src="table_budget.png"></p>
<p>Using a table lets you easily align data in columns for easy reference
and scanning, increasing information density without making an
irregular Where's Waldo of numbers.</p>
<hr>
<h3><a name="categories" href="#categories">Categories are problematic</a></h3>
<p>Categories are generally epiphenomena of human perception.</p>
<p>In this example, why is "Medicare" separate from "Health"? Why use the
divisions here and not others? Sometimes big categories here are
omitted by others as non-discretionary; why not do that?</p>
<p>Questions of this kind are probably a bigger deal than the
visualization you choose, but are outside scope here.</p>
<hr>
<h3><a name="change" href="#change">Change over time?</a></h3>
<p>Data is shown for a single year here, but changes over time are super
interesting. "Income security" is the top category for 2020, but
that's because of COVID-19: it was fifth for 2019. "National defense"
was second in 2019. I'm not sure what the best way to show these
changes over time; the <a href="https://datalab.usaspending.gov/americas-finance-guide/spending/trends/">trends</a> page from the data provider isn't
bad.</p>
<hr>
<h3><a name="data" href="#data">Data for this example</a></h3>
<p>The data is from <a href="https://www.usaspending.gov/">USAspending.gov</a>'s Data Lab
<a href="https://datalab.usaspending.gov/americas-finance-guide/spending/categories/">Federal Spending by Category and Agency</a>. I dropped "Offsetting
Revenue Collected But Not Attributed to Functions" on the grounds that
I don't understand how it's spending. Really I think their displays
are pretty good.</p>
<hr>
<h3><a name="code" href="#code">Code for this example</a></h3>
<p>A brief Python notebook is <a href="https://github.com/ajschumacher/pareto_chart">on GitHub</a>. I mocked some stuff up in a
<a href="https://docs.google.com/presentation/d/1hpaWIa7o0OvJkJZUQPotfGkvMxM548Gc6n5ruEZ8rTE/edit?usp=sharing">Google Slides deck</a>, and the main table is in a <a href="https://docs.google.com/spreadsheets/d/1o6fo5obvkJAUW-r12EAzqvmoNnEhd-Q05RUFMlq1xuw/edit?usp=sharing">Google Sheet</a>.
All of these are fairly clumsy and I'd love to find better ways of
doing this kind of thing.</p>    
    ]]></description>
<link>http://planspace.org/20210907-try_a_table_instead_of_a_pareto_chart/</link>
<guid>http://planspace.org/20210907-try_a_table_instead_of_a_pareto_chart/</guid>
<pubDate>Tue, 07 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Dot product really does give you cosine</title>
<description><![CDATA[

<p>The <a href="https://en.wikipedia.org/wiki/Dot_product">dot product</a> of \( A \) and \( B \) gives you the
<a href="https://en.wikipedia.org/wiki/Trigonometric_functions">cosine</a> of the angle \( \gamma \) between them, scaled by the
product of their lengths, \( a \) and \( b \) (Equation 1). Here's
a proof using the Law of Cosines.</p>
<p>\[ A \cdot B = \cos \left( \gamma \right) a b \tag{1} \]</p>
<p></p><center><img src="diagram.jpg" height="200px"></center>
<p>Equation 1 is invoked, for example, in defining <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a>,
often without derivation.</p>
<p>If, in \( n \) dimensions, the <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian coordinates</a> of a point
\( X \) are \( x_1, x_2, \dotso, x_n \), then the dot product \(
A \cdot B \) is the sum of element-wise products as in Equation 2.</p>
<p>\[ A \cdot B = \sum_{i=1}^n{a_i b_i} \tag{2} \]</p>
<p>The dot product is so simple, it's a little surprising a nice
trigonometric function like cosine should come out of it in arbitrary
high-dimensional spaces.</p>
<p>Notation has been chosen so as to write the <a href="https://en.wikipedia.org/wiki/Law_of_cosines">Law of Cosines</a> as
usual in Equation 3.</p>
<p>\[ c^2 = a^2 + b^2 - 2 a b \cos \left( \gamma \right) \tag{3} \]</p>
<p>The \( c^2 \) in Equation 3 is the square of the distance from \( A
\) to \( B \) and can also be written, using the
<a href="https://en.wikipedia.org/wiki/Pythagorean_theorem">Pythagorean theorem</a>, as in Equation 4.</p>
<p>\[ c^2 =
    \sum_{i=1}^k{ \left( a_i - b_i \right)^2 } =
    \sum_{i=1}^k{ a_i^2 + b_i^2 - 2 a_i b_i } =
    a^2 + b^2 - 2 \sum_{i=1}^k{ a_i b_i } \tag{4} \]</p>
<p>Equating the right hands of Equations 3 and 4, and recognizing the dot
product as in Equation 2, we've built Equation 1 from scratch. \(
\Box \)</p>
<hr>
<p>It's also possible to use two-dimensional right triangle visualization
thinking to see how dot product projects one vector onto another, with
scaling by the lengths of the vectors. 3Blue1Brown has a great
<a href="https://www.youtube.com/watch?v=LyGKycYT2v0&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&amp;index=10">video</a>. It's easy to connect to the usual definition of cosine.</p>
<p>Since you can always rotate your coordinate frame to get one vector
with all zero coordinates except for one, and the other vector with
all zero coordinates except for that one and one more, it's clear that
dot product should give cosine in that frame, but it isn't necessarily
obvious (to me) that everything works out in other coordinate frames.
The proof above gives me confidence that it does. (Not that I didn't
believe it before, but it's nice to have a reason.)</p>
<hr>
<p>I wasn't quite satisfied with cosine similarity via dot product for a
long time. My satisfaction now and the proof above is based quite
directly on the proof Hamming generously gives on pages 117-118 of
<a href="/20200725-art_of_doing_science_and_engineering/">The Art of Doing Science and Engineering</a>. As he says there
(italics in original):</p>
<blockquote>
<p>"I have found it very valuable in important situations to review
<em>all the basic derivations involved</em> so I have a firm feeling for
what is going on."</p>
</blockquote>
<p>He uses different (possibly better?) notation, and his figure is
certainly nicer than mine.</p>
<!-- mathjax for formulas -->

    ]]></description>
<link>http://planspace.org/20210904-dot_product_really_does_give_you_cosine/</link>
<guid>http://planspace.org/20210904-dot_product_really_does_give_you_cosine/</guid>
<pubDate>Sat, 04 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Working Backwards, by Bryar and Carr</title>
<description><![CDATA[

<p>It's kind of an <a href="https://www.workingbackwards.com/">ad</a> for the authors' consulting, but it's also
interesting to hear how Amazon works. They quote a lot of
<a href="https://ir.aboutamazon.com/annual-reports-proxies-and-shareholder-letters/">shareholder letters</a> (NDA concerns?) and are no doubt biased, but
some Amazon ideas seem okay. The chapter organization is decent:</p>
<ol>
<li>"Building Blocks: <a href="https://www.amazon.jobs/en/principles">Leadership Principles</a> and Mechanisms"<ul>
<li>I've heard there are also team-specific (and other?)
   "<a href="https://medium.com/fact-of-the-day-1/tenets-at-amazon-a2bb8a56ae94">tenets</a>" that sort of layer on top of the Leadership
   Principles.</li>
</ul>
</li>
<li>"Hiring: Amazon's Unique Bar Raiser Process"<ul>
<li>Quite structured, focused on specifics/data/anecdotes, with a
   facilitator expert in hiring process.</li>
</ul>
</li>
<li>"Organizing: Separable, Single-Threaded Leadership"<ul>
<li>Make it somebody's only responsibility. They don't use
   <a href="https://www.theguardian.com/technology/2018/apr/24/the-two-pizza-rule-and-the-secret-of-amazons-success">two-pizza teams</a> that much any more, but this
   single-threaded idea is still emphasized.</li>
</ul>
</li>
<li>"Communicating: Narratives and the Six-Pager"<ul>
<li>They listened to <a href="https://www.edwardtufte.com/tufte/powerpoint">Tufte</a>! No PowerPoint!</li>
</ul>
</li>
<li>"Working Backwards: Start with the Desired Customer Experience"<ul>
<li>They write a press release and FAQ for the thing, as if they're
   launching it today, before they decide to do it at all.</li>
</ul>
</li>
<li>"Metrics: Manage Your Inputs, Not Your Outputs"<ul>
<li>Makes a lot of sense, assuming you really know how inputs
   connect to outputs... Studying that is probably somebody's job.</li>
</ul>
</li>
</ol>
<p>And then they talk about Kindle, Prime, Prime Video, and AWS in part two.</p>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"In its first shareholder letter back in 1997, Amazon's first year
as a public company, you'll find the phrases "Obsess Over
Customers," "It's All About the Long Term," and "We will continue to
learn from both our successes and our failures." One year later the
term "Operational Excellence" entered the discussion, completing the
four-faceted description of Amazon's corporate culture that endures
today." (page xi)</p>
<p>"Of course, these four cultural touchstones don't quite get at the
"how," that is, how people can work, individually and collectively,
to ensure that they are maintained. And so Jeff and his leadership
team crafted a set of 14 [now 16] Leadership Principles, as well as
a broad set of explicit, practical methodologies, that constatntly
reinforce its cultural goals. These include: the Bar Raiser hiring
process that ensures that the company continues to acquire top
talent; a bias for separable teams run by leaders with a singular
focus that optimizes for speed of delivery and innovation; the use
of written narratives instead of slide decks to ensure that deep
understanding of complex issues drives well-informed decisions; a
relentless focus on input metrics to ensure that teams work on
activities that propel the business. And finally there is the
product development process that gives this book its name: working
backwards from the desired customer experience." (page xi)</p>
</blockquote>
<hr>
<p>Around page 12, they talk about how the Leadership Principles tried to
capture the culture, not create it. They were first listed in
2004-2005, ten years after Amazon was founded.</p>
<hr>
<blockquote>
<p>"In my tenure at Amazon I heard him [Jeff Bezos] say many times that
if we wanted Amazon to be a place where builders can build, we
needed to eliminate communication, not encourage it." (page 61)</p>
</blockquote>
<hr>
<blockquote>
<p>"The metrics used to measure progress were agreed upon. For example,
In-stock Product Pages Displayed divided by Total Product Pages
Displayed, weighted at 60 percent; and Inventory Holding Cost,
weighted at 40 percent." (page 70)</p>
</blockquote>
<p>Reading this quickly, it seems to make sense. But the values are on
different scales: one is between zero and one (I hope) and the other
is a cost, presumably measured in dollars. So what is this really?</p>
<p>Also, for product pages, an ebook is always in stock, so is there an
incentive to show ebooks rather than physical books? Is that
desirable?</p>
<hr>
<blockquote>
<p>"If you're good at course correcting, being wrong may be less costly
than you think, whereas being slow is going to be expensive for
sure." (page 71, quoting the 2016 Bezos shareholder letter)</p>
</blockquote>
<hr>
<blockquote>
<p>"Sometimes it's best to start slow in order to move fast." (page 71)</p>
</blockquote>
<hr>
<blockquote>
<p>"Fitness Functions Were Actually Worse Than Their Component Metrics</p>
<p>Two-pizza teams had been meant to increase the velocity of product
development, with custom-tailored fitness functions serving as the
directional component of each team's velocity. By pointing each team
in the right direction and alerting them early if they drifted off
course, fitness functions were supposed to align the team uniquely
to its goals. We tried them out for more than a year, but fitness
functions never really delivered on their promise for a couple of
important reasons.</p>
<p>First, teams spent an inordinate amount of time struggling with how
to construct the most meaningful fitness function. Should the
formula be 50 percent for Metric A plus 30 percent for Metric B plus
20 percent for Metric C? Or should it be 45 percent for Metric A
plus 40 percent for Metric B plus 15 percent for Metric C? You can
imagine how easy it was to get lost in those debates. The
discussions became less useful and ultimately distracting—just
another argument that people needed to win.</p>
<p>Second, some of these overly complicated functions combined seven or
more metrics, a few of which were composite numbers built from their
own submetrics. When graphed over time, they might describe a trend
line that went up and to the right, but what did that mean? It was
often impossible to discern what the team was doing right (or wrong)
and how they should respond to the trend. Also, the relative
weightings could change over time as business conditions changed,
obscuring historic trends altogether.</p>
<p>We eventually reverted to relying directly on the underlying metrics
instead of the fitness function. After experimenting over many
months across many teams, we realized that as long as we did the
up-front work to agree on the specific metrics for a team, and we
agreed on specific goals for each input metric, that was sufficient
to ensure the team would move in the right direction. Combining them
into a single, unifying indicator was a very clever idea that simply
didn't work." (pages 73-74)</p>
</blockquote>
<hr>
<blockquote>
<p>"What was originally known as a two-pizza team leader (2PTL) evolved
into what is now known as a single-threaded leader (STL). The STL
extends the basic model of separable teams to deliver their key
benefits at any scale the project demands. Today, despite their
initial success, few people at Amazon still talk about two-pizza
teams." (page 75)</p>
</blockquote>
<hr>
<blockquote>
<p>"When the retail, operations, and finance teams began to construct
the initial Amazon WBR [Weekly Business Review], they turned to a
well-known Six Sigma process improvement method called DMAIC, an
acronym for Define-Measure-Analyze-Improve-Control." (page 124)</p>
<p>"Amazon takes this philosophy
[of understanding how inputs affect outputs] to heart, focusing most
of its effort on leading indicators (we call these "controllable
input metrics") rather than lagging indicators ("output metrics")."
(page 124)</p>
</blockquote>
<hr>
<blockquote>
<p>"When Amazon teams come across a surprise or a perplexing problem
with the data, they are relentless until they discover the root
cause. Perhaps the most widely used technique at Amazon for these
situations is the Correction of Errors (COE) process, based upon the
"Five Whys" method developed at Toyota and used by many companies
worldwide." (page 132)</p>
</blockquote>
<hr>
<blockquote>
<p>"Anecdotes and exception reporting are woven into the
[Weekly Business Review] deck." (page 135)</p>
<p>"Data Combined with Anecdote to Tell the Whole Story: Numerical data
become more powerful when combined with real-life customer stories."
(page 142)</p>
<p>"These stories remind us that the work we do has direct impact on
customers' lives." (page 143)</p>
<p>"Data and anecdotes make a powerful combination when they're in
sync, and they are a valuable check on one another when they are
not." (page 145)</p>
</blockquote>
<hr>
<blockquote>
<p>"Even the best process can only improve the quality of your
decision-making; no process will make the decision for you." (page
159)</p>
</blockquote>
<hr>
<blockquote>
<p>"With each modification [of the org structure], the scope of each
leader's responsibilities would become narrower, but the intended
scale of each role was greater. At most companies, reducing a
leader's scope would be considered a demotion, and in fact there
were many VPs and directors who saw each of these changes in that
way. At Amazon, it was not a demotion." (page 174)</p>
</blockquote>
<p>There's some interesting organizational psychology here; maybe it's
obvious, but it seems interesting to me.</p>
<hr>
<blockquote>
<p>"Steve asked Gregg to build out a hardware organization, which he
did with the code name Lab126 (the 1 and 26 stood for the letters A
and Z) and earmarked a meaningful amount of capital to the effort."
(page 181)</p>
</blockquote>
<hr>
<blockquote>
<p>"... we learned from studies that the average consumer would only
bother to connect their iPod to their PC once a year. That meant
most people walked around without the latest music on their devices.
It was known as the "stale iPod" syndrome." (page 183)</p>
</blockquote>
<p>This kind of thing is fascinating - often I would never guess the real
behavior of real people, on average.</p>
<hr>
<blockquote>
<p>"... in Amazonian terms, a "strong general athlete" (SGA)." (page 202)</p>
</blockquote>
<p>Seems like this phrase shows up sometimes on Amazon job descriptions...</p>
<hr>
<blockquote>
<p>"Jeff and other Amazon leaders often talk about the "institutional
no" and its counterpart, the "institutional yes." The institutional
no refers to the tendency for well-meaning people within large
organizations to say no to new ideas." (pages 203-204)</p>
</blockquote>
<hr>
<blockquote>
<p>"Jeff said he wanted to build a moat around our best customers.
Prime would be a premium experience for convenience-oriented
customers." (page 208)</p>
</blockquote>
<hr>
<p>Wrapping up with recommendations:</p>
<blockquote>
<ul>
<li>"Ban PowerPoint</li>
<li>Establish the Bar Raiser hiring process</li>
<li>Focus on controllable input metrics</li>
<li>Move to an organizational structure that accomodates autonomous
  teams with single-threaded leaders</li>
<li>Revise the compensation structure for leaders</li>
<li>Articulate the core elements of the company's culture</li>
<li>Define a set of leadership principles</li>
<li>Depict your flywheel" (pulled from pages 261-262)</li>
</ul>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210903-working_backwards_by_bryar_and_carr/</link>
<guid>http://planspace.org/20210903-working_backwards_by_bryar_and_carr/</guid>
<pubDate>Fri, 03 Sep 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>I want to be a mathematician, by Halmos</title>
<description><![CDATA[

<p>I don't always agree perfectly with <a href="https://en.wikipedia.org/wiki/Paul_Halmos">Halmos</a>, but I really like his
<a href="https://smile.amazon.com/I-Want-be-Mathematician-Automathography/dp/0387960783">automathography</a>. I've looked at <a href="https://planspace.org/20201124-take_notes_like_paul_halmos/">parts</a> before, but it was great
to read the whole thing. It has a grandfatherly vibe, is beautifully
written and funny, and frequently has good ideas. Some quotes follow.</p>
<hr>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"Looking back on those days [growing up in Hungary] now, 50 to 60
years later, I appreciate and admire the atmosphere. Culture was not
ridiculous, unusual, or sissy—it was taken for granted. Books and
music were regarded as a part of everyone's common heritage. At
school we discussed the latest Nick Carter, sure, but we talked
about d'Artagnan too, and we could tell each other that we had just
read something without being considered odd." (page 7)</p>
</blockquote>
<hr>
<blockquote>
<p>"I think by writing." (page 8)</p>
</blockquote>
<hr>
<blockquote>
<p>"Anyway, back to chemistry: laboratory work seemed to me an
uninspiring and messy waste of time. I was never told and I never
caught on that a laboratory could teach you new facts and insights;
I regarded it as just one of those chores (like irregular verbs in
German and finger exercises for the piano) that the world assigns to
apprentices before allowing them to become journeymen. I knew in
advance what each experiment was intended to prove, and I proved it;
I cooked the books mercilessly. Before the year was over I knew that
chemistry was not for me, and I arranged to be transferred to the
general liberal arts curriculum." (pages 23-24)</p>
</blockquote>
<hr>
<blockquote>
<p>"The [calculus] text was the infamous Granville, Smith, and Longley
that, according to rumor, brought each of its authors a royalty
income of many thousands of dollars for at least 20 years. It was
very bad. The explanations were not explanations—they were neither
clear nor correct—they were cookbook instructions, no more. The
selling virtue of the book was that it had many exercises, amost all
of the the routine mechanical kind." (pages 26-27)</p>
</blockquote>
<hr>
<blockquote>
<p>"[In graduate school] I did not understand (never even dreamt of)
the idea of a "structure", in the sense in which, later,
<a href="https://en.wikipedia.org/wiki/Nicolas_Bourbaki">Bourbaki</a> used that word, and I was stumped by the infinitesimal
subtlety of epsilontic analysis. I could read analytic proofs,
remember them if I made an effort, and reproduce them, sort of. but
I didn't really know what was going on." (page 47)</p>
</blockquote>
<p>This is interesting to me... What about modern mathematicians? Are
they working because of or in spite of Bourbaki? I know I took some
courses that presented hyper-formal versions of things as if there
were no alternative, and certainly no real intuition... I'm not sure
it's the right way to teach, at least for a first introduction.</p>
<hr>
<blockquote>
<p>"Music and poetry are more important than carburetors and calculus,
because both the bus driver and I would be better human beings if we
had more in common and because we could then collaborate better to
live in a saner world." (page 30)</p>
</blockquote>
<hr>
<blockquote>
<p>"Another way in which I wish I had then followed the advice I give
now has to do with the old adage about all work and no play. I don't
believe it in; I think all work and no play is the only way to get
anything done. Having made my point in as shocking a way as I could
think of, I'm ready to take it back and modify it. I am not talking
about a lifetime of torture and slavery, and I am not excluding the
relaxing tennis game, detective story, dinner in Chinatown with a
bunch of friends, or Saturday night movie. What I am saying is that
the work of a scholar is not torture that would be insupportable
without distraction, and that, for most of us, two consuming
passions are one too many." (page 53)</p>
</blockquote>
<hr>
<blockquote>
<p>"If I had to describe my conclusion [about how to study] in one
word, I'd say <em>examples</em>. They are, to me, of paramount importance.
Every time I learn a new concept (free group, or pseudodifferential
operator, or paracompact space), I look for examples—and of course,
non-examples. The examples should include, whenever possible, the
typical ones and the extreme degenerate ones." (pages 61-62)</p>
</blockquote>
<hr>
<blockquote>
<p>"I did read the first 10 or 20 pages of all those books, and I
dipped into other parts, skipping back and forth among them. (I wish
I had read the first 10 pages of many more books—a splendid
mathematical education can be acquired that way.)" (page 65)</p>
</blockquote>
<hr>
<blockquote>
<p>"It's been said before and often, but it cannot be overemphasized:
study actively. Don't just read it; fight it! Ask your own
questions, look for your own examples, discover your own proofs. Is
the hypothesis necessary? Is the converse true? What happens in the
classical special case? What about the degenerate cases? Where does
the proof use the hypothesis?" (page 69)</p>
</blockquote>
<hr>
<blockquote>
<p>"With no official pre-arrangement, I simply tacked up a card on the
bulletin board in Fine Hall saying that I would offer a course
called "Elementary theory of matrices", and I proceeded to offer it.
I prepared for it carefully, a goodly number of students (something
like a dozen) attended regularly, and a couple of them took notes.
... As far as money goes, Princeton was agreeable to accepting my
services free; I was slightly surprised when, at the end of the
term, those services were officially recognized. I received an
official request to assign grades in the course—as far as Princeton
University and the students were concerned, the course carried
graduate credit. From my point of view, as teacher, the course was
splendid. No one came unless he wanted to; there was no nonsense
about prerequisites and distribution requirements. There was no
syllabus; we talked about what we wanted to talk about. There was no
homework, there were no exams. When I had to give grades, I did so
on the basis of subjective impressions acquired during class and
during between-class discussions." (pages 95-96)</p>
</blockquote>
<p>Halmos similarly just <em>showed up</em> at the Institute for Advanced Study
with a friend of his who was actually invited, and effectively joined
by proximity. Bold!</p>
<hr>
<blockquote>
<p>"To write a book based on the notes of a course is a good way to
write a book. The most important single feature of good writing—of
clear communication of any kind—is organization. If you know the
right order in which a sequence of things should be said, and if you
know the extent to which you need to emphasize some parts and play
others down, your communication battle is more than half won." (page
96)</p>
</blockquote>
<hr>
<blockquote>
<p>"I readily admit—I'd like to be among the first to insist—that
expository writing should not deviate from currently accepted
standard English; in such writing even puns and other attempts at
humor, and, of course, outright vulgarity, are badly out of place.
Why? Because they are irrelevant, they are distracting, they
interfere with the clear reception of the message. Expository
writing must not be sloppy in either content or form and, of course,
it must not be misleading.; it must be dignified, correct, and
clear. Within these guidelines, however, expository writing should
be written in a living, colloquial style, it should be evocative in
the same sense in which poetry is, and it should not be stuffy, but
friendly and informal. The purpose of writing is to communicate, and
style is a tool for communication. It should be chosen so as to put
the reader at his ease and make the subject seem as easy to him as
it already is to the author." (page 113)</p>
</blockquote>
<hr>
<blockquote>
<p>"What is important in communication, in lecturing for example, is
not what message the speaker sends but what message the listener
receives. A part of the art of lecturing is to know when and how to
lie. Don't insist on protecting yourself by being cowardly
legalistic, but lead the audience to the truth." (page 114)</p>
</blockquote>
<hr>
<blockquote>
<p>"..., John Isbell (who, God forgive him, became a categorist), ..."
(page 155)</p>
</blockquote>
<hr>
<blockquote>
<p>"I give most of the credit
[for still remembering Spanish after many years] to the saturation
method—do everything, do it all at once, and do it every minute you
can possibly spare—the best way of learning there is." (page 172)</p>
</blockquote>
<hr>
<blockquote>
<p>"By now I think fondly of it [Uruguay] and wish it well; it gave me
something and I left part of me there; I am glad I went, and I am
glad I am not there now." (page 199)</p>
</blockquote>
<p>I feel similarly about South Korea.</p>
<hr>
<blockquote>
<p>"Both the logician and, say, the harmonic analyst, look for a
certain kind of structure, but their kinds of structures are
psychologically different. The mathematician wants to know, must
know, the connections of his subject with other parts of
mathematics. The intuitive similarities between quotient groups and
quotient spaces are, at the very least, valuable signposts, the
constituents of "mathematical maturity", wisdom, and experience. A
microscopic examination of such similarities might lead to category
theory, a subject that is viewed by some with the same kind of
suspicion as logic, but not to the same extent." (page 205)</p>
</blockquote>
<p>"The logician" here is not "the mathematician"...</p>
<hr>
<blockquote>
<p>"He [Carl E. Linderholm] became famous for a brilliant, witty,
extended mathematical in-joke, a book called
<a href="https://en.wikipedia.org/wiki/Mathematics_Made_Difficult"><em>Mathematics Made Difficult</em></a> [<a href="http://i7-dungeon.sourceforge.net/math_hard.pdf">PDF</a>]. The book treats high
school trigonometry, for instance, from the point of view of
category theory, for instance—I recommend it highly." (page 222)</p>
</blockquote>
<p>As <a href="https://projecteuclid.org/journals/bulletin-of-the-american-mathematical-society/volume-61/issue-3.P1/Review-G-P%C3%B3lya-Mathematics-and-plausible-reasoning/bams/1183519731.full">reviewed</a> on Amazon by Easwaran, with review title "Categories
for the Non-Working Mathematician" (itself a reference to
<a href="https://en.wikipedia.org/wiki/Categories_for_the_Working_Mathematician">Categories for the Working Mathematician</a>):</p>
<blockquote>
<p>This book is a wonderfully humorous satire of the project (possibly
pushed by Mac Lane, Lawvere, Grothendieck, and others, though never
as far as one might think) to reformulate all of mathematics on
category-theoretic foundations. As such, many of the jokes will be
lost on a reader with no familiarity with the language of category
theory. But there are plenty of other jokes that even a high
schooler should be able to appreciate. There's also some
entertaining national stereotypes of French mathematicians and
others that probably date the book a bit.</p>
<p>Highly recommended for a math graduate student who needs distraction
from work.</p>
</blockquote>
<hr>
<p>On page 223 I learned that Halmos <a href="https://projecteuclid.org/journals/bulletin-of-the-american-mathematical-society/volume-61/issue-3.P1/Review-G-P%C3%B3lya-Mathematics-and-plausible-reasoning/bams/1183519731.full">reviewed</a> <em>Mathematics and
Plausible Reasoning</em>, which I haven't finished reading.</p>
<hr>
<blockquote>
<p>"As for quality [of books being higher than that of articles],
that's just a feeling I have. I think that, with extremely rare
exceptions, even the book of lowest quality is likely to be correct
most of the time, and to be well enough organized and expounded that
studying it would add to your mathematical wealth. Articles are more
often wrong and very often so badly done that reading them is more
work than it is worth. They must exist—don't misunderstand me—I am
not advocating that we stop publishing current research papers and
go back to the days when "publish" was synonymous with "publish a
book". No, papers are absolutely necessary, but books are better."
(page 234)</p>
</blockquote>
<hr>
<blockquote>
<p>"I am convinced (by faith) that if I knew everything about Boolean
algebras I would be very close to knowing everything about
analysis—or, to be a little more precise about such a vague article
of religion, that I would be as close as a person who knows
everything about measurable sets is to knowing everything about
measurable functions. Close, yes, but not yet there." (page 245)</p>
</blockquote>
<p>I'm not sure I really understand what he's getting at here, but it
sounds interesting.</p>
<hr>
<p>Halmos advocates the <a href="https://en.wikipedia.org/wiki/Moore_method">Moore method</a> (e.g., page 257). I'd be curious
to see the documentary about it, "Challenge in the Classroom"... (Did
I see it, once?)</p>
<hr>
<blockquote>
<p>"I think an automobile transmission mechanic should try to be the
best automobile transmission mechanic he has the talent to be, and
butlers, college presidents, shoe salesmen, and hod-carriers should
aim for perfection in their professions. Try to rise, improve
conditions if you can, and change professions if you must, but as
long as you are a hod-carrier, keep carrying those hods. If you set
out to be a mathematician, you must learn the profession, every part
of it, and then work at it, profess it, live it as best you can. If
you keep asking "what's there in it for me?", you're in the wrong
business. If you're looking for comfort, money, fame, and glory, you
probably won't get them, but if you keep trying to be a
mathematician, you might." (pages 264-268)</p>
</blockquote>
<p>I like this whole section and put it up as a separate page:
<a href="/20210820-how_to_be_a_pro_halmos/">How to be a pro</a>.</p>
<hr>
<blockquote>
<p>"On a Ph.D. oral he [Tamarkin] asked the candidate about the
convergence properties of a certain hypergeometric series. "I don't
remember", said the student, "but I can always look it up if I need
it." Tamarkin was not pleased. "That doesn't seem to be true", he
said, "because you sure need it now."" (page 272-273)</p>
</blockquote>
<hr>
<blockquote>
<p>"But let's get back to teaching by challenging. An intrinsic aspect
of the method at all levels, elementary or advanced, is to
concentrate attention on the definite, the concrete, the specific.
Once a student understands, really and truly understands, why 3x5 is
the same as 5x3, then he quickly gets the automatic and obvious but
nevertheless exciting unshakable generalized conviction that "it
goes the same way" for all other numbers. We all have an innate
ability to generalize; the teacher's function is to call attention
to a concrete special case that hides (and, we hope, ultimately
reveals) the germ of the conceptual difficulty." (page 272)</p>
</blockquote>
<hr>
<blockquote>
<p>"(Do all readers know that I reject "Hal-mush", some people's notion
of the "right" way to pronounce me? Please, please, say
"Hal-moss".)" (page 292)</p>
</blockquote>
<hr>
<blockquote>
<p>"How to do almost everything" (title of chapter 14, page 319)</p>
</blockquote>
<hr>
<blockquote>
<p>"Mathematics is not a deductive science—that's a cliché. When you
try to prove a theorem, you don't just list the hypotheses, and then
start to reason. What you do is trial and error, experimentation,
guesswork. You want to find out what the facts are, and what you do
is in that respect similar to what a laboratory technician does, but
it is different in its degree of precision and information. Possibly
philosophers would look on us mathematicians the same way as we look
on the technicians, if they dared." (page 321)</p>
</blockquote>
<hr>
<blockquote>
<p>"I love to do research, I want to do research, I have to do
research, and I hate to sit down and begin to do research—I always
try to put it off just as long as I can." (page 321)</p>
</blockquote>
<hr>
<blockquote>
<p>"It is important to me to have something big and external, not
inside myself, that I can devote my life to. Gauss and Goya and
Shakespeare and Paganini are excellent, their excellence gives me
pleasure, and I admire and envy them. They were also dedicated human
beings. Excellence is for the few but dedication is something
everybody can have—should have—and without it life is not worth
living." (pages 321-322)</p>
</blockquote>
<hr>
<blockquote>
<p>"Despite my great emotional involvement in work, I just hate to
start doing it; it's a battle and a wrench every time. Isn't there
something I can (must?) do first? Shouldn't I sharpen my pencils
perhaps? In fact I never use pencils, but "pencil sharpening" has
become the code phrase for anything that helps to postpone the pain
of concentrated attention. It stands for reference searching in the
library, systematizing old notes, or even preparing tomorrow's class
lecture, with the excuse that once those things are out of the way
I'll really be able to concentrate without interruption.</p>
<p>"When Carmichael complained that as dean he didn't have more than 20
hours a week for research I marvelled, and I marvel still. During my
productive years I probably averaged 20 hours of concentrated
mathematical thinking a week, but much more than that was extremely
rare. The rare exception came, two or three times in my life, when
long ladders of thought were approaching their climax. Even though I
never was dean of a graduate school, I seemed to have psychic energy
for only three or four hours of work, "real work", each day; the
rest of the time I wrote, taught, reviewed, conferred, refereed,
lectured, edited, travelled, and generally sharpened pencils all the
ways I could think of. Everybody who does research runs into fallow
periods. During mine the other professional activities, down to and
including teaching trigonometry, served as a sort of excuse for
living. Yes, yes, I may not have proved any new theorems today, but
at least I explained the law of sines pretty well, and I have earned
my keep." (page 322)</p>
</blockquote>
<p>There's more good stuff here... Almost worth putting up the whole
section ("How to do research") but I'll stop short of that. In
particular interesting that he describes his process as largely
writing-driven: "I sit down at my desk, pick up a black ball-point
pen, and start writing..." (page 323)</p>
<hr>
<blockquote>
<p>"For Dieudonné the important result is, I think, the powerful
general theorem, from which it is easy to infer all the special
cases you want; for me the greatest kind of step forward is the
illuminating central example from which it is easy to get insight
into all the surrounding sweeping generalities." (page 325)</p>
</blockquote>
<hr>
<blockquote>
<p>"André Weil's logarithmic law (first-rate people choose first-rate
people, but second-rate people elect third-rate ones) works the same
way whether the vote concerns a minor addition to the teaching staff
or the elevation of a colleague to leadership." (page 349)</p>
</blockquote>
<p>Ah; there's a similar thing on page 123 too:</p>
<blockquote>
<p>"André Weil suggested that there is a logarithmic law at work:
first-rate people attract other first-rate people, but second-rate
people tend to hire third-raters, and third-rate people hire
fifth-raters. If a dean or a president is genuinely interested in
building and maintaining a high-quality university (and some of them
are), then he must not grant complete self-determination to a
second-rate department; he must, instead, use his administrative
powers to intervene and set things right. That’s one of the proper
functions of deans and presidents, and pity the poor university in
which a large proportion of both the faculty and the administration
are second-raters; it is doomed to diverge to minus infinity." (page
123)</p>
</blockquote>
<p>A similar sentiment is often <a href="https://www.culture-spark.com/hire-bs-hire-cs/">attributed</a> to Steve Jobs: "A level
people hire level A people, B level people hire C level people."</p>
<hr>
<blockquote>
<p>"Napolean said that the only thing worse than a bad general is two
good ones, and I agree: a bad chairman will hurt a department less
than a committee can, even if it consists of competent people full
of good intentions." (page 351)</p>
</blockquote>
<hr>
<blockquote>
<p>"I believe that the work of the world is done by people, not by
committees. Socrates, the teacher, was not a committee, nor was
Archimedes, the inventor and research mathematician. The great
strides forward (in administration and in finance, as well as in
science and in the humanities) have always been made by people, not
by committees; Lincoln, Rothschild, Newton, and Goethe bear
witness." (page 352)</p>
</blockquote>
<hr>
<blockquote>
<p>"I read the Times book reviews because I don't have the time to read
all the books that come out, and reading reviews keeps me closer in
touch with modern culture than not reading anything at all." (page
375)</p>
</blockquote>
<hr>
<blockquote>
<p>"The purpose of the review is to provide a first approximation in
three or four pages to what the book does (or could have done) in
three or four hundred." (page 375)</p>
</blockquote>
<hr>
<blockquote>
<p>"In other words, exposition is intended to attract and describe more
than to explain and instruct." (page 390)</p>
</blockquote>
<hr>
<blockquote>
<p>"The most difficult technical problem of written communication
(whether the intended result is a long novel, a short biography, a
research paper, or a recipe for cherry pie) is that of linear order.
The way we usually receive information about the universe is
multidimensional. We learn about something (or somebody) through
signals that come to us simultaneously through our many senses. Our
sense of balance tells us one thing, and the way our muscles stretch
another; we see it, hear it, feel it, smell it, and taste it; we
find it warm or cold, wet or dry. A lecturer uses words, but, at the
same time, he controls how fast he speaks and how loudly; his facial
expressions, his gestures, and his tone of voice are all part of the
show. The most highly distilled form of verbal communication is
writing. The only raw material a writer has is his vocabulary, and
the presentation of his words in a total order is the only way he
has to produce an effect." (page 394)</p>
</blockquote>
<hr>
<blockquote>
<p>"You can't be perfect, but if you don't try, you won't be good
enough." (page 400)</p>
</blockquote>
<hr>
<blockquote>
<p>"Archimedes taught us that a small quantity added to itself often
enough becomes a large quantity (or, in proverbial terms, that every
little bit helps). When it comes to accomplishing the bulk of the
world's work, and, in particular, the work of a mathematician,
whether it is proving a theorem, writing a book, teaching a course,
chairing a department, or editing a journal, I claim credit for the
formulation of the converse: Archimedes's way is the only way to get
something done. Do a small bit, steadily every day, with no
exception, with no holiday. As an example, I mention the first
edition of my <em>Hilbert Space Problem Book</em>, which had 199 problems.
I wrote most of the first draft during my Miami year, and I forced
myself, compulsively, to write a problem a day. That doesn't mean
that it took 199 days to write the whole book—the total came to
about three times that many." (pages 401-402)</p>
</blockquote>
<hr>
<p>Somewhere, I'm not sure where now, Halmos talks about being a
<em>teacher</em> versus being an <em>example</em>... Interesting to think about: How
are these different? What's more useful, when? Is this an apprentice
model? How can that be done well? It reminds me of when I heard
<a href="https://en.wikipedia.org/wiki/Leon_Botstein">Botstein</a> talk about how he wouldn't hire a professor who wasn't
doing research. At the time I was surprised; I knew so little.</p>    
    ]]></description>
<link>http://planspace.org/20210821-i_want_to_be_a_mathematician_by_halmos/</link>
<guid>http://planspace.org/20210821-i_want_to_be_a_mathematician_by_halmos/</guid>
<pubDate>Sat, 21 Aug 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>How to be a pro (Halmos)</title>
<description><![CDATA[

<p>This is a section (pages 264-268) from
<a href="https://smile.amazon.com/I-Want-be-Mathematician-Automathography/dp/0387960783/">I want to be a mathematician</a>, by Halmos.</p>
<blockquote>
<p>Anna, one of the mathematics department secretaries at Chicago,
complained to me once when we met at a party and she had already
consumed several gin and tonics. She was a good typist, and she
didn't have much trouble picking up the art of technical,
mathematical, typing—but she hated every minute of it. You have to
look at every symbol separately, you have to keep changing "typits"
or Selectric balls, you have to shift a half space up or down for
exponents and subscripts, and you have no idea what you're doing.
"I'm not going to spend my life flipping that damned carriage up and
down", she said.</p>
<p>Another time Bruno, a well-known mathematician, asked me: "How did
you manage to make your ten lectures at the CBMS conference all the
same length? Isn't it true that some things take longer? When I did
it, some of my talks were 45 minutes, and some 75."</p>
<p>More recently still I asked Calvin, a colleague, "Can you give a
graduate student a ride to this month's Wabash functional analysis
seminar?" "No", he said, "you better get someone else. I've been
away, giving colloquium talks twice this month, and that's enough
travelling."</p>
<p>I didn't make up any of this (except the names). Do you see what
these three stories have in common? To me it's obvious, it jumps to
the eye, and it horrifies me. What Anna, Bruno, and Calvin share and
express is widespread and bad: it's the "me" attitude. It is the
attitude that says "I do only what's important to me, and I am more
important to me than the profession."</p>
<p>I think an automobile transmission mechanic should try to be the
best automobile transmission mechanic he has the talent to be, and
butlers, college presidents, shoe salesmen, and hod-carriers should
aim for perfection in their professions. Try to rise, improve
conditions if you can, and change professions if you must, but as
long as you are a hod-carrier, keep carrying those hods. If you set
out to be a mathematician, you must learn the profession, every part
of it, and then work at it, profess it, live it as best you can. If
you keep asking "what's there in it for me?", you're in the wrong
business. If you're looking for comfort, money, fame, and glory, you
probably won't get them, but if you keep trying to be a
mathematician, you might.</p>
<p>I didn't preach to Calvin, but if I had done so, my sermon would
have said that you support an activity such as the Wabash seminar
(I'll tell more about that seminar later) without even thinking
about it—it's an integral part of professional life. You go to such
seminars the way you get dressed in the morning, nod amiably to an
acquaintance you pass on the street, or brush your teeth before you
go to bed at night. Sometimes you feel like doing it and sometimes
not, but you do it always—it's a part of life and you have no
choice. You don't expect to get rewarded if you do and punished if
you don't, you don't think about it—you just do it.</p>
<p>A professional must know every part of his profession and (we all
hope) like it, and in the profession of mathematics, as in most
others, there are many parts to know. To be a mathematician you have
to know how to be a janitor, a secretary, a businessman, a
conventioneer, an educational consultant, a visiting lecturer, and,
last but not least, in fact above all, a scholar.</p>
<p>As a mathematician you will use blackboards, and you should know
which ones are good and what is the best way and the best time to
clean them. There are many kinds of chalk and erasers; would you
just as soon make do with the worst? At some lecture halls you have
no choice—you must use the overhead projector, and if you don't come
prepared with transparencies, your audience will be in trouble. Word
processors and typewriters, floppy disks and lift-off
ribbons—ignorance is never preferable to bliss. Should you ditto
your preprints, or use mimeograph, or multilith, or xerox? Who
should make decisions about these trivialities—you, or someone who
doesn't care about your stuff at all?</p>
<p>From time to time you'll be asked for advice. A manufacturer will
consult you about the best shape for a beer bottle, a dean will
consult you about the standing of his mathematics department, a
publisher will consult you about the probably sales of a proposed
textbook on fuzzy cohomology. Possibly they will be genteel and not
even mention paying for your service; at other times they will refer
delicately to an unspecified honorarium that will be forthcoming.
Would they treat a surgeon the same way, or an attorney, or an
architect? Would you? Could you?</p>
<p>I am sometimes tempted to tell people that I am a <em>real</em> doctor,
not the medical kind; my education lasted a lot longer than their
lawyer's and cost at least as much; my time and expertise are worth
at least as much as their architect's. In fact, I do not use tough
language, but I've long ago decided not to accept "honoraria" but to
charge fees, carefully spelled out and agreed on in advance. I set
my rates some years back, when I was being asked to review more
textbooks than I had time for. I'd tell the inquiring publisher that
my fee is $1.00 per typewritten page or $50.00 per hour, whichever
comes to less. Sometimes the answer was: "Oh, sorry, we didn't
really want to spend that much", and at other times it was,
matter-of-factly, "O.K., send us your bill along with your report".
The result was that I had less of that sort of work to do and got
paid more respectably for what I still did. My doctor, lawyer, and
architect friends tell me that prices have changed since I
established mine. The time has com, they say, to double the charges.
The answers, they predict, will remain the same: half "no" and half
"sure, of course".</p>
<p>A professional mathematician talks about mathematics at lunch and
at tea. The subject doesn't have to be hot new theorems and proofs
(which can make for ulcers or ecstasy, depending)—it can be a new
teaching twist, a complaint about a fiendish piece of student
skullduggery, or a rumor about an error in the proof of the four
color theorem. At many good universities there is a long-standing
tradition of brown-bag (or faculty club) mathematics lunches, and
they are an important constituent of high quality. They keep the
members of the department in touch with one another; they make it
easy for each to use the brains and the memory of all. At a few
universities I had a hand in establishing the lunch tradition, which
then took root and flourished long after I left.</p>
<p>The pros go to colloquia, seminars, meetings, conferences, and
international congresses—and they use the right word for each. The
pros invite one another to give colloquium talks at their
universities, and the visitor knows—should know—that his duty is not
discharged by one lecture delivered between 4:10 and 5:00 p.m. on
Thursday. The lunch, which gives some of the locals a chance to meet
and have a relaxed conversation with the gues, the possible
specialists' seminar for the in-group at 2:00, the pre-lecture
coffee hour at 3:00, and the post-lecture dinner and evening party
are essential parts of the visitor's job description. It makes for
an exhausting day, but that's how it goes, that's what it means to
be a colloquium lecturer.</p>
<p>Sometimes you are not just a colloquium lecturer, but the "Class of
1909 distinguished Visitor", invited to spend a whole week on the
campus, give two or three mathematics talks and one "general"
lecture, and, in between, mingle, consult, and interact. Some do it
by arriving in time for a Monday afternoon talk, squeezing in a
Tuesday colloquium at a sister university 110 miles down the road,
reappearing for a Wednesday talk and a half of Thursday (spent
mostly with the specialist crony who arranged the visit), and
catching the plane home at 6:05 p.m. Bad show—malfeasance and
nonfeasance—that's not what the idea is at all. When Bombieri came
to Bloomington, I understood much of his first lecture, almost none
of the second, and gave up on the third (answered my mail
instead)—but I got a lot out of his presence. I heard him hold forth
on meromorphic functions at lunch on Monday, explain the Mordell
conjecture over a cup of coffee Wednesday afternoon, and at dinner
Friday evening guess at the probably standing of Euler and Gauss a
hundred years from now. We also talked about clocks and children and
sport and wine. I learned some mathematics and I got a little
insight into what makes one of the outstanding mathematicians of our
time tick. He earned his keep as Distinguished Visitor, not because
he is a great mathematician (that helps!) but because he took the
job seriously. It didn't take his talent to do that; that's
something us lesser people can do too.</p>
<p>Mathematical talent is probably congenital, but aside from that the
most important attribute of a genuine professional mathematician is
scholarship. The scholar is always studying, always ready and eager
to learn. The scholar knows the connections of his specialty with
the subject as a whole; he knows not only the technical details of
his specialty, but its history and its present standing; he knows
about the others who are working on it and how far they have
reached. He knows the literature, and he trusts nobody: he himself
examines the original paper. He acquires firsthand knowledge no only
of its intellectual content, but also of the date of the work, the
spelling of the author's name, and the punctuation of the title; he
insists on getting every detail of every reference absolutely
straight. The scholar tries to be as broad as possible. No one can
know all of mathematics, but the scholar can succeed in knowing the
outline of it all: what are its parts and what are their places in
the whole?</p>
<p>These are the things, some of the things, that go to make up a
pro.</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210820-how_to_be_a_pro_halmos/</link>
<guid>http://planspace.org/20210820-how_to_be_a_pro_halmos/</guid>
<pubDate>Fri, 20 Aug 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Books for Machine Learning</title>
<description><![CDATA[

<blockquote>
<p>"for someone that doesn't have a lot of experience with machine
learning, what books would you recommend starting with? machine
learning for dummies?"</p>
</blockquote>
<hr>
<div style="display:block; float:left;">

<a href="https://www.statlearning.com/">
<img src="intro_stat_learn.png" alt="Introduction to Statistical Learning" width="24%">
</a>

<a href="https://www.manning.com/books/deep-learning-with-python">
<img src="dl_with_py.png" alt="Deep Learning with Python" width="24%">
</a>

<a href="/20210508-statistical_rethinking_by_mcelreath/">
<img src="stat_rethink.jpg" alt="Statistical Rethinking" width="24%">
</a>

<a href="http://www.mmds.org/">
<img src="mine_massive.jpg" alt="Mining of Massive Datasets" width="24%">
</a>

</div>

<hr>
<p><a href="https://www.statlearning.com/">Intro to Statistical Learning</a>: The friendly version of
<a href="https://web.stanford.edu/~hastie/ElemStatLearn/">Elements</a> has <a href="https://www.r-bloggers.com/2014/09/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/">MOOC videos</a> and a 2nd edition coming soon, all
free online. Is there a better intro? Maybe using Python?</p>
<p><a href="https://www.manning.com/books/deep-learning-with-python">Deep Learning with Python</a>: The creator of <a href="https://keras.io/">Keras</a> provides
pretty good explanations and code, as I recall. Is there a better
intro? Maybe something using <a href="https://pytorch.org/">PyTorch</a>?</p>
<p><a href="/20210508-statistical_rethinking_by_mcelreath/">Statistical Rethinking</a> has great explanations, examples, and
philosophical commentary for understanding Bayesian approaches.</p>
<p><a href="http://www.mmds.org/">Mining of Massive Datasets</a> is much better than its cover, with
good coverage of both more and less commonly discussed techniques (and
a <a href="https://online.stanford.edu/courses/soe-ycs0007-mining-massive-data-sets">MOOC</a>).</p>
<hr>
<h3>See also:</h3>
<ul>
<li>William Chen's <a href="http://www.wzchen.com/data-science-books">22 Free Data Science Books</a> includes three of my
   four selections.</li>
<li>My <a href="/20160320-books_for_professionals/">Books for Professionals</a> selects four titles on professional
   life.</li>
<li>My <a href="/20160322-books_for_programmers/">Books for Programmers</a> recommends for Python, JavaScript,
   Clojure, R, and git.</li>
</ul>
<hr>
<p>Thanks to a couple of colleagues who inspired this collection of
recommended books!</p>
<p>What else would you add/change in this list?</p>    
    ]]></description>
<link>http://planspace.org/20210721-books_for_machine_learning/</link>
<guid>http://planspace.org/20210721-books_for_machine_learning/</guid>
<pubDate>Wed, 21 Jul 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Wise Charlie Mental Models (cards)</title>
<description><![CDATA[

<p>These <a href="https://www.wisecharlie.com/shop">100 cards</a> are kind of cute. They summarize mental models in
the style of <a href="https://en.wikipedia.org/wiki/Charlie_Munger#%22Elementary,_worldly_wisdom%22">Charlie Munger</a>; some are distinct Munger-isms. The
descriptions aren't terribly good and there are errors. I like the
<a href="https://fs.blog/mental-models/">general idea</a>, and I like cards; these are mediocre but not bad.</p>
<p><img alt="image" src="image.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20210527-wise_charlie_mental_models/</link>
<guid>http://planspace.org/20210527-wise_charlie_mental_models/</guid>
<pubDate>Thu, 27 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>The End of Everything, by Mack</title>
<description><![CDATA[

<p>Here's a fun <a href="http://www.astrokatie.com/book">book</a> by a millennial astrophysicist. I hadn't thought
about a big bang with an infinite universe before; that's fun. I would
have enjoyed more on how we know we're in a false vacuum and how fast
everything has moved over time, but it's a light pop book.</p>
<p>Ways for the universe to end:</p>
<ul>
<li>Big Crunch (gravity crushes us)</li>
<li>Heat Death (best guess; things get cold and lonely)</li>
<li>Big Rip (things eventually spread out explosively, on local scales)</li>
<li>Vacuum Decay (suddenly ice-9 but for everything)</li>
<li>Bounce (maybe we hit another 3-brane or something?)</li>
</ul>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"I knew I would only ever really be able to accept the kind of truth
I could rederive mathematically." (page 4)</p>
</blockquote>
<p>If this is the standard, you will only accept mathematical truths. The
book seems to care quite a bit about observation and measurement, so I
assume she's being rather loose with language here.</p>
<hr>
<blockquote>
<p>"Translating redshifts to speeds, the pattern Hubble detected meant
that the more distant a galaxy, the faster it's receding from us."
(page 57)</p>
</blockquote>
<p>As explained in the book, it seems like this could be read "the faster
it <em>was</em> receding from us" because light from far away is quite old. I
didn't catch it if there was an explanation of how we work out how
fast we think those distant things are moving away now.</p>
<p>This is particularly perplexing because the book explains that it
looks like (by redshift) very distant things are receding fastest,
less distant things look to be receding less fast, and the nearest
things look to be coming toward us. So my naive thought is: How do we
know that the distant things aren't currently coming toward us now?</p>
<p>There is presumably some clever way to work this out?</p>
<blockquote>
<p>"We glossed over this a bit in the previous chapter, but it turns
out that even just determining the past expansion rate is far more
difficult than it seems like it has any right to be." (page 115)</p>
</blockquote>
<p>That introduces the <a href="https://en.wikipedia.org/wiki/Cosmic_distance_ladder">distance ladder</a>, but I think still doesn't
address the above.</p>
<hr>
<blockquote>
<p>"Just like a curved fiber-optic cable can make the light inside it
turn a corner, a massive object bending space can cause light to
curve around it." (page 68)</p>
</blockquote>
<p>It isn't quite "just like" that, I think... I mean, the trampoline
analogy isn't good either...</p>
<hr>
<blockquote>
<p>"Measuring <em>distance</em> accurately over billions of light-years,
however, is a lot harder [than measuring redshift]." (page 69)</p>
</blockquote>
<p>This, I think, is very true. What does distance even mean?</p>
<hr>
<p>The play <a href="https://en.wikipedia.org/wiki/Arcadia_(play)">Arcadia</a>, quoted in the epigraph of Chapter 4, seems neat.</p>
<hr>
<blockquote>
<p>"To throw some more terminology into the mix, an evolving (i.e.,
nonconstant) dark energy is often called <em>quintessence</em>, after the
"fifth element," a mysterious something-or-other that was popular to
philosophize about in the Middle Ages and is not really much more
precisely specified now." (page 80)</p>
</blockquote>
<p>Leeloo Dallas Multipass</p>
<hr>
<blockquote>
<p>"As of this writing, supernova measurements allow us to measure the
Hubble Constant to an accuracy of 2.4 percent."</p>
<p>"Which is weird, because the number we get totally disagrees with
the value of the exact same number we derive from looking at the
cosmic microwave background." (pages 125-126)</p>
</blockquote>
<hr>
<p>How does the data suggest that we're in a local minimum vacuum? How
can we tell that?</p>
<hr>
<blockquote>
<p>"This has led physicists to suggest solutions ranging from abstract
arguments aimed at narrowing down the total range of possible
universes to philosophical debates about how to make advances in
areas of theory in which experimental evidence may never appear."
(page 161)</p>
</blockquote>
<hr>
<p>The epigraph for Chapter 8 quotes Hozier's "<a href="https://www.youtube.com/watch?v=gXq_J29V5Io">No Plan</a>" but I prefer
their "<a href="https://www.youtube.com/watch?v=0C5IS21neGA">Nobody</a>." The drums are bananas.</p>
<hr>
<blockquote>
<p>""By thinking about the end of the universe, just like with its
beginning, you can sharpen your own thinking about what you think is
happening now, and how to extrapolate. I feel like extrapolations in
fundamental physics are essential," says Hiranya Peiris, a
cosmologist at University College London." (page 179)</p>
</blockquote>
<hr>
<blockquote>
<p>"But personally, I still feel there's a big difference, in some
emotional sense, between "we go on forever" and "we don't." Nima
Arkani-Hamed feels the same way. "At the absolute, absolute deepest
level ... whether or not people explicitly admit to thinking about
it or not (and if they don't they're all the poorer for it) ... If
you think there is a purpose to life, then I at least don't know how
to find one that doesn't connect to something that transcends our
little mortality," he tells me. "I think a lot of people at some
level—again, either explicitly or implicitly—will do science or art
or something because of the sense that you do get to transcend
something. You touch something eternal. That word, eternal: very
important. It's very, very, very important."" (page 207)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210508-the_end_of_everything_by_mack/</link>
<guid>http://planspace.org/20210508-the_end_of_everything_by_mack/</guid>
<pubDate>Sat, 08 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Statistical Rethinking, by McElreath</title>
<description><![CDATA[

<p>I was fortunate to read this <a href="https://xcelab.net/rm/statistical-rethinking/">excellent book</a>. It's opinionated,
often quotable, and a fair summary is that "you can imagine your own
generative process, simulate data from it, write the model, and verify
that it recovers the true parameter values. You don't have to wait for
a mathematician to legalize the model you need." (page 376)
Recommended.</p>
<blockquote>
<p>"Thinking generatively—how the data could arise—solves many
problems. Many statistical problems cannot be solved with
statistics. All variables are measured with error. Conditioning on
variables creates as many problems as it solves. There is no
inference without assumption, but do not choose your assumptions for
the sake of inference. Build complex models one piece at a time. Be
critical. Be kind." (page 553)</p>
</blockquote>
<p>Notes by chapter:</p>
<ol>
<li><a href="#ch1">The Golem of Prague</a> (statistics, models, science)</li>
<li><a href="#ch2">Small Worlds and Large Worlds</a> (Bayes' theorem)</li>
<li><a href="#ch3">Sampling the Imaginary</a> (priors and posteriors)</li>
<li><a href="#ch4">Geocentric Models</a> (linear regression)</li>
<li><a href="#ch5">The Many Variables &amp; The Spurious Waffles</a></li>
<li><a href="#ch6">The Haunted DAG &amp; The Causal Terror</a></li>
<li><a href="#ch7">Ulysses' Compass</a> (overfitting)</li>
<li><a href="#ch8">Conditional Manatees</a> (interactions)</li>
<li><a href="#ch9">Markov Chain Monte Carlo</a></li>
<li><a href="#ch10">Big Entropy and the Generalized Linear Model</a></li>
<li><a href="#ch11">God Spiked the Integers</a> (GLMs for counts)</li>
<li><a href="#ch12">Monsters and Mixtures</a> (over-dispersion, ordered categories)</li>
<li><a href="#ch13">Models with Memory</a> (varying effects)</li>
<li><a href="#ch14">Adventures in Covariance</a></li>
<li><a href="#ch15">Missing Data and Other Opportunities</a></li>
<li><a href="#ch16">Generalized Linear Madness</a> (beyond GLMs)</li>
<li><a href="#ch17">Horoscopes</a> (conclusion)</li>
</ol>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<h3><a name="ch1" href="#ch1">Chapter 1: The Golem of Prague</a></h3>
<p>statistics, models, science</p>
<hr>
<blockquote>
<p>"What researchers need is some unified theory of golem engineering,
a set of principles for designing, building, and refining
special-purpose statistical procedures. Every major branch of
statistical philosophy possesses such a unified theory. But the
theory is never taught in introductory—and often not even in
advanced—courses. So there are benefits in rethinking statistical
inference as a set of strategies, instead of a set of pre-made
tools." (page 4)</p>
</blockquote>
<hr>
<p>I think there's a little bit of linguistic confusion between
scientific hypotheses ("I think the world works like...") and
statistical hypotheses (also called "Statistical models" in Figure
1.2).</p>
<hr>
<blockquote>
<p>"... deductive falsification never works." (page 4)</p>
</blockquote>
<p>I think this is too strong.</p>
<hr>
<blockquote>
<p>"<em>modus tollens</em>, which is Latin shorthand for “the method of
destruction.”" (page 7)</p>
</blockquote>
<hr>
<p>also: importance of <em>measurement</em></p>
<hr>
<p>He has some neat examples of evidence that's not trivial to infer
from - whether the ivory-billed woodpecker was extinct, and
faster-than-light neutrinos... To these, also add the Piltdown Man
fraud.</p>
<hr>
<h3><a name="ch2" href="#ch2">Chapter 2: Small Worlds and Large Worlds</a></h3>
<p>Bayes' theorem</p>
<hr>
<p>Neat counting example in 2.1! I tried to write up
<a href="/2013/11/11/whats-the-difference-between-bayesian-and-non-bayesian-statistics/">a similar example</a> (inspired by <a href="http://www.stat.columbia.edu/~gelman/book/">Gelman</a>) some years ago...</p>
<hr>
<p>In note 41, from page 24, McElreath advocates <a href="https://en.wikipedia.org/wiki/Cox%27s_theorem">Cox</a>-style
probability.</p>
<hr>
<p>I also wrote up (still years ago) a <a href="/2014/02/23/bayes-rule-for-ducks/">cute example</a> trying to explain
Bayes' rule, but I think it's pretty crummy relative to his
development through sections 2.1.2 and 2.1.3.</p>
<hr>
<p>I kind of miss seeing "evidence" in Bayes' rule... Maybe I like this,
with "explanation" for the other term?</p>
<pre><code>P(explanation|evidence) = P(evidence|explanation) * P(explanation)
                          ----------------------------------------
                                        P(evidence)</code></pre>

<p>(The P's everywhere would kind of obfuscate the nice counting
development he was using, but still...)</p>
<p>Then, note that <code>P(evidence|explanation)</code> is the "likelihood" of the
evidence, and that we're going to talk about that a lot.</p>
<hr>
<p>Ah, here on page 37 is his version:</p>
<pre><code>Posterior = Probability of the data * Prior
            -------------------------------
            Average probability of the data</code></pre>

<p>Also nice! He reminds me that I'm using "evidence" (above) in a
different way from using it to mean the denominator there...</p>
<p>There's also the way of doing it that's more like this:</p>
<pre><code>Posterior =     Probability of the data     * Prior
            -------------------------------
            Average probability of the data</code></pre>

<p>And then we can talk about the first term as the likelihood ratio,
which is kind of nice, but makes it less clear that the denominator is
a normalizer that can often be mostly ignored...</p>
<p>Likelihood ratio is a nice thing to think about, especially in
connection with Polya's "plausible reasoning"... Evidence that is
<em>only</em> consistent with the explanation (and no other) increases
confidence a lot.</p>
<p>There's also a nice connection to the error mode of getting the
denominator wrong and jumping to conclusions when you don't know of
another possible explanation. "I didn't think you were planning a
surprise party!" etc.</p>
<p>I don't really like "average probability of the data" as a term, I
think...</p>
<hr>
<p>On page 39, he doesn't include Hamiltonian Monte Carlo as one of the
"engines"... Is it a type of MCMC? Ah, <a href="https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo">yes</a>.</p>
<hr>
<p>Oh no! Very ugly page break from 42 to 43, with the header of a table
separated from its contents...</p>
<hr>
<p>Interesting; really not explaining what's going on with <code>dbeta</code>,
conjugate priors, etc... Probably fine?</p>
<hr>
<p>Wow! I do not understand how this Metropolis algorithm on page 45
works! I guess I can wait until Chapter 9.</p>
<hr>
<p>Ooh fun, some people have problem solutions online... Here's one:</p>
<ul>
<li>https://github.com/cavaunpeu/statistical-rethinking</li>
</ul>
<hr>
<h3><a name="ch3" href="#ch3">Chapter 3: Sampling the Imaginary</a></h3>
<p>priors and posteriors</p>
<hr>
<p>I'm reading Ellenberg's <a href="/20200925-how_not_to_be_wrong_by_ellenberg/">How Not to Be Wrong</a>, and he says on page
49: "In mathematics, you very seldom get the clearest account of an
idea from the person who invented it."</p>
<p>I have that feeling in connection with Gelman and Pearl (not sure they
completely invented things they're associated with, but still): I feel
like McElreath is doing a better job of explaining things, and it's
super nice.</p>
<p>Also Ellenberg:</p>
<blockquote>
<p>"If a tiny state like South Dakota experiences a rash of brain
cancer, you might presume that the spike is in large measure due to
luck, and you might estimate that the rate of brain cancer in the
future is likely to be closer to the overall national number. You
could accomplish this by taking some kind of weighted average of the
South Dakota rate with the national rate. But how to weight the two
numbers? That's a bit of an art, involving a fair amount of
technical labor I'll spare you here." (pages 70-71)</p>
</blockquote>
<p>I think he's referring to <a href="https://en.wikipedia.org/wiki/Multilevel_model">multi-level modeling</a>, in the Gelman
style.</p>
<hr>
<p>This common medical testing scenario appeared in a recent
LearnedLeague one-day on statistics:</p>
<blockquote>
<p>"Suppose that 1% of a population has a particular genetic mutation,
and a test for the mutation is 99% accurate for both positive and
negative cases. In other words, if someone with the mutation takes
the test, there is a 99% chance that the test comes back positive;
if someone without the mutation takes the test, there is a 99%
chance that the test comes back negative. If a randomly-selected
person takes the test and gets a positive result, what is the
probability that the person actually has the mutation? (Express your
answer as a fraction in lowest terms.)"</p>
</blockquote>
<p>I solved it by seeing that 0.01 * 0.99 == 0.99 * 0.01, which is sort
of like what McElreath says is called "frequency format" or "natural
frequencies." I definitely thought of it in terms of "quantity," but
as percentages rather than counts. I was surprised when Erica referred
to the problem as "the Bayesian" problem, because I hadn't thought of
it that way. So I agree with McElreath that it isn't uniquely Bayesian.</p>
<hr>
<blockquote>
<p>"Changing the representation of a problem often makes it easier to
address or inspires new ideas that were not available in an old
representation. In physics, switching between Newtonian and
Lagrangian mechanics can make problems much easier. In evolutionary
biology, switching between inclusive fitness and multilevel
selection sheds new light on old models. And in statistics,
switching between Bayesian and non-Bayesian representations often
teaches us new things about both approaches." (page 50)</p>
</blockquote>
<hr>
<blockquote>
<p>"I avoid discussing the analytical approach
[of conjugate priors, etc.] in this book, because very few problems
are so simple that they have exact analytical solutions like this
[the beta-binomial conjugate prior]." (page 560, note for page 51)</p>
</blockquote>
<hr>
<p>The "Why statistics can't save bad science" box on page 51 is neat.</p>
<hr>
<p>Just to establish equivalence between R and Python...</p>
<pre><code class="language-r">dbinom(6, size=9, prob=0.5)
## [1] 0.1640625</code></pre>

<pre><code class="language-python">import scipy.stats
scipy.stats.binom(n=9, p=0.5).pmf(6)
## 0.16406250000000006</code></pre>

<hr>
<p>Interesting: using "compatibility interval" rather than "credible
interval" (or "confidence interval") in the sense of "compatible with
the model and data." (page 54)</p>
<hr>
<blockquote>
<p>"Overall, if the choice of interval type
[percent interval or highest posterior density interval] makes a big
difference, then you shouldn't be using intervals to summarize the
posterior." (page 58)</p>
</blockquote>
<hr>
<blockquote>
<p>"There is no way to really be sure that software works correctly."
(page 64)</p>
</blockquote>
<hr>
<p>Hmm; his HPDI (Highest Posterior Density Interval) <a href="https://github.com/rmcelreath/rethinking/blob/3b48ec8dfda4840b9dce096d0cb9406589ef7923/R/utilities.r#L106">implementation</a>
itself relies on the implementation in <a href="https://cran.r-project.org/package=coda">coda</a>...</p>
<p>How hard is this really to implement? If you have a histogram or just
sorted counts, every left point determines one interval, so you could
do it in one pass with a little farting around to find the right point
each time, and a running smallest interval... Really not so
computation-intensive.</p>
<hr>
<pre><code class="language-r">birth1 &lt;- c(1,0,0,0,1,1,0,1,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,
0,0,0,1,1,1,0,1,0,1,1,1,0,1,0,1,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,
1,1,0,1,0,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,0,1,1,0,
1,0,1,1,1,0,1,1,1,1)
birth2 &lt;- c(0,1,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,0,
1,1,1,0,1,1,1,0,1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,
1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,1,1,
0,0,0,1,1,1,0,0,0,0)
table(birth1, birth2)
##        birth2
##  birth1  0  1
##       0 10 39
##       1 30 21</code></pre>

<p>So really, what <em>is</em> up with this data?</p>
<hr>
<h3><a name="ch4" href="#ch4">Chapter 4: </a></h3>
<p>linear regression</p>
<hr>
<blockquote>
<p>"Linear regression is the geocentric model of applied statistics."
(page 71)</p>
</blockquote>
<hr>
<p>Frank's <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1420-9101.2009.01775.x">The common patterns of nature</a> seems pretty neat, getting
into how common distributions come from processes and information
considerations...</p>
<hr>
<blockquote>
<p>"Multiplying small numbers is approximately the same as addition."
(page 74)</p>
</blockquote>
<hr>
<p>On page 76 he shows "precision" as τ, meaning 1/σ^2, and it shows up
in the equation for the Gaussian with π, which is an example of
notation that doesn't work particularly well with
<a href="https://tauday.com/">the tau manifesto</a>.</p>
<hr>
<p>"procrustean" (on page 77): "(especially of a framework or system)
enforcing uniformity or conformity without regard to natural variation
or individuality."</p>
<hr>
<p>I like the <a href="https://en.wikipedia.org/wiki/Sparkline">spark</a> histograms!</p>
<p>Oh, neat, they're even <a href="https://github.com/rmcelreath/rethinking/blob/f9c16bb7faec8a9883d976a769824b1764d12540/R/precis.r#L72">called</a> "histosparks"...</p>
<p>And I might have guessed... they're <a href="https://rdrr.io/github/hadley/precis/src/R/histospark.R">from</a> Hadley.</p>
<p>So there are unicode characters that do blocks of various sizes, by
eighths... It looks like Hadley only uses some of them:</p>
<pre><code class="language-r">sparks &lt;- c("\u2581", "\u2582", "\u2583", "\u2585", "\u2587")
#             1/8       2/8       3/8       5/8       7/8</code></pre>

<p>Can look these up for example here: https://www.fileformat.info/info/unicode/char/2581/index.htm</p>
<p>" ▁▂▃▄▅▆▇█" has all the heights, with a normal blank at the beginning.</p>
<p>So why does Hadley only use some of the available heights? Not sure.</p>
<p>Oh look at that! In my terminal those all look fine, but in a browser (maybe it depends on font?) the half and full blocks go lower than the others! Still doesn't explain why 6/8 is missing from Hadley's list... Maybe it looks bad in other fonts?</p>
<p>Let's try it fixed-width:</p>
<pre><code> ▁▂▃▄▅▆▇█</code></pre>

<p>Yup, looks much nicer in fixed width.</p>
<p>Here's another nice place to see these: https://en.wikipedia.org/wiki/Block_Elements</p>
<hr>
<blockquote>
<p>"E. T. Jaynes (1922-1988) called this the <em>mind projection fallacy</em>,
the mistake of confusing epistemological claims with ontological
claims." (page 81)</p>
</blockquote>
<p>And a fun reference to <a href="https://bayes.wustl.edu/etj/articles/cmonkeys.pdf">Monkeys, Kangaroos, and N</a>:</p>
<blockquote>
<p>"... I think you will find that 90% of the past confusions and
controversies in statistics have been caused, not by mathematical
errors or even ideological differences; but by the technical
difficulty that the two parties had different problems in mind, and
failed to realize this. Thinking along different lines, each failed
to perceive at all what the other considered too obvious to
mention." (Jaynes)</p>
</blockquote>
<hr>
<blockquote>
<p>"There's also a tradition called <em>dimensionless analysis</em> that
advocates constructing variables so that they are unit-less ratios."
(page 94)</p>
</blockquote>
<p>I haven't heard about this as such, I think. Dimension_al_ analysis is
more well known, but not quite the same thing...</p>
<hr>
<p>Interesting to recall that in the first edition, what's now called
<code>quap</code> (quadratic approximation posterior / a posteriori?) was called
<code>map</code> (maximum a posteriori?)</p>
<hr>
<blockquote>
<p>"My experience is that many natural and social scientists have
naturally forgotten whatever they once knew about logarithms." (page
98)</p>
</blockquote>
<hr>
<blockquote>
<p>"... most social and natural scientists have never had much training
in probability theory and tend to get very nervous around ∫'s."
(page 106)</p>
</blockquote>
<hr>
<p>He repeats it in different ways here and there, but I noted it again
on page 107: I like his effort at clarity between "small world" and
"large world" claims, where small world is "assuming the model" or "in
the world of the model."</p>
<hr>
<p>When doing the quadratic example, he z-scores but does not
decorrelate... The default behavior in R (using <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/poly">poly</a>) is to
"compute orthogonal polynomials"... I'm not sure how common that is
elsewhere.</p>
<p>Okay I'll look at sklearn... Here's somebody with a nice Python
implementation:
http://davmre.github.io/blog/python/2013/12/15/orthogonal_poly But as
far as I can tell there isn't anything "built in" for Python...</p>
<hr>
<p>page 111: <code>weight.s</code> is used in one listing, while <code>weight_s</code> is used
in another, which is a very mild kind of inconsistency. (<a href="https://github.com/rmcelreath/rethinking/pull/279">PR</a>)</p>
<hr>
<blockquote>
<p>"We should feel embarrassed to use [linear models], just so we don't
become satisfied with the phenomenological explanations they
provide." (page 113)</p>
</blockquote>
<hr>
<p>I really liked section 4.5.2 on splines; I don't think I ever saw a
good explanation of splines before.</p>
<hr>
<blockquote>
<p>"Matrix algebra is a stressful topic for many scientists." (page 119)</p>
</blockquote>
<hr>
<p>In both R listings 4.76 and 4.79, it's a little unintuitive to me in
that it doesn't seem obvious that <code>w</code> is a vector. In <code>w ~ dnorm(0,
10)</code>, that <code>dnorm</code> returns just one number. Somewhere <code>quap</code> is
figuring out how many elements it needs, I guess?</p>
<hr>
<p>For question 4H8 on page 122, it asks what else would have to change
if the intercept was removed from the model. I think the answer is
just the priors on the other coefficient(s), since they'd have to get
the mean all the way to where it needs to be by themselves then.
And/or maybe the data couldn't be centered, because making the mean
zero would really hurt the ability to have the result be right? It
would still be okay if both x and y were centered, at least for simple
designs.</p>
<hr>
<h3><a name="ch5" href="#ch5">Chapter 5: The Many Variables &amp; The Spurious Waffles</a></h3>
<hr>
<blockquote>
<p>"... introduce graphical causal models as a way to design and
interpret regression models." (page 124)</p>
</blockquote>
<hr>
<blockquote>
<p>"About one thing, however, there is general agreement: Causal
inference always depends upon unverifiable assumptions." (page 124)</p>
</blockquote>
<hr>
<blockquote>
<p>"Think before you regress" (page 128)</p>
</blockquote>
<p>In the first paragraph of 5.1.1, I don't really see how Figure 5.2
tells us that only one of the predictor variables has a causal
influence...</p>
<hr>
<p>I really like <a href="http://www.dagitty.net/">dagitty</a>. Learning about it is one of the best things
in the book, in that I was wishing to find such software while reading
<a href="https://planspace.org/20200917-book_of_why/">The Book of Why</a> but didn't.</p>
<p>It is a little weird that the web interface uses ⊥ (falsum)... Hmm;
<a href="https://en.wikipedia.org/wiki/Up_tack">looking it up</a>, it seems it's the same symbol as <code>\perp</code>, which is
used for independence. Ah! The "double tack up" (⫫) is for conditional
independence! The web interface still uses ⊥ for both kinds of
independence.</p>
<hr>
<blockquote>
<p>"This is very weird notation and any feelings of annoyance on your
part are justified." (page 130)</p>
</blockquote>
<hr>
<p>The <code>coeftab</code> visualization (see page 133) is pretty nice.</p>
<hr>
<p>It took me a little bit to understand what he was getting at with the
"predictor residual plots" (page 135) but I'm glad I did, since it
connects to one of his main points about how multiple regression is
about how much a variable adds given all the other variables.</p>
<hr>
<blockquote>
<p>"Usually answers to large world questions about truth and causation
depend upon information not included in the model." (page 139)</p>
</blockquote>
<hr>
<p>The section 5.2 "Masked relationship" is neat.</p>
<hr>
<blockquote>
<p>"Taking the log of a measure translates the measure into
magnitudes." (page 148)</p>
</blockquote>
<p>What use of "magnitude" is this? Hmm... Looks like star brightness is
done via a log that is called magnitude... Just weird, because in
other domains "magnitude" refers to the <em>un</em>-logged value...</p>
<p>Seems like this is less surprising to others, and it makes sense as "<em>order of</em> magnitude."</p>
<hr>
<blockquote>
<p>"A set of DAGs with the same conditional independencies is known as
a Markov equivalence set." (page 151)</p>
</blockquote>
<hr>
<p>I was unfamiliar with <a href="https://en.wikipedia.org/wiki/Melanesia">Melanesia</a>.</p>
<hr>
<p>One page 155, he makes index variables seem fundamentally different
from indicator variables. Their notation in <code>quap</code> is different (and
nicer) but fundamentally the only difference is with index variables
you drop the intercept term (or equivalently, you have separate
intercept terms for each thing). Just reading through, I initially
thought his index variables were a real novelty, but they're not. (I'm
still curious about where he says on page 156 "It is also important to
get used to index variables, because multilevel models (Chapter 13)
depend upon them.")</p>
<hr>
<blockquote>
<p>"The mistake of accepting the null hypothesis." (page 158)</p>
</blockquote>
<hr>
<p>Question 5E3 on page 159 jokes (I think?) about the effects of amount
of funding and size of laboratory on time to PhD, but I'm not sure I
know what he thinks is funny...</p>
<hr>
<h3><a name="ch6" href="#ch6">Chapter 6: The Haunted DAG &amp; The Causal Terror</a></h3>
<hr>
<p>On page 161 he starts with Berkson's Paradox, suggesting
"selection-distortion effect" as a better name. Dave suggested a nice
example: shorter basketball players in the NBA are better 3 point
shooters.</p>
<hr>
<blockquote>
<p>"Let's bein with the least of your worries: multicollinearity."
(page 163)</p>
</blockquote>
<p>This can "smear out" your estimates, because it isn't clear which
variables to put beta weight on.</p>
<hr>
<p>Section 6.2 (page 170) uses "post-treatment bias" to refer to what I
might call a mediator, and what he later calls a "pipe" situation
(page 185).</p>
<hr>
<blockquote>
<p>"The "d" [in d-separation] stands for <em>directional</em>." (page 174)</p>
<p>"You'll often see the "d" in d-separation defined as "dependency."
That would certainly make more sense. But the term d-separation
comes from a more general theory of graphs. Directed graphs involve
d-separation and undirected graphs involve instead u-separation."
(page 563)</p>
</blockquote>
<hr>
<blockquote>
<p>"No statistical procedure can substitute for scientific knowledge
and attention to it." (page 175)</p>
</blockquote>
<hr>
<blockquote>
<p>"If a procedure cannot figure out the truth in a simulated example,
we shouldn't trust it in a real one." (page 177)</p>
</blockquote>
<hr>
<blockquote>
<p>"So I'm sorry to say that we also have to consider the possibility
that our DAG may be haunted." (page 180)</p>
</blockquote>
<p>The thing haunting it (as in the title of the chapter) is unmeasured
causes that induce collider bias, which means conditioning on things
we have can induce bias about effects we're trying to measure.</p>
<hr>
<p>I like "the four elemental confounds" on page 185. They're pretty
similar to the cases I included in
<a href="https://planspace.org/20200912-what_should_be_in_your_regression/">What should be in your regression?</a>.</p>
<hr>
<p>The explanation of shutting the back-door on pages 184-185 is better
than others I've seen, I think. And then on page 186 he shows how
everybody's favorite <a href="http://www.dagitty.net/">dagitty</a> can do it automatically.</p>
<p>Front-door isn't mentioned until page 460.</p>
<hr>
<p>On page 186, he says "Conditioning on C is the better idea, from the
perspective of efficiency, since it could also help with the precision
of the estimate of X➔Y." This seems reasonable since C is closer to Y,
but I feel like a little more explanation wouldn't have been a bad
thing here.</p>
<hr>
<blockquote>
<p>"In fact, domain specific structural causal models can make causal
inference possible even when a DAG with the same structure cannot
decide how to proceed." (page 188)</p>
</blockquote>
<p>Say more? Like, a footnote? An endnote? Some kind of reference to more
information? Seems so mysterious!</p>
<hr>
<blockquote>
<p>"Sometimes, in order to avoid multicollinearity, people inspect
pairwise correlations among predictors before including them in a
model. This is a bad procedure, because what matters it the
conditional association, not the association before the variables
are included in the model." (page 189)</p>
</blockquote>
<hr>
<h3><a name="ch7" href="#ch7">Chapter 7: Ulysses' Compass</a></h3>
<p>overfitting</p>
<hr>
<ul>
<li>7.1. The problem with parameters</li>
<li>7.2. Entropy and accuracy</li>
<li>7.3. Golem taming: regularization</li>
<li>7.4. Predicting predictive accuracy</li>
<li>7.5. Model comparison</li>
</ul>
<hr>
<p>McElreath has slides and video of his lectures <a href="https://github.com/rmcelreath/statrethinking_winter2019">online</a>.</p>
<hr>
<blockquote>
<p>"This chapter describes some of the most commonly used tools for
coping with this trade-off." (page 191, referring to the trade-off
between simplicity and accuracy)</p>
</blockquote>
<p>There's some parallel between statistical models and scientific models
generally; see <a href="https://planspace.org/20170825-characteristics_of_good_theories/">Characteristics of good theories</a>.</p>
<hr>
<blockquote>
<p>"... when we design any particular statistical model, we must decide
whether we want to understand causes or rather just predict." (page
192)</p>
</blockquote>
<hr>
<p>"Stargazing" is a cute way to criticize fixation on stars that
represent statistical significance. (page 193)</p>
<hr>
<p>On page 194 he uses "hominin" which I wasn't familiar with. Hominins
refers to humans and chimps. Add gorillas and you get hominines. Add
orangutans to that and you get hominids.</p>
<hr>
<blockquote>
<p>"In fact, Carl Friedrich Gauss originally derived the OLS procedure
in a Bayesian framework." (page 196)</p>
</blockquote>
<p>He loves pointing out this kind of thing.</p>
<hr>
<blockquote>
<p>"The point of this example is not to praise R<sup>2</sup> but to
bury it." (page 197)</p>
</blockquote>
<p>This alludes to Shakespeare's famous Marc Antony speech in Julius
Caesar: "I come to bury Caesar, not to praise him."</p>
<hr>
<blockquote>
<p>"This means the <em>actual</em> empirical variance, not the variance that R
returns with the <code>var</code> function, which is a frequentist estimator
and therefore has the wrong denominator." (page 197)</p>
</blockquote>
<p>Saucy!</p>
<hr>
<blockquote>
<p>"... model fitting can be considered a form of data compression. ...
This view of model selection is often known as minimum description
length (MDL)." (page 201)</p>
</blockquote>
<p>Wikipedia <a href="https://en.wikipedia.org/wiki/Minimum_description_length">says</a> "In its most basic form, MDL is a model selection
principle: the shortest description of the data as the best model."</p>
<p>McElreath points to <a href="https://homepages.cwi.nl/~pdg/publicationpage.html">Grünwald's</a> The Minimum Description Length
Principle.</p>
<hr>
<p>He's trying to develop "out-of-sample deviance" in 7.2 "Entropy and
accuracy" starting page 202.</p>
<hr>
<p>"Likelihood" as in the likelihood of the data, given the model, on
page 204. And he <em>really</em> likes it:</p>
<blockquote>
<p>"If you see an analysis using something else, either it is a special
case of the log scoring rule or it is possibly much worse."</p>
</blockquote>
<hr>
<p>Interesting "Rethinking" box on page 204:</p>
<blockquote>
<p>"Calibration is overrated. ... The problem is that calibrated
predictions do not have to be good."</p>
</blockquote>
<p>It has an endnote on page 563 that includes:</p>
<blockquote>
<p>"Strictly speaking, there are no "true" probabilities of events,
because probability is epistemological and nature is deterministic."</p>
</blockquote>
<hr>
<p>On page 207 he points out that when probability is zero, L'Hopital's
rule gives us 0*log(0) = 0.</p>
<hr>
<p>Endnote 110 on page 564 begins:</p>
<blockquote>
<p>"I really wish I could say there is an accessible introduction to
maximum entropy, at the level of most natural and social scientists'
math training. If there is, I haven't found it yet."</p>
</blockquote>
<p>On page 207 he just says:</p>
<blockquote>
<p>"So Bayesian updating is entropy maximization."</p>
</blockquote>
<hr>
<p>He just says "divergence" to mean Kullback-Leibler divergence, and
adds in endnote 111 on page 564:</p>
<blockquote>
<p>"For what it's worth, Kullback and Leibler make it clear in their
1951 paper that Harold Jeffreys had used this measure already in the
development of Bayesian statistics."</p>
</blockquote>
<p>There he goes again!</p>
<hr>
<blockquote>
<p>"In plainer language, the divergence is <em>the average difference in
log probability between the target (p) and model (q)</em>. This
divergence is just the difference between two entropies: The entropy
of the target distribution <em>p</em> and the <em>cross entropy</em> arising from
using <em>q</em> to predict <em>p</em>."</p>
</blockquote>
<hr>
<blockquote>
<p>"At this point in the chapter, dear reader, you may be wondering
where the chapter is headed." (page 209)</p>
</blockquote>
<hr>
<blockquote>
<p>"It's as if we can't tell how far any particular archer is from
hitting the target, but we can tell which archer gets closer and by
how much." (page 209)</p>
</blockquote>
<hr>
<blockquote>
<p>"To compute this [log-probability] score for a Bayesian model, we
have to use the entire posterior distribution. Otherwise, vengeful
angels will descend upon you." (page 210)</p>
</blockquote>
<p>His package has <code>lppd</code> for "log-pointwise-predictive-density."</p>
<blockquote>
<p>"It is also quite common to see something called the deviance, which
is like a lppd score, but multiplied by -2 so that smaller values
are better. The 2 is there for historical reasons."</p>
</blockquote>
<p>There's more explanation in endnote 112 on page 564:</p>
<blockquote>
<p>"In non-Bayesian statistics, under somewhat general conditions, a
difference between two deviances has a chi-squared distribution. The
factor of 2 is there to scale it the proper way."</p>
</blockquote>
<p>(Recall we're interested in the difference between these things; they
don't have a meaningful scale on their own.)</p>
<hr>
<p>I was briefly befuddled by the positive log-likelihoods on page 210,
but of course it's the point density, not probability, and the density
can be greater than one.</p>
<hr>
<p>On page 211 he talks about <code>log_sum_exp</code> which "takes all the
log-probabilities for a given observation, exponentiates each, sums
them, then takes the log. But it does this in a way that is
numerically stable."</p>
<p>I had cause to do this recently! It comes down to this:</p>
<pre><code class="language-python">import math

def sum_log_prob(a, b):
    return max(a, b) + math.log1p(math.exp(0 - abs(a - b)))</code></pre>

<p>I based that on a <a href="https://gasstationwithoutpumps.wordpress.com/2014/05/06/sum-of-probabilities-in-log-prob-space/">post from Kevin Karplus</a>.</p>
<p>McElreath's is:</p>
<pre><code class="language-r">log_sum_exp &lt;- function( x ) {
    xmax &lt;- max(x)
    xsum &lt;- sum( exp( x - xmax ) )
    xmax + log(xsum)
}</code></pre>

<p>(<a href="https://rdrr.io/github/rmcelreath/rethinking/src/R/distributions.r">Found</a> on rdrr.)</p>
<hr>
<blockquote>
<p>"That [two-parameter] model does worse in prediction than the model
with only 1 parameter, even though the true model does include the
additional predictor. This is because with only N=20 cases, the
imprecision of the estimate for the first predictor produces more
error than just ignoring it." (page 213)</p>
</blockquote>
<hr>
<blockquote>
<p>"When you encounter multilevel models in Chapter 13, you'll see that
their central device is to learn the strength of the prior from the
data itself. So you can think of multilevel models as adaptive
regularization, where the model itself tries to learn how skeptical
it should be." (page 216)</p>
</blockquote>
<hr>
<blockquote>
<p>"Statisticians often make fun of machine learning for reinventing
statistics under new names. But regularization is one area where
machine learning is more mature. Introductory machine learning
courses usually describe regularization. Most introductory
statistics courses do not." (page 216)</p>
</blockquote>
<hr>
<p>Section 7.4 (page 217) is "predicting predictive accuracy."</p>
<hr>
<blockquote>
<p>"It is a benign aspect of the universe that this importance
[of individual examples] can be estimated without refitting the
model." (page 217)</p>
</blockquote>
<hr>
<p>"PSIS" is "Pareto-smoothed importance sampling cross-validation."
(page 217)</p>
<hr>
<blockquote>
<p>"For ordinary linear regression with flat priors, the expected
overfitting penalty is about twice the number of parameters." (page
219)</p>
</blockquote>
<hr>
<blockquote>
<p>"AIC is of mainly historical interest now." (page 219)</p>
</blockquote>
<hr>
<p>It seems like WAIC can only be used when you have a posterior
distribution, since it relies on variance of those predictions...</p>
<hr>
<blockquote>
<p>"... in the natural and social sciences the models under
consideration are almost never the data-generating models. It makes
little sense to attempt to identify a "true" model." (page 221)</p>
</blockquote>
<hr>
<blockquote>
<p>"Watanabe recommends computing both WAIC and PSIS and contrasting
them. If there are large differences, this implies one or both
criteria are unreliable.</p>
<p>"Estimation aside, PSIS has a distinct advantage in warning the user
about when it is unreliable." (page 223)</p>
</blockquote>
<hr>
<blockquote>
<p>"A very common use of cross-validation and information criteria is
to perform model selection, which means choosing the model with the
lowest criterion value and then discarding the others. But you
should never do this." (page 225)</p>
</blockquote>
<hr>
<p>Endnote 133 references
<a href="https://www.fooledbyrandomness.com/violencenobelsymposium.pdf">The Decline of Violent Conflicts: What Do The Data Really Say?</a> which is interesting.</p>
<hr>
<blockquote>
<p>"This chapter has been a marathon." (page 235)</p>
</blockquote>
<p>And then the chapter summary doesn't even mention cross-validation!</p>
<hr>
<p>Acronyms:</p>
<ul>
<li>AIC: Akaike Information Criterion</li>
<li>BIC: Bayesian Information Criterion (aka Schwarz criterion)</li>
<li>CV: Cross-Validation</li>
<li>DIC: Deviance Information Criterion</li>
<li>D_{KL}(p, q): Kullback-Leibler divergence</li>
<li>E: Expectation</li>
<li>H(p): Entropy</li>
<li>H(p, q): Cross-entropy</li>
<li>lppd: Log Pointwise Predictive Density</li>
<li>MAP: Maximum A posteriori Probability (mode of posterior)</li>
<li>MDL: Minimum Description Length</li>
<li>N: sample size</li>
<li>PSIS: Pareto-smoothed importance sampling cross-validation</li>
<li>S(q): Sum of log probabilities</li>
<li>R^2: "variance explained" or "coefficient of determination"</li>
<li>WAIC: [Widely Applicable | Watanabe-Akaike] Information Criterion</li>
</ul>
<hr>
<p>Practice problem 7E1: State the three motivating criteria that define
information entropy.</p>
<ul>
<li>It should change smoothly with changes in the inputs.</li>
<li>When more things could happen, it should go up.</li>
<li>It should add, when you combine things.</li>
</ul>
<hr>
<p>Practice problem 7E2: Suppose a coin is weighted such that, when it is
tossed and lands on a table, it comes up heads 70% of the time. What
is the entropy of this coin?</p>
<p>Well, entropy is the negative sum of p*log(p), so:</p>
<pre><code class="language-python">import math

# Truth (as in Problem 7E1)
p = [0.7, 0.3]

# Entropy, H(p)
H = lambda p: -sum(p_i * math.log(p_i) for p_i in p)
H(p)  # 0.6108643020548935

# Candidate "models"
q = [0.5, 0.5]
r = [0.9, 0.1]

# Cross-Entropy, H(p, q), xH here because Python
xH = lambda p, q: -sum(p_i * math.log(q_i) for p_i, q_i in zip(p, q))
xH(p, q)  # 0.6931471805599453
xH(p, r)  # 0.764527888858692

# KL Divergence, D(p, q)
D = lambda p, q: sum(p_i * math.log(p_i/q_i) for p_i, q_i in zip(p, q))
D(p, q)  # 0.08228287850505178
D(p, r)  # 0.15366358680379852

# D(p, q) = H(p, q) - H(p)
D(p, q) == xH(p, q) - H(p)  # True

# We wish we could do this (use D) but we can't, because we don't have p.

# Data
d = [0, 0, 1]

# Log probability (likelihood) score
S = lambda d, p: sum(math.log(p[d_i]) for d_i in d)
S(d, q)  # -2.0794415416798357
S(d, r)  # -2.513306124309698

# True vs. predictive
S(d, p)  # -1.917322692203401
S(d, [2/3, 1/3])
         # -1.9095425048844388

# Deviance
deviance = lambda d, p: -2 * S(d, q)

# Positive log likelihoods! Gasp!

# Note the log probabilities here are really probabilities, because
# I'm just using point estimates, not real distributions. Really,
# you'll have densities, which can be greater than one.</code></pre>

<hr>
<blockquote>
<p>"Information criteria construct a theoretical estimate of the
relative out-of-sample KL divergence." (page 219)</p>
</blockquote>
<p>And he really likes them, largely forgetting about cross-validation.</p>
<hr>
<h3><a name="ch8" href="#ch8">Chapter 8: Conditional Manatees</a></h3>
<p>interactions</p>
<hr>
<p>Propeller marks on manatees are unpleasant, but DID YOU KNOW you see
those marks so much because they don't kill the manatees, so they're
still around to be seen? Manatees are mostly killed by blunt force
thwacking by the hulls of boats, not their propellers.</p>
<hr>
<blockquote>
<p>"Using GDP to measure the health of an economy is like using heat to
measure the quality of a chemical reaction." (endnote 138, page 565)</p>
</blockquote>
<hr>
<p>Why not split data to condition on some categorical variable? (page
241)</p>
<ul>
<li>For parameters that exist in both parts, "you are essentially
   making two less-accurate estimates instead of pooling all of the
   evidence".</li>
<li>"you can't easily quanitfy that uncertainty" (about "the predictive
   value of distinguishing" your parts)</li>
<li>It makes it hard to use information criteria (the comparison works
   best when the same data is in all the models under comparison)</li>
<li>Multilevel models don't split the data, and derive benefits in
   "borrowing information across categories".</li>
</ul>
<hr>
<p>On page 245, he explains (again?) that using indicator variables is
bad in the sense that it implies more uncertainty in the indicated
class (uncertainty of baseline, plus uncertainty of indicator's
coefficient).</p>
<hr>
<p>On using fancy Greek letters in your model specification:</p>
<blockquote>
<p>"If your reader cannot say the symbol's name, it could make
understanding the model harder." (page 249)</p>
</blockquote>
<hr>
<p>Section 8.2 (page 250) on "Symmetry of interactions" is pretty neat.</p>
<blockquote>
<p>"There is just no way to specify a simple, linear interaction in
which you can say the effect of some variable <em>x</em> depends upon <em>z</em>
but the effect of <em>z</em> does not depend upon <em>x</em>." (page 256)</p>
</blockquote>
<hr>
<p>In endnote 142, McElreath recommends Grafen and Hails'
<a href="https://smile.amazon.com/Statistics-STATISTICS-May-09-2002-MAY-09-2002-Hardcover/dp/B009CPMY4Y/">Modern Statistics for the Life Sciences</a>, saying "It has a rather
unique geometric presentation of some of the standard linear models."
The book has the somewhat surprising subtitle of "Learn to analyse
your own data".</p>
<hr>
<p><a href="https://en.wikipedia.org/wiki/Main_effect">Main effects</a> vs. interaction effects.</p>
<hr>
<p>On weakly informative priors:</p>
<blockquote>
<p>"If you displayed these priors to your colleagues, a reasonable
summary might be, "These priors contain no bias towards positive or
negative effects, and at the same time they very weakly bound the
effects to realistic ranges."" (page 260)</p>
</blockquote>
<hr>
<blockquote>
<p>"While you can't see them in a DAG, interactions can be important
for making accurate inferences." (page 260)</p>
</blockquote>
<hr>
<h3><a name="ch9" href="#ch9">Chapter 9: Markov Chain Monte Carlo</a></h3>
<hr>
<blockquote>
<p>"Researchers rely upon random numbers for the proper design of
experiments." (page 263)</p>
</blockquote>
<hr>
<p>In an endnote, McElreath recommends Kruschke's
<a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>, and it seems like it might be good.</p>
<hr>
<blockquote>
<p>"the combination of parameter values that maximizes posterior
probability, the mode, is not actually in a region of parameter
values that are highly plausible." (page 269)</p>
</blockquote>
<hr>
<blockquote>
<p>"we need MCMC algorithms that focus on the entire posterior at once,
instead of one or a few dimensions at a time like Metropolis and
Gibbs. Otherwise we get stuck in a narrow, highly curving region of
parameter space." (page 270)</p>
</blockquote>
<hr>
<blockquote>
<p>"It appears to be a quite general principle that, whenever there is
a randomized way of doing something, then there is a nonrandomized
way that delivers better performance but requires more thought."
(page 270, quoting E. T. Jaynes)</p>
</blockquote>
<hr>
<blockquote>
<p>"[The U-turn problem] just shows that the efficiency of HMC comes
with the expense of having to tune the leapfrog steps and step size
in each application." (page 274)</p>
</blockquote>
<hr>
<blockquote>
<p>"Fancy HMC samplers ... choose the leapfrog steps and step size for
you ... by conducting a warmup phase in which they try to figure out
which step size explores teh posterior efficiently. If you are
familiar with older algorithms like Gibbs sampling, which use a
burn-in phase, warmup is not like burn-in." (page 274)</p>
</blockquote>
<hr>
<h3><a name="ch10" href="#ch10">Chapter 10: Big Entropy and the Generalized Linear Model</a></h3>
<hr>
<blockquote>
<p>"Indeed, it may be that no one fully understands
[the principle of maximum entropy]." (page 303)</p>
</blockquote>
<hr>
<blockquote>
<p>"[The exponential] distribution is the core of survival and event
history analysis, which is not covered in this book." (page 315)</p>
</blockquote>
<hr>
<blockquote>
<p>"... no regression coefficient ... from a GLM every produces a
constant change on the outcome scale. ... every predictor
essentially interacts with itself, because the impact of a change in
a predictor depends upon the value of the predictor before the
change. More generally, every predictor variable effectively
interacts with every other predictor variable, whether you
explicitly model them as interactions or not." (page 318)</p>
</blockquote>
<hr>
<blockquote>
<p>"Link functions are assumptions." (page 319)</p>
</blockquote>
<p>He suggests sensitivity assumptions, presumably including trying
different link functions, which I think is the closest he comes to
talking about probit regression.</p>
<hr>
<blockquote>
<p>"... even a variable that isn't technically a confounder can bias
inference, once we have a link function." (page 320)</p>
</blockquote>
<hr>
<blockquote>
<p>"Parameter estimates do not by themselves tell you the importancce
of a predictor on the outcome." (page 320)</p>
</blockquote>
<hr>
<blockquote>
<p>"... a big beta-coefficient may not correspond to a big effect on
the outcome." (page 320)</p>
</blockquote>
<hr>
<p>He also points out on page 320 that with a different likelihood (and
so link) function, you can't compare log likelihoods (etc.) any more
because there's an (unknown) normalization constant that's different
between them.</p>
<hr>
<h3><a name="ch11" href="#ch11">Chapter 11: God Spiked the Integers</a></h3>
<p>GLMs for counts</p>
<hr>
<ul>
<li>
<ol>
<li>God spiked the integers</li>
<li>11.1. Binomial regression<ul>
<li>11.1.1. Logistic regression: Prosocial chimpanzees</li>
<li>11.1.2. Relative shark and absolute deer</li>
<li>11.1.3. Aggregated binomial: Chimpanzees again, condensed</li>
<li>11.1.4. Aggregated binomial: Graduate school admissions</li>
</ul>
</li>
<li>11.2. Poisson regression<ul>
<li>11.2.1. Example: Oceanic tool complexity</li>
<li>11.2.2. Negative binomial (gamma-Poisson) models</li>
</ul>
</li>
<li>11.3. Multinomial and categorical models<ul>
<li>11.3.1. Predictors matched to outcomes</li>
<li>11.3.2. Predictors matched to observations</li>
<li>11.3.3. Multinomial in disguise as Poisson</li>
</ul>
</li>
</ol>
</li>
</ul>
<hr>
<blockquote>
<p>"As described in Chapter 10, the Poisson model is a special case of
binomial." (page 323)</p>
</blockquote>
<p>This is a little loose, maybe; Poisson is the limit of binomial, which
isn't quite "a special case" I think...</p>
<p>Logistic regression as a special case of binomial regression, okay.</p>
<hr>
<blockquote>
<p>"There are many ways to construct new variables like this, including
mutant helper functions." (page 327)</p>
</blockquote>
<p>Mutant helper functions? Is this a common term?</p>
<hr>
<blockquote>
<p>"Let's look at these on the outcome scale:" (page 330)</p>
</blockquote>
<p>He shows a table that includes logistic regression coefficients, but
there's really no attempt to interpret them directly, which is
different from some presentations of logistic regression. He goes
directly to showing things on the probability scale. He does then show
some plots on the coefficient scale, and describes them as being "on
the logit scale," but still not a lot of effort spent on connecting
them to changes in odds etc.</p>
<hr>
<blockquote>
<p>"counting the rows in the data table is no longer a sensible way to
assess sample size." (page 340)</p>
</blockquote>
<p>(When using data that is counts of outcomes.)</p>
<hr>
<blockquote>
<p>"This isn't to say that over-parameterizing a model is always a good
idea. But it isn't a violation of any statistical principle." (page
345)</p>
</blockquote>
<hr>
<blockquote>
<p>"Keep in mind that the number of rows is not clearly the same as the
"sample size" in a count model. The relationship between parameters
and "degrees of freedom" is not simple, outside of simple linear
regressions." (page 347)</p>
</blockquote>
<hr>
<blockquote>
<p>"Any rules you've been taught about minimum sample sizes for
inference are just non-Bayesian superstitions." (page 347)</p>
</blockquote>
<hr>
<p>He really seems to want to make gamma-Poisson happen (replacing
negative binomial).</p>
<hr>
<p>Probit doesn't appear anywhere! (At least, I haven't seen it and it
isn't in the index.)</p>
<hr>
<blockquote>
<p>"In general, more than two things can happen." (page 359)</p>
</blockquote>
<hr>
<blockquote>
<p>"The conventional and natural link in this context is the
multinomial logit, also known as the softmax function." (page 359)</p>
</blockquote>
<hr>
<blockquote>
<p>"Another way to fit a multinomial/categorical model is to refactor
it into a series of Poisson likelihoods. That should sound a bit
crazy." (page 363)</p>
</blockquote>
<hr>
<blockquote>
<p>"It is important to never convert counts to proportions before
analysis, because doing so destroys information about sample size."
(page 365)</p>
</blockquote>
<hr>
<h3><a name="ch12" href="#ch12">Chapter 12: Monsters and Mixtures</a></h3>
<p>over-dispersion, ordered categories</p>
<hr>
<blockquote>
<p>"Just be sure to validate it [your model] by simulating dummy data
and then recovering the data-generating process through fitting the
model to the dummy data." (page 369)</p>
</blockquote>
<hr>
<blockquote>
<p>"continuous mixture models in which a linear model is attached not
to the observations themselves but rather to a distribution of
observations." (page 370)</p>
</blockquote>
<hr>
<blockquote>
<p>"... Poisson distributions are very narrow. The variance must equal
the mean, recall." (page 373)</p>
</blockquote>
<hr>
<blockquote>
<p>"You should not use WAIC and PSIS with these
[beta-binomial and gamma-Poisson/negative binomial] models, however,
unless you are very sure of what you are doing. The reason is that
while ordinary binomial and Poisson models can be aggregated and
disaggregated across rows in the data, without changing any causal
assumptions, the same is not true of beta-binomial and gamma-Poisson
models. The reason is that a beta-binomial or gamma-Poisson
likelihood applies an unobserved parameter to each row in the data.
When we then go to calculate log-likelihoods, how the data are
structured will determine how the beta-distributed or
gamma-distributed variation enters the model." (page 375)</p>
</blockquote>
<hr>
<blockquote>
<p>"In the sciences, there is sometimes a culture of anxiety
surrounding statistical inference. It used to be that researchers
couldn't easily construct and study their own custom models, because
they had to rely upon statisticians to properly study the models
first. This led to concerns about unconventional models, concerns
about breaking the laws of statistics. But statistical computing is
much more capable now. Now you can imagine your own generative
process, simulate data from it, write the model, and verify that it
recovers the true parameter values. You don't have to wait for a
mathematician to legalize the model you need." (page 376)</p>
</blockquote>
<p>This could almost be a summary of the book, maybe.</p>
<hr>
<blockquote>
<p>"Just treating ordered categories as continuous measures is not a
good idea."</p>
</blockquote>
<p>He offers the cumulative link function.</p>
<hr>
<blockquote>
<p>"This kind of vector, in which all the values sum to one (or any
other constant), has a special name, a simplex." (page 394)</p>
</blockquote>
<hr>
<h3><a name="ch13" href="#ch13">Chapter 13: Models with Memory</a></h3>
<p>It's the varying effects ("random effects") chapter! Multilevel models!</p>
<hr>
<blockquote>
<p>"Anterograde amnesia is bad for learning about the world." (page 399)</p>
</blockquote>
<hr>
<blockquote>
<p>"this prior is actually learned from the data." (pages 399-400)</p>
</blockquote>
<hr>
<blockquote>
<p>"When some individuals, locations, or times are sampled more than
others, multilevel models automatically cope with differing
uncertainty across these clusters. This prevents over-sampled
clusters from unfairly dominating inference." (page 400)</p>
</blockquote>
<p>This is a pretty cool property to have. The problem of data imbalance
is a challenge for many machine learning algorithms. Considering
multilevel models as a kind of solution is interesting. Not obvious
that it can be easily applied e.g. to vision models, but still, it's
interesting.</p>
<hr>
<blockquote>
<p>"When it comes to regression, multilevel regression deserves to be
the default approach. There are certainly contexts in which it would
be better to use an old-fashioned single-level model. But the
contexts in which multilevel models are superior are much more
numerous. It is better to begin to build a multilevel analysis, and
then realize it's unnecessary, than to overlook it." (page 400)</p>
</blockquote>
<p>Is this really the case? It would be neat to see an example where a
multilevel model isn't obviously needed but is better.</p>
<hr>
<p>Costs of multilevel models (page 400, paraphrase):</p>
<ul>
<li>new assumptions (priors on priors)</li>
<li>estimation challenges (requires MCMC)</li>
<li>hard to understand</li>
</ul>
<hr>
<p>Synonyms (page 401):</p>
<ul>
<li>multilevel model</li>
<li>hierarchical model</li>
<li>mixed effects model</li>
</ul>
<p>With parameters of multilevel models "most commonly known as random
effects". An endnote cites section 6 of Gelman's <a href="http://www.stat.columbia.edu/~gelman/research/published/banova7.pdf">Anova paper</a> but I
didn't find it as "entertaining" as promised. It does include the
origin of "varying effects" as a proposed better name than "random
effects":</p>
<blockquote>
<p>"We define effects (or coefficients) in a multilevel model as
<em>constant</em> if they are identical for all groups in a population and
<em>varying</em> if they are allowed to differ from group to group." (page
20 in Gelman)</p>
</blockquote>
<p>(A "group" could be an individual, depending on the nature of the
data.)</p>
<hr>
<p>I don't love that "hyperparameter" is used for parameters that are
learned from the data, even if they're a level up, because it
conflicts with the usual ML usage of "hyperparameter". It seems fair
that their priors are called hyperpriors, though.</p>
<hr>
<p>Reasons for using a Gaussian prior (page 403):</p>
<ol>
<li>convention (everybody does it)</li>
<li>pragmatism (easy to use/fit)</li>
<li>entropy (maxent if specifying only mean and variance)</li>
</ol>
<hr>
<blockquote>
<p>"Rethinking: Varying intercepts as over-dispersion. ... Compared to
a beta-binomial or gamma-Poisson model, a binomial or Poisson model
with a varying intercept on every observed outcome will often be
easier to estimate and easier to extend." (page 407)</p>
</blockquote>
<p>Oh my! A coefficient for every observation! Take that, frequentist
statisticians!</p>
<p>It would be interesting to see a direct comparison, using e.g.
beta-binomial on the one hand and multilevel on the other...</p>
<hr>
<p>Page 408 itemizes three perspectives:</p>
<ul>
<li>Complete pooling (one estimate shared by all groups)</li>
<li>No pooling (each group independently)</li>
<li>Partial pooling (multilevel model; shrinkage of group estimates)</li>
</ul>
<p>This in particular reminds me of
<a href="https://www.evanmiller.org/how-not-to-sort-by-average-rating.html">How Not To Sort By Average Rating</a>, which inspired in part my
<a href="https://planspace.org/2014/08/17/how-to-sort-by-average-rating/">How To Sort By Average Rating</a> advocating Laplace smoothing instead
of Wilson bounds.</p>
<p>If you use the grand average to determine the Laplace binomial values,
this is just like partial pooling via multilevel model, only much less
rigorous, less obviously extensible to multivariate settings, and far
easier.</p>
<p>I did a version of Laplace smoothing back when I was helping use
survey data to determine how well various medical facilities were
satisfying their patients. A ranking was desired, but ranking by raw
scores ("no pooling") made the most extreme scores nearly always
associated with the locations that had the fewest survey responses.</p>
<hr>
<blockquote>
<p>"Note that the priors are part of the model when we estimate, but
not when we simulate. Why? Because priors are epistemology, not
ontology. They represent the initial state of information of our
robot, not a statement about how nature chooses parameter values."
(page 409)</p>
</blockquote>
<hr>
<p>I enjoy that my preferred way of writing the logistic function is used
on page 411.</p>
<hr>
<blockquote>
<p>"Partial pooling isn't always better. It's just better on average in
the long run." (page 413)</p>
</blockquote>
<hr>
<blockquote>
<p>"As soon as you start trusting the machine, the machine will betray
your trust." (page 416)</p>
</blockquote>
<hr>
<blockquote>
<p>"If the individual units are exhcnagable—the index values could be
reassigned without changing the meaning of the model—then partial
pooling could help." (page 419)</p>
</blockquote>
<hr>
<blockquote>
<p>"Recall that HMC simulates the frictionless flow of a particle on a
surface." (page 420)</p>
</blockquote>
<hr>
<blockquote>
<p>"Algebra makes many things possible." (page 425)</p>
</blockquote>
<hr>
<p>Ah! Here's where he mentions Mister P: Multilevel Regression and
Post-stratification. (page 430)</p>
<hr>
<blockquote>
<p>"Selection on the outcome variable is one of the worst things that
can happen in statistics." (page 431)</p>
</blockquote>
<hr>
<h3><a name="ch14" href="#ch14">Chapter 14: Adventures in Covariance</a></h3>
<hr>
<blockquote>
<p>"... the general varying effects strategy: Any batch of parameters
with <em>exchangeable</em> index values can and probably should be pooled.
Exchangeable just means the index values have no true ordering,
because they are arbitrary labels." (page 435)</p>
</blockquote>
<hr>
<blockquote>
<p>"a way to pool information <em>across</em> parameter types—intercepts and
slopes" (page 436)</p>
</blockquote>
<hr>
<blockquote>
<p>"Finally, we'll circle back to causal inference and use our new
powers over covariance to go beyond the tools of Chapter 6
[The Haunted DAG &amp; the Causal Terror], introducing Instrumental
Variables." (pages 436-437)</p>
</blockquote>
<p>That doesn't reflect the actual order, which has IV in the middle of
the chapter...</p>
<ul>
<li>14.1 Varying slopes by construction</li>
<li>14.2 Advanced varying slopes</li>
<li>14.3 Instruments and causal designs</li>
<li>14.4 Social relations as correlated varying effects</li>
<li>14.5 Continuous categories and the Gaussian Process</li>
</ul>
<hr>
<blockquote>
<p>"In conventional multilevel models, the device that makes this
[modeling the joint population of intercepts and slopes by modeling
their covariance] possible is a joint multivariate Gaussian
distribution for all of the varying effects, both intercepts and
slopes." (page 437)</p>
</blockquote>
<hr>
<blockquote>
<p>"... we are always forced to analyze data with a model that is
misspecified: The true data-generating process is different than the
model." (page 441)</p>
</blockquote>
<hr>
<blockquote>
<p>"how you fit the model is part of the model." (page 447)</p>
</blockquote>
<hr>
<blockquote>
<p>"This [fewer effective than actual parameters] is a good example of
how varying effects adapt to the data. The overfitting risk is much
milder here than it would be with ordinary fixed effects." (page
451)</p>
</blockquote>
<p>Estimates are pooled/shrunk, so parameters don't fit "tightly" to the
data...</p>
<hr>
<blockquote>
<p>"Our interpretation of this experiment has not changed. These
chimpanzees simply did not behave in any consistently different way
in the partner treatments." (page 452)</p>
</blockquote>
<p>This chimpanzee example continues to be fairly dull, for the level of
complexity... I guess it's an example of sensitivity analysis, in a
sense, looking at it in multiple different ways? But it would be more
interesting if there were sometimes different (or any) results.</p>
<hr>
<blockquote>
<p>"There is an obvious cost to these non-centered forms: They look a
lot more confusing. Hard-to-read models and model code limit our
ability to share implementations with our colleagues, and sharing is
the principal goal of scientific computation." (page 454)</p>
</blockquote>
<hr>
<blockquote>
<p>"This last line ["Q cannot influence W except through E"] is
sometimes called the exclusion restriction. It cannot be strictly
tested, and it is often implausible."</p>
</blockquote>
<hr>
<p>The introduction to instrumental variables is based on the classic
<a href="https://www.jstor.org/stable/2937954">Does Compulsory School Attendance Affect Schooling and Earnings?</a></p>
<hr>
<blockquote>
<p>"Remember: With real data, you never know what the right answer is."
(page 456)</p>
</blockquote>
<hr>
<blockquote>
<p>"Instrumental variables are hard to understand. But there are some
excellent tools to help you. For example, the <code>dagitty</code> package
contains a function <code>instrumentalVariables</code> that will find
instruments, if they are present in a DAG." (page 459)</p>
</blockquote>
<hr>
<blockquote>
<p>"The instrumental variable model is often discussed with an
estimation procedure known as two-stage least squares (2SLS). This
procedure involves two linear regressions. The predicted values of
the first regression are fed into the second as dta, with
adjustments so that the standard errors make sense. Amazingly, when
the weather is nice, this procedure works. ... Some people mistake
2SLS for the model of instrumental variables. They are not the same
thing. Any model can be estimated through a number of different
procedures, each with its own benefits and costs." (page 460)</p>
</blockquote>
<hr>
<blockquote>
<p>"Instrumental variables are natural experiments that impersonate
randomized experiments." (page 460)</p>
</blockquote>
<hr>
<p>Discussing the front-door criterion, he points to a <a href="http://www.alexchinco.com/example-front-door-criterion/">blog post</a> and
<a href="https://www.aeaweb.org/articles?id=10.1257/pol.6.3.63">paper</a>.</p>
<hr>
<ul>
<li>Instrumental Variables</li>
<li>Front-Door Criterion</li>
<li>Regression Discontinuity</li>
</ul>
<hr>
<blockquote>
<p>"First, the correlation changes if we switch the A/B labels." (page
462)</p>
</blockquote>
<p>This is a little puzzling. Swapping axes shouldn't change correlation.</p>
<p>Ahhh... It doesn't swap the axes (unless there are only two
participants, or an even number that all pair off sufficiently
nicely, or the relabeling is otherwise sufficiently "nice"...</p>
<p>Why does this happen...</p>
<p>Some labeling is essentially arbitrary, so that "giver" and "receiver"
switch.</p>
<p>Consider a three-point graph. Our "point of view" node is attached to
two others. Label them however you want, the give/receive with us
remains the same. But when you switch those two, give/receive change
direction between them, and if they're not equal, that will send a
point over the diagonal and change the correlation.</p>
<p>Cool.</p>
<hr>
<blockquote>
<p>"Social Relations Model, or SRM" (page 462)</p>
</blockquote>
<hr>
<blockquote>
<p>"The general approach is known as Gaussian Process regression. This
name is unfortunately wholly uninformative about what it is for and
how it works." (page 468)</p>
</blockquote>
<p>I like the phrase the author uses to describe GP regression:
"continuous categories".</p>
<hr>
<blockquote>
<p>"phylogenic, or <a href="https://en.wikipedia.org/wiki/Patrocladogram">patristic</a>, distance." (page 481)</p>
</blockquote>
<hr>
<blockquote>
<p>"<a href="https://www.carlboettiger.info/2013/10/11/is-it-time-to-retire-pagels-lambda.html">Pagel's lambda</a>" (page 482)</p>
</blockquote>
<hr>
<blockquote>
<p>"Biologists tend to use phylogenies under a cloud of superstition
and fearful button pushing." (page 482)</p>
</blockquote>
<hr>
<blockquote>
<p>"Gaussian processes represent a practical method of extending the
varying effects strategy to continuous dimensions of similarity,
such as spatial, network, phylogenic, or any other abstract distance
between entities in the data." (page 485)</p>
</blockquote>
<hr>
<p>The <a href="https://mc-stan.org/docs/2_26/stan-users-guide/gaussian-process-regression.html">Stan documenation</a> has more on fitting GP regressions.</p>
<p>I think the thing that keeps this kind of GP from fitting the data
perfectly, as is <a href="https://planspace.org/20181226-gaussian_processes_are_not_so_fancy/">often the case</a> with GPs, is the eta term...</p>
<p>But really, why doesn't it fit the data perfectly? In the primates
example, there's a correlation matrix that clearly includes ones...</p>
<p>Oh! It's because the kernel matrix doesn't enter into the mean! ...
Well, that's the case for the primates example, anyway...</p>
<p>So the effect of just changing the covariance matrix is like this:</p>
<pre><code class="language-r">install.packages('mvtnorm')
library(mvtnorm)

data &lt;- c(1, 1, -1, -1)

# the mean here defaults to c(0, 0, 0, 0)

# "standard" 4d normal (identity for covariance matrix)
dmvnorm(data)
# 0.003428083

# covariance matrix that expects clustering
sigma &lt;- matrix(c(1, 0.5, 0, 0,
                  0.5, 1, 0, 0,
                  0, 0, 1, 0.5,
                  0, 0, 0.5, 1), nrow=4)
dmvnorm(data, sigma=sigma)
# 0.008902658 (more likely than when assuming independence)</code></pre>

<p>So when expecting clustering, you don't have to explain via the mean
as much...</p>
<p>For the primates example, he gets a significant coefficient on group
size, then he makes it go away via covariance, and then he uses a
different covariance and gets it back...</p>
<blockquote>
<p>"This [the second] model annihilates group size—the posterior mean
is almost zero and there is a lot of mass on both sides of zero. The
big change from the previous model suggests that there is a lot of
clustering of brain size in the tree and that this produces a
spurious relationship with group size, which also clusters in the
tree." (page 482)</p>
</blockquote>
<p>This is a little weird, isn't it? Just because the relationship
clusters in the tree, that doesn't mean there isn't a relationship,
right? There are at least two interpretations: (a) bigger groups and
bigger brains co-evolved, in this part of the tree, and (b) this part
of tree just happens to have both bigger groups and bigger brains. I
guess it's a potential confound?</p>
<p>In the final example he gets less covariance and the coefficient on
brain size comes back. Which model is more right? Doesn't seem very
obvious to me.</p>
<p>Ah: For the earlier example, it's a Poisson regression anyway, so it's
not obvious it could fit perfectly anyway, because of the link
function.</p>
<p>And the multi-variate normal bit has mean zero! It can only pull out
of the mean zero distribution with given covariance (which is
constrained by prior so variance isn't very big). So there's really no
chance of fitting perfectly.</p>
<hr>
<h3><a name="ch15" href="#ch15">Chapter 15: Missing Data and Other Opportunities</a></h3>
<ul>
<li>15.1. "Measurement error" (Oh! Like Nate Silver with polls!)</li>
<li>15.2. "Missing data"</li>
<li>15.3. "Categorical errors and discrete absences" (sum over options)</li>
</ul>
<hr>
<blockquote>
<p>"A big advantage of Bayesian inference is that it obviates the need
to be clever. ... There's no need to be clever when you can be
ruthless." (page 489)</p>
</blockquote>
<p>(The ruthlessness is ruthlessness in applying rules of conditional
probability.)</p>
<hr>
<blockquote>
<p>"And that's the real trick of the Bayesian approach: to apply
conditional probability in all places, for data and parameters."
(page 490)</p>
</blockquote>
<hr>
<blockquote>
<p>"Bayes is an honest partner. It is not afraid to hurt your
feelings." (page 491)</p>
</blockquote>
<hr>
<blockquote>
<p>"The big take home point for this section is that when you have a
distribution of values, don't reduce it down to a single value to
use in a regression." (page 497)</p>
</blockquote>
<hr>
<blockquote>
<p>"This [considering covariance between errors] is computationally
similar to how we did instrumental variable regression in the
previous chapter." (page 498)</p>
</blockquote>
<p>It sounds like instrumental variables are often (originally?) about
measurement error, but I don't completely understand how...</p>
<hr>
<blockquote>
<p>"Use your background knowledge to write down a generative model or
models, simulate data from these models in order to understand the
inferential risks, and design a statistical approach that can work
at least in theory." (page 499)</p>
</blockquote>
<hr>
<blockquote>
<p>"So there will be a posterior distribution for each missing value."
(page 505)</p>
</blockquote>
<p>In the model, when we <em>have</em> data, the distribution we enter is
interpreted as a <em>likelihood</em>, but when we <em>don't have</em> data (it's
missing), the distribution is interpreted as a prior... Neat!</p>
<hr>
<blockquote>
<p>"Implementing an imputation model can be done several ways. All of
the ways are a little awkward, because the locations of missing
values have to be respected, and that means plenty of index
management." (page 506)</p>
</blockquote>
<hr>
<blockquote>
<p>"Doing better is good." (page 511)</p>
</blockquote>
<hr>
<blockquote>
<p>"If you aren't comfortable dropping incomplete cases, then you
shouldn't be comfortable using multiple imputation either." (page
511)</p>
</blockquote>
<p>This is maybe a little strong; he's explaining here that multiple
imputation is an approximation of the technique he's advocating, after
all.</p>
<hr>
<p>He refs this paper, which has some missing data:
<a href="https://www.nature.com/articles/s41586-019-1043-4">Complex societies precede moralizing gods throughout world history</a>.</p>
<hr>
<blockquote>
<p>"HMC just doesn't do discrete variables." (page 516)</p>
</blockquote>
<hr>
<blockquote>
<p>"This all sounds too good to be true. It is all true. But
implementing it is not at all obvious." (page 517)</p>
</blockquote>
<hr>
<blockquote>
<p>"This chapter highlights the general principles of the book, that
effective statistical modeling requires both careful thought about
how the data were generated and delicate attention to numerical
algorithms. Neither can lift inference alone." (page 521)</p>
</blockquote>
<h3><a name="ch16" href="#ch16">Chapter 16: Generalized Linear Madness</a></h3>
<p>beyond GLMs</p>
<hr>
<ul>
<li>16.1. "Geometric people"</li>
<li>16.2. "Hidden minds and observed hehavior"</li>
<li>16.3. "Ordinary differential nut cracking"</li>
<li>16.4. "Population dynamics"</li>
</ul>
<hr>
<blockquote>
<p>"GLMs (or GLMMs)" (page  526)</p>
</blockquote>
<p>"GLMM" is "<a href="https://en.wikipedia.org/wiki/Generalized_linear_mixed_model">Generalized linear mixed model</a>" where "mixed" means
adding "random effects" in addition to "fixed effects" which means
doing something hierarchical, essentially. Varying effects, per
individual, group, etc.</p>
<hr>
<blockquote>
<p>"Useful mathematical modeling typically involves ridiculous
assumptions." (page 527)</p>
</blockquote>
<p>The 1985 "Consider a Spherical Cow: A Course in Environmental Problem
Solving" doesn't seem to be the origin of the <a href="https://en.wikipedia.org/wiki/Spherical_cow">spherical cow</a>, but
it's still fun.</p>
<p>Three cites here:</p>
<ul>
<li><a href="https://uberty.org/wp-content/uploads/2015/07/Levins-1966-Model_Building.pdf">The Strategy of Model Building in Population Biology</a></li>
<li><a href="https://www.journals.uchicago.edu/doi/abs/10.1086/341764">Using False Models to Elaborate Constraints on Processes: Blending Inheritance in Organic and Cultural Evolution</a>, which includes in its abstract: "Scientific models may be more useful for false assumptions they make than true ones when one is interested not in the fit of the model, but in the form of the residuals."</li>
<li><a href="https://www.taylorfrancis.com/chapters/edit/10.4324/9781315173726-14/models-stupid-need-paul-smaldino">Models Are Stupid, and We Need More of Them</a></li>
</ul>
<hr>
<blockquote>
<p>"One of the major advantages of having a scientifically inspired
model is that the parameters have meanings." (page 528)</p>
</blockquote>
<hr>
<blockquote>
<p>"The key, as always is to think generatively." (page 531)</p>
</blockquote>
<hr>
<p><a href="https://www.nature.com/articles/s41598-018-38392-8">Learning curves and teaching when acquiring nut-cracking in humans and chimpanzees</a></p>
<hr>
<blockquote>
<p>"no lag beyond one period makes any causal sense." (page 543)</p>
</blockquote>
<p>I think this is too strong, and he walks it back a little...</p>
<hr>
<ul>
<li><a href="http://www.scholarpedia.org/article/State_space_model">State Space Model (SSM)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hidden_Markov_model">Hidden Markov Model (HMM)</a></li>
</ul>
<hr>
<blockquote>
<p>"Sometimes all this nonsense is okay, if all you care about is
forecasting. But often these models don't even make good forecasts,
because getting the future right often depends upon having a decent
causal model." (page 543)</p>
</blockquote>
<hr>
<p>This particular model is a famous one, the <a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations">Lotka-Volterra Model</a>.
It models simple predator-prey interactions and demonstrates several
important things about ecological dynamics. Lots can be proved about
it without using any data at all. For example, the population tends to
be unstable, cycling up and down like in Figure 16.6. This is
interesting because it suggests that, while nature is more
complicated, all that is necessary to see cyclical population dynamics
is captured in a stupidly simple model. (page 544)</p>
<hr>
<blockquote>
<p>"The hidden states are the causes. The measurements don't cause
anything." (page 549)</p>
</blockquote>
<hr>
<h3><a name="ch17" href="#ch17">Chapter 17: Horoscopes</a></h3>
<p>conclusion</p>
<hr>
<blockquote>
<p>"Thinking generatively—how the data could arise—solves many
problems. Many statistical problems cannot be solved with
statistics. All variables are measured with error. Conditioning on
variables creates as many problems as it solves. There is no
inference without assumption, but do not choose your assumptions for
the sake of inference. Build complex models one piece at a time. Be
critical. Be kind." (page 553)</p>
</blockquote>
<hr>
<blockquote>
<p>"Philosophers of science actually have a term, <em>the pessimistic
induction</em>, for the observation that because most science has been
wrong, most science is wrong." (page 554)</p>
</blockquote>
<hr>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/1745691612459059">A Vast Graveyard of Undead Theories: Publication Bias and Psychological Science’s Aversion to the Null</a></p>
<hr>
<blockquote>
<p>"Even retracted papers continue to be cited." (page 555)</p>
</blockquote>
<p>This makes me wonder whether there could be some proactive system to
inform authors of such issues... "I see you cited this paper; did you
know?"</p>
<hr>
<blockquote>
<p>"The data and its analysis are the scientific product. The paper is
just an advertisement." (page 555)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210508-statistical_rethinking_by_mcelreath/</link>
<guid>http://planspace.org/20210508-statistical_rethinking_by_mcelreath/</guid>
<pubDate>Sat, 08 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Scout Mindset, by Galef</title>
<description><![CDATA[

<p>The metaphor is soldier vs. scout. The advice is broadly good. With no
real discussion of epistemology but an implicit (roughly positivist?)
assumed worldview, I felt interesting foundational discussion was
elided. There was also little directly on “hard” (not yet known or
unknowable) questions. My critique is principally that I wanted more.</p>
<ul>
<li><a href="#more">Quotes and notes</a></li>
<li><a href="#outline">Slightly expanded table of contents</a></li>
</ul>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<h3><a name="more" href="#more">Quotes and notes</a></h3>
<hr>
<blockquote>
<p>"our judgment isn’t limited by knowledge nearly as much as it’s
limited by attitude." (page x)</p>
</blockquote>
<hr>
<blockquote>
<p>"In “Persuasion,” we saw that law students who are randomly assigned
to one side of a moot court case become confident, after reading the
case materials, that their side is morally and legally in the right.
But that confidence doesn’t help them persuade the judge. On the
contrary, law students who are more confident in the merits of their
own side are significantly <em>less</em> likely to win the case—perhaps
because they fail to consider and prepare for the rebuttals to their
arguments." (page 27)</p>
</blockquote>
<p>This cites <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/667711?journalCode=jls">Eigen and Listokin</a>, and I don’t have access or
inclination to read the paper just now, but it seems like there’s a
claim here like “confidence causes bad performance” and I wonder
whether possible confounds have been considered. To me, “lower quality
lawyer causes both confidence and bad performance” seems plausible.</p>
<hr>
<blockquote>
<p>"Having an accurate map doesn’t help you very much when you’re
allowed to travel only one path." (page 40)</p>
</blockquote>
<hr>
<p>Page 45 starts an exploration of Kahan’s famous paper on
<a href="https://www.nature.com/articles/nclimate1547" title="The polarizing impact of science literacy and numeracy on perceived climate change risks">scientific polarization increasing with education</a>. Perhaps in an
effort to avoid alienating any readers, the tools of the scout are not
applied to settle the question of whether global warming is real. The
opportunity to engage one way or another with the idea of
<a href="https://en.wikipedia.org/wiki/Na%C3%AFve_realism_(psychology)" title="Naïve realism">naive realism</a> is not taken.</p>
<p>In Harford’s <a href="https://planspace.org/20210330-how_to_make_the_world_add_up_by_harford/#golden">treatment</a> of Kahan, I really appreciated the emphasis
on <em>curiosity</em> being essential for “scout-like” thinking.</p>
<hr>
<p>I think I hadn’t seen the idea of Blind Data Analysis mentioned on
page 55, citing <a href="https://www.nature.com/news/how-scientists-fool-themselves-and-how-they-can-stop-1.18517">Nuzzo</a>. Nice! Will keep this in mind.</p>
<hr>
<blockquote>
<p>"It [being critical of a study with undesirable results] prompted me
to go back through the studies I had been planning to cite in my
favor, and scrutinize their methodology for flaws, just as I had
done with the pro-soldier mindset study. (Sadly, this ended up
disqualifying most of them.)" (page 68)</p>
</blockquote>
<p>I’m not sure to what extent this is a joke; I thought it was funny as
I read it. But seriously, I wish people generally would <a href="https://www.paperswithoutcode.com/">say more</a>
about determinations such as this.</p>
<hr>
<p>I might be a soldier on this, but I don’t love quantifying uncertainty
in the manner of the calibration game introduced starting on page 75.
I thought a little bit about why.</p>
<ul>
<li>For simple matters of fact, uncertainty is ignorance. It just isn’t
   that interesting, or useful. You can go check and get 100% (or
   close) confidence.</li>
<li>For predictions about the future, there are interesting questions
   about what confidence means (is the universe deterministic? what is
   knowable?) and I think there’s no way to know whether your
   prediction <em>at a given time</em> is calibrated. The advice is to update
   your estimate over time, after all. If I say event <em>x</em> (to be
   evaluated in a week) is 20% likely today but 10% likely tomorrow,
   was I "right" at those respective times? Did the probability
   change, or just my estimate? Is there such a thing as "correct
   probability given what you know," likely different from true
   probability?</li>
<li>For difficult propositions, there is no oracle; you can’t
   calibrate. Worse, consensus can change over time. When it was
   consensus, what confidence in <a href="https://en.wikipedia.org/wiki/Aether_(classical_element)">aether</a> would have been
   appropriate? How confident should you be in a research result
   before it comes out that an error in analysis invalidates it? How
   confident should you be in a value judgment?</li>
<li>If we’re serious about quantifying confidence, shouldn’t we also
   estimate confidence in our confidence? Like: I’m 60% confident,
   plus or minus 10pp. This seems necessary, to allow for things like
   mistaken beliefs about current evidence. It also seems silly.</li>
</ul>
<p>I’m not sure I have any really coherent argument here. I agree with
the general idea of being aware of how sure you are. Somehow I don’t
like the exercise of writing down numbers for it.</p>
<p>There is an interesting topic of decision-making in the face of low
confidence. What do you do when you know you’re not sure? (Ramble,
seems to be my answer.) Maybe out of scope for the book.</p>
<hr>
<blockquote>
<p>"The reality is that there’s no clear divide between the
“decision-making” and “execution” stages of pursuing a goal. Over
time, your situation will change, or you’ll learn new information,
and you’ll need to revise your estimate of the odds." (page 110)</p>
</blockquote>
<p>I really agree with this. Planning can be valuable, but following the
plan to the letter is often not.</p>
<hr>
<p>Galef discusses low (10%, 30%) early estimates of “success” from Musk
and Bezos (starting page 111). Exploring why they would take such
chances, she mentions both expected value (10% of huge is still big)
and the idea that even “failure” would be fairly positive. I think
expected value is almost always the wrong way to think about
significant choices (especially one-shot choices with unclear odds)
and I don’t really believe it’s how people tend to think (or should).
I think the question of whether something is
<a href="/20181204-worth_doing_even_if_it_fails/">worth doing, even if it fails</a> is the right question. So I think
the balance of emphasis is off here. Expected value is a simple tool,
a hammer that people reach for <a href="/2012/06/04/expected-value-is-not-useful-for-making/">too often</a>, simplifying problems too
far. I wouldn’t even mention it in this setting.</p>
<hr>
<blockquote>
<p>"You might think these principles sound obvious and that you know
them already. But “knowing” a principle, in the sense that you read
it and say, “Yes, I know that,” is different from having
internalized it in a way that actually changes how you think." (page
144)</p>
</blockquote>
<hr>
<blockquote>
<p>"In his book <em>Sources of Power</em>, decision researcher Gary Klein
cites this [explaining away signs of a problem] as one of the top
three causes of bad decisions. He calls it a “de minimus error,” an
attempt to minimize the inconsistency between observations and
theory. Each new piece of evidence that doesn’t fit a doctor’s
medical diagnosis can be explained away or dismissed as a fluke, so
the doctor never realizes her initial diagnosis was wrong." (page
165)</p>
</blockquote>
<hr>
<p><a href="https://www.pnas.org/content/115/37/9216">Exposure to opposing views on social media can increase political polarization</a> cited in chapter 12.</p>
<hr>
<p><a href="http://www.paulgraham.com/identity.html">Keep your identity small</a> cited in chapter 14.</p>
<hr>
<blockquote>
<p>"They [a group of citizen scientists] also dove into the politics of
government research, familiarizing themselves with how funding was
structured and how the drug trials were conducted. The
disorganization they discovered alarmed them. “It sort of felt like
reaching the Wizard of Oz,” said one activist named Mark Harrington.
“You’ve gotten to the center of the whole system and there’s just
this schmuck behind a curtain.”" (page 212)</p>
</blockquote>
<p>Cites <a href="https://www.penguinrandomhouse.com/books/209900/how-to-survive-a-plague-by-david-france/">How to Survive a Plague</a>.</p>
<hr>
<h3><a name="outline" href="#outline">Slightly expanded table of contents</a></h3>
<ul>
<li>Introduction<ul>
<li>Realize that truth isn't in conflict with your other goals</li>
<li>Learn tools that make it easier to see clearly</li>
<li>Appreciate the emotional rewards of scout mindset</li>
</ul>
</li>
<li>Part 1: The case for scout mindset<ul>
<li>Chapter 1: Two types of thinking<ul>
<li>“Can I believe it?” vs. “Must I believe it?”</li>
</ul>
</li>
<li>Chapter 2: What the soldier is protecting</li>
<li>Chapter 3: Why truth is more valuable than we realize</li>
</ul>
</li>
<li>Part 2: Developing self-awareness<ul>
<li>Chapter 4: Signs of a scout<ul>
<li>Do you tell other people when you realize they were right?</li>
<li>How do you react to personal criticism?</li>
<li>Do you ever prove yourself wrong?</li>
<li>Do you take precautions to avoid fooling yourself?</li>
<li>Do you have any good critics?</li>
<li>Can you point to occasions in which you were in soldier
   mindset?</li>
</ul>
</li>
<li>Chapter 5: Noticing bias<ul>
<li>The double standard test</li>
<li>The outsider test</li>
<li>The conformity test</li>
<li>The selective skeptic test</li>
<li>The status quo bias test</li>
<li>Core skill: "a sense that your judgments are
   <em>contingent</em>—that what seems true or reasonable or fair or
   desirable can change when you mentally vary some feature of
   the question that should have been irrelevant." (page 87)</li>
</ul>
</li>
<li>Chapter 6: How sure are you?<ul>
<li>Core skill: "being able to tell the difference between the
   feeling of <em>making a claim</em> and the feeling of <em>actually
   trying to guess what's true</em>." (page 87)</li>
</ul>
</li>
</ul>
</li>
<li>Part 3: Thriving without illusion<ul>
<li>Chapter 7: Coping with reality</li>
<li>Chapter 8: Motivation without self-deception</li>
<li>Chapter 9: Influence without overconfidence</li>
</ul>
</li>
<li>Part 4: Changing your mind<ul>
<li>Chapter 10: How to be wrong</li>
<li>Chapter 11: Lean in to confusion</li>
<li>Chapter 12: Escape your echo chamber</li>
</ul>
</li>
<li>Part 5: Rethinking identity<ul>
<li>Chapter 13: How beliefs become identities</li>
<li>Chapter 14: Hold your identity lightly</li>
<li>Chapter 15: A scout identity</li>
</ul>
</li>
</ul>
<!-- https://twitter.com/planarrowspace/status/1388919415660548102 -->    
    ]]></description>
<link>http://planspace.org/20210502-the_scout_mindset_by_galef/</link>
<guid>http://planspace.org/20210502-the_scout_mindset_by_galef/</guid>
<pubDate>Sun, 02 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Simple Front Door Regression</title>
<description><![CDATA[

<p>If you have a mediator, you can estimate effects despite confounding,
which is neat. The idea is like flip of <a href="/20210430-a_simple_instrumental_variable/">instrumental variables</a>;
here the constructed non-confounded variable is what’s not explained
by the confounded one. A <a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation#Interpretation_as_two-stage_least_squares">two-stage regression</a> illustrates the
idea.</p>
<p>We seek to estimate the impact of <em>x</em> on <em>y</em>, where they’re both
influenced by <em>u</em>.</p>
<p><img alt="front door scenario" src="front_door.jpg"></p>
<p>Unfortunately, <em>u</em> is <em>u</em>nobserved, so we can’t control for it.
But lo, there is <em>z</em>, a perfect mediator between <em>x</em> and <em>y</em>. Let’s
simulate data where all the true coefficients are one.</p>
<!-- set.seed(101) -->

<pre><code class="language-r">u = rnorm(100)
x = u + rnorm(100)
z = x + rnorm(100)
y = u + z + rnorm(100)</code></pre>

<p>Regressing naively, we get an incorrect estimate for the effect of <em>x</em>
on <em>y</em>.</p>
<pre><code class="language-r">summary(lm(y ~ x))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.54648    0.09848  15.704   &lt;2e-16 ***</code></pre>

<p>Luckily, <em>z</em> is in there, and it isn’t confounded with <em>u</em>.</p>
<p>But how do we use it? Throwing it in the regression doesn’t help.</p>
<pre><code class="language-r">summary(lm(y ~ x + z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            0.46175    0.15517   2.976  0.00369 **
##  z            1.02436    0.12740   8.041  2.2e-12 ***</code></pre>

<p>A fancier model-fitting approach is needed. Here’s an illustrative
two-stage regression, ignoring standard error concerns.</p>
<p>Stage one: Do a regression using <em>x</em> to predict <em>z</em>. Note the
coefficient on <em>x</em>. Then get the residuals for <em>z</em> from that model,
which I’ll call <em>z_not_from_x</em>. This uses the non-confounding of <em>z</em>
with <em>u</em> to make a “version of” (maybe a component of) <em>z</em> that is
independent of <em>u</em> (because it’s independent of <em>x</em>): the variation of
<em>z</em> not due to <em>x</em> (or <em>u</em>).</p>
<p>Stage two: Do a regression using <em>z_not_from_x</em> to predict <em>y</em>.</p>
<p>Multiplying the coefficients from the two models gives the effect of
<em>x</em> on <em>y</em>.</p>
<pre><code class="language-r">summary(lm(z ~ x))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x           1.058940   0.060797  17.418   &lt;2e-16 ***
z_not_from_x = residuals(lm(z ~ x))
summary(lm(y ~ z_not_from_x))
##               Estimate Std. Error t value Pr(&gt;|t|)
##  z_not_from_x   1.0244     0.2889   3.546 0.000601 ***
1.058940 * 1.0244  # Estimate for x on y
##  1.084778</code></pre>

<p>We’ve recovered a fair estimate of the true parameter for <em>x</em>, despite
not using the unobserved confound <em>u</em>!</p>
<p>Here’s the same thing as above but with the <code>lavaan</code> <a href="https://lavaan.ugent.be/">package</a> for
<a href="https://en.wikipedia.org/wiki/Structural_equation_modeling">SEM</a>, following <a href="http://www.felixthoemmes.com/blog/the-front-door-criterion-in-linear-parametric-models/">Thoemmes</a>.</p>
<pre><code class="language-r">model = "z ~ x_on_z * x
         y ~ z_on_y * z
         x ~~ y  # Allow x and y to still covary
         x_on_y := x_on_z * z_on_y"
summary(sem(model, data.frame(x=x, z=z, y=y)))
##                   Estimate  Std.Err  z-value  P(&gt;|z|)
##    x_on_z            1.059    0.060   17.594    0.000
##    z_on_y            1.024    0.125    8.164    0.000
##    x_on_y            1.085    0.146    7.406    0.000</code></pre>

<p>So there’s standard errors for you!</p>
<hr>
<h3>Other cases</h3>
<p>This example goes well with a collection of four simpler ("back door")
regression situations, <a href="/20200912-what_should_be_in_your_regression/">What should be in your regression?</a> It goes
especially well with its cousin, <a href="/20210430-a_simple_instrumental_variable/">A simple Instrumental Variable</a>.</p>
<hr>
<h3>More complicated cases</h3>
<p>The <a href="http://www.dagitty.net/">dagitty</a> tools seems to be a great way to analyze a given
situation (expressed as a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>) and figure out what you can do with
it.</p>
<p>Maybe regression discontinuity is another kind of case?</p>    
    ]]></description>
<link>http://planspace.org/20210501-simple_front_door_regression/</link>
<guid>http://planspace.org/20210501-simple_front_door_regression/</guid>
<pubDate>Sat, 01 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>A simple Instrumental Variable</title>
<description><![CDATA[

<p>Instrumental variables can let you estimate effects despite
confounding, which is pretty neat. The idea is sort of that the
instrument helps identify a non-confounded version of a variable, as
illustrated in the over-simplified version of
<a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation#Interpretation_as_two-stage_least_squares">two-stage least squares</a> below.</p>
<p>We seek to estimate the impact of <em>x</em> on <em>y</em>, where they’re both
influenced by <em>u</em>.</p>
<p><img alt="diagram of simple instrumental variable setup" src="simple_iv.jpg"></p>
<p>Unfortunately, <em>u</em> is <em>u</em>nobserved, so we can’t control for it.
But lo, there is <em>z</em> influencing <em>x</em>. Let’s simulate data where all
the true coefficients are one.</p>
<!-- set.seed(42) -->

<pre><code class="language-r">u = rnorm(100)
z = rnorm(100)
x = u + z + rnorm(100)
y = u + x + rnorm(100)</code></pre>

<p>Regressing naively, we get an incorrect estimate for the effect of <em>x</em>
on <em>y</em>.</p>
<pre><code class="language-r">summary(lm(y ~ x))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.35260    0.07697  17.573   &lt;2e-16 ***</code></pre>

<p>Luckily, <em>z</em> is an “instrument,” satisfying three requirements
(following <a href="https://xcelab.net/rm/statistical-rethinking/">McElreath</a>):</p>
<ul>
<li><em>z</em> is independent of <em>u</em></li>
<li><em>z</em> is not independent of <em>x</em></li>
<li><em>z</em> doesn’t influence <em>y</em> except through <em>x</em></li>
</ul>
<p>But how do we use the instrument? Throwing it in the regression makes
things <em>worse</em>:</p>
<pre><code class="language-r">summary(lm(y ~ x + z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.52949    0.09207  16.612  &lt; 2e-16 ***
##  z           -0.54659    0.17099  -3.197  0.00188 **</code></pre>

<p>A fancier model-fitting approach is needed. McElreath points out that
two-stage least squares is not the only way to do this, and also that
there should be some adjustments to make the standard errors make
sense. I’m going to ignore adjustments and just try to get some
intuition from how two-stage least squares works.</p>
<p>Stage one: Do a regression using <em>z</em> to predict <em>x</em>. Then get the
predictions for <em>x</em> from that model, which I’ll call <em>x_from_z</em>. This
uses the independence of <em>z</em> from <em>u</em> to make a “version of” (maybe a
component of) <em>x</em> that is independent of <em>u</em>: the variation of <em>x</em> due
to <em>z</em>.</p>
<p>Stage two: Do a regression using <em>x_from_z</em> to predict <em>y</em>.</p>
<pre><code class="language-r">x_from_z = predict(lm(x ~ z))
summary(lm(y ~ x_from_z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x_from_z     1.03978    0.23886   4.353  3.3e-05 ***</code></pre>

<p>We’ve recovered a fair estimate of the true parameter for <em>x</em>, despite
not using the unobserved confound <em>u</em>!</p>
<p>Here’s the same thing as above but with the <code>ivreg</code> <a href="https://john-d-fox.github.io/ivreg/">package</a>,
correcting the standard error:</p>
<pre><code class="language-r">summary(ivreg(y ~ x | z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.03978    0.13844   7.511 2.77e-11 ***</code></pre>

<p>You could also use <a href="https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo">HMC</a> as in <a href="https://xcelab.net/rm/statistical-rethinking/">McElreath</a> §14.3.</p>
<hr>
<h3>Simpler cases</h3>
<p>This example of an instrumental variable situation extends the earlier
collection of four simpler regression situations,
<a href="/20200912-what_should_be_in_your_regression/">What should be in your regression?</a></p>
<hr>
<h3>More complicated cases</h3>
<p>The <a href="http://www.dagitty.net/">dagitty</a> tools seems to be a great way to analyze a given
situation (expressed as a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>) and figure out what you should
control for and/or whether there are instruments you can use to
estimate a given effect.</p>
<p>There’s also the front-door criterion, which I’m not yet sure how to
fit a model for. Maybe I’ll try to write something up eventually.</p>
<p>Maybe regression discontinuity is another kind of case?</p>    
    ]]></description>
<link>http://planspace.org/20210430-a_simple_instrumental_variable/</link>
<guid>http://planspace.org/20210430-a_simple_instrumental_variable/</guid>
<pubDate>Fri, 30 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Diamond Age, by Stephenson</title>
<description><![CDATA[

<p>This <a href="https://www.nealstephenson.com/the-diamond-age.html">novel</a> about an educational book invites comparison to its
subject. Stephenson's pedagogy walks you through Chekhov's armory,
dense with mental condensation nuclei, firing guns at the end but
maintaining ambiguity. Steam punk nanotech is backdrop for a My Fair
Lady story and revolution, with themes of <a href="https://en.wikipedia.org/wiki/Mind%E2%80%93body_dualism">dualism</a> and generally
flawed humans.</p>
<p><img alt="cover" src="cover.jpg"></p>
<h3>Economics and technology</h3>
<p>I read Diamond Age because it was mentioned in <a href="https://planspace.org/20210401-trekonomics_by_saadia/">Trekonomics</a>. They
have a technology like a replicator, but it doesn't really feel like a
post-scarcity world because its use is centrally controlled/limited.</p>
<blockquote>
<p>"... the Feed is not a system of control and oppression, as CryptNet
would maintain. It is the only way order can be maintained in modern
society—if everyone possessed a Seed, anyone could produce weapons
whose destructive power rivalled that of Elizabethan nuclear
weapons." (page 384, Hackworth speaking unconvincingly)</p>
</blockquote>
<p>The Seed, never quite achieved in the book, is a nanotech magic bean
that promises to usher in a decentralized post-scarcity world, like
farming communes where you can grow anything effortlessly, biological
or mechanical. Its creation is opposed by the less obviously
destructive factions based on fear of loss of control.</p>
<p>Some of the rich and powerful are referred to as "Equity Lords," which
is an interesting title, especially in relation to modern tech
companies where people have equity to varying degrees, or more
generally in connection with people who own stock in the markets.</p>
<h3>Anti-relativism</h3>
<blockquote>
<p>"Finkle-McGraw began to develop an opinion that was to shape his
political views in later years, namely, that while people were not
<em>genetically</em> different, they were <em>culturally</em> as different as they
could possibly be, and that some cultures were simply better than
others. This was not a subjective value judgment, merely an
observation that some cultures thrived and expanded while others
failed. It was a view implicitly shared by nearly everyone but, in
those days, never voiced." (pages 20-21)</p>
<p>"[Nell's mother] didn't like craftsmen, she said, because they were
too much like actual Victorians, always spouting all kinds of crap
about how one thing was better than another thing, which eventually
led, she explained, to the belief that some people were better than
others." (page 185)</p>
<p>"it is upon moral qualities that a society is ultimately founded.
All the prosperity and technological sophistication in the world is
of no use without that foundation—we learned this in the late
twentieth century, when it became unfashionable to teach these
things." (page 322, Miss Matheson speaking)</p>
</blockquote>
<p>The "Neo-Victorian" group is largely a reaction to techno-hedonism. It
reminds me of how it can seem these days that wealthier people are
more likely to choose old-fashioned wooden toys and the like for their
children, more likely to avoid screen time.</p>
<p>In the extreme, I think this kind of view takes a form like
<a href="https://www.amazon.com/Absolute-Relativism-Dictatorship-What-about/dp/1933919469">Absolute Relativism: The New Dictatorship</a>.</p>
<h3>Rugged individualism</h3>
<blockquote>
<p>"Grandfather loved to tell stories of these criminals, how they had
tried to excuse their own crimes by pleading that they were
economically disadvantaged or infected with the disease of substance
abuse, and how the Lone Eagles—many of whom had overcome poverty or
addiction themselves—had dispatched them with firing squads and left
them posted around the edge of their territory as NO TRESPASSING
signs that even the illiterate could read." (pages 405-406)</p>
<p>"... the usual crowd of starving peasants and professional amputees"
(page 449)</p>
</blockquote>
<p>For one thing, it's pretty clearly not a post-scarcity society. For
another, it's not very shy about seeming to blame people for not doing
better for themselves despite this.</p>
<h3>Tribalism</h3>
<p>There's a lot of tribalism, much of it racial/racist. I think the
reasoning was that with the dissolution of traditional governments,
people needed to form their own equivalents more than they previously
did, but this wasn't super clear to me.</p>
<p>The major conflict, which develops mostly in the background until the
end of the book, is a second <a href="https://en.wikipedia.org/wiki/Boxer_Rebellion">Boxer Rebellion</a>.</p>
<p>It's not clear whether the ends justify the means, but there's at
least a chance the Seed could be a good idea. Would tribalism recede
in a true post-scarcity environment?</p>
<h3>Dualism</h3>
<p>Nanotechnology represents the material, physical world.</p>
<blockquote>
<p>"But [Hackworth, the nanotech engineer] had felt the need to go
beyond that—he had wanted to reach beyond mere matter and into
someone's soul." (page 188)</p>
</blockquote>
<p>Mercifully, there's no mention of quantum mechanics to introduce false
confusion. The technology is very physical in the classical sense;
nanotech computers use "rod logic" to achieve their results. With the
Neo-Victorians, it contributes to a steam punk vibe.</p>
<p>The discussion of dualism is extended to computing, with a substantial
exploration of Turing machines.</p>
<blockquote>
<p>"... a Turing machine, no matter how complex, was not human. It had
no soul. It could not do what a human did." (page 442)</p>
</blockquote>
<p>There's also no mention of <a href="https://en.wikipedia.org/wiki/Hypercomputation">hypercomputation</a>... An amusing thought:
is hypercomputation fundamentally dualist (implying non-physical
phenomena)?</p>
<h3>Education</h3>
<p>I'm interested in educational technology. It's largely <a href="/20201028-failure_to_disrupt_by_reich/">failed</a> to
revolutionize education so far, but many like <a href="https://moores.samaltman.com/">Altman</a> hold out hope
for "AI teachers that can diagnose and explain exactly what a student
doesn’t understand" and the like.</p>
<p>What is the goal of education? The instigator of the creation of the
AI teaching books says he wants to encourage subversion, but he also
thinks the effect of this will be creating people who tend to agree
with him.</p>
<blockquote>
<p>"You encourage subversiveness because you think that it will have an
effect opposite to what one might naively suppose." (page 365, Carl
Hollywood addressing Finkle-McGraw)</p>
</blockquote>
<p>Of the girls who get the three "original" books with voices done by
remote human voice actors, one girl becomes an actor in a strange
troupe, one joins a faction opposed to that of Finkle-McGraw (though
he thinks she'll return eventually), and one works scripts at a
specialist brothel and then eventually stymies (at least briefly) a
revolution that threatens a person she loves. Is this successful
education? Maybe?</p>
<p>There are also hundreds of thousands of girls who were raised by books
with computer-generated voices. Their books were also further modified
by Hackworth.</p>
<blockquote>
<p>"At this point, John Percival Hackworth, almost without thinking
about it and without appreciating the ramifications of what he was
doing, devised a trick and slipped it in under the radar of the
Judge and Dr. X and all of the other people in the theatre, who were
better at noticing tricks than most other people in the world.
"While I'm at it, if it pleases the court, I can also," Hackworth
said, most obsequiously, "make changes in the content so that it
will be more suitable for the unique cultural requirements of the
Han readership."" (page 180)</p>
</blockquote>
<p>Everybody who gets the Chinese-language version of the Primer goes on
to form the "mouse army" that serves Nell for unclear reasons toward
the end of the book.</p>
<p>Diamond Age definitely suggests that valuable aspects of human
development work best (or only) through human interaction. Multiple
times the importance of culture generally is emphasized. The AI book
is not necessarily any more enlightened than other kinds of education.
Maybe it can stand in for ed tech that is just a computerized version
of antique methods, despite all its customization.</p>
<p>There are other comments about education, but Stephenson sometimes
seems to be effectively free-associating, suggesting different aspects
to connect and consider.</p>
<hr>
<h3>More selected quotes</h3>
<hr>
<blockquote>
<p>"By nature, men are nearly alike; by practice, they get to be wide
apart." (epigraph, quoting <a href="https://china.usc.edu/confucius-analects-17">Confucius</a>)</p>
</blockquote>
<hr>
<blockquote>
<p>"A sizable investment, but the best a father could make." (page 78,
referring to education)</p>
</blockquote>
<hr>
<blockquote>
<p>"... Nell knew better than to fret over things she could not
change." (page 123)</p>
</blockquote>
<p>The Primer seems to have helped make Nell a <a href="/20210107-enchiridion_in_52_sentences/">stoic</a>.</p>
<hr>
<blockquote>
<p>"If the Coastal Republic had believed in the <em>existence</em> of virtue,
it could at least have aspired to hypocrisy." (page 144)</p>
</blockquote>
<hr>
<blockquote>
<p>"He is worth a thousand lesser engineers." (page 170, Dr. X
referring to Hackworth)</p>
</blockquote>
<hr>
<p>On page 184, the Primer is described as "a <a href="https://en.wikipedia.org/wiki/Propaedeutics">Propædeutic</a>
Enchiridion."</p>
<hr>
<blockquote>
<p>"She often put it under her pillow, though, and sometimes she even
woke up in the middle of the night and heard it whispering things to
her that she had just been dreaming about." (page 184)</p>
</blockquote>
<p>This seems to imply that the Primer employed some kinds of
subconscious programming techniques...</p>
<hr>
<blockquote>
<p>"But I think it is not likely to be the only instance in which real
life turns out to be more complicated than what you have seen in the
book." (page 281, Constable Moore speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>""Nell," the Constable continued, indicating through his tone of
voice that the lesson was concluding, "the difference between
ignorant people and educated people is that the latter know more
facts. But that has nothing to do with whether they are stupid or
intelligent. The difference between stupid and intelligent
people—and this is true whether or not they are well-educated—is
that intelligent people can handle subtlety. They are not baffled by
ambiguous or even contradictory situations—in fact, they expect them
and are apt to become suspicious when things seem overly
straightforward.</p>
<p>"In your Primer you have a resource that will make you highly
educated, but it will never make you intelligent. That comes from
life. Your life up to this point has given you all of the experience
you need to be intelligent, but you have to think about those
experiences. If you don't think about them, you'll be
psychologically unwell. If you do think about them, you will become
not merely educated but intelligent" (page 283)</p>
</blockquote>
<hr>
<blockquote>
<p>"She appears to be learning new material that isn't explicitly
covered in the Primer, and she's developing more sophisticated forms
of social interaction, suggesting that she's spending more time
around a higher class of people." (pages 284-285, Miranda speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>"And there was an ocean of history to be learned: first biblical,
Greek, and Roman, and then the history of many other peoples around
the world that essentially served as backdrop for History of the
English-Speaking Peoples." (page 312, describing the stodgy school)</p>
</blockquote>
<hr>
<blockquote>
<p>"Miss Stricken handled the big payoff at the end of each period and
at the end of each unit. She stormed in to explain what conclusion
they were being led to and to make sure that all of them got it."
(page 313)</p>
</blockquote>
<hr>
<blockquote>
<p>"She was tormented by the irrationality of this place." (page 319,
referring to the stodgy school)</p>
</blockquote>
<hr>
<blockquote>
<p>"Now, there was a time when we believed that what a human mind could
accomplish was determined by genetic factors. Piffle, of course, but
it looked convincing for many years, because distinctions between
tribes were so evident. Now we understand that it's all cultural.
That, after all, is what a culture is—a group of poeple who share in
common certain acquired traits." (page 321, Miss Matheson speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>"It is the hardest thing in the world to make educated Westerners
pull together," Miss Matheson went on. "That is the job of people
like Miss Stricken. We must forgive them their imperfections. She is
like an avatar—do you children know about avatars? She is the
physical embodiment of a principle. That principle is that outside
the comfortable and well-defended borders of our phyle is a hard
world that will come and hurt us if we are not careful. It is not an
easy job to have. We must all feel sorry for Miss Stricken." (page
323)</p>
</blockquote>
<hr>
<p>On pages 353 and 354 Miss Matheson goes on about how Nell is special.
"You are different." and so on. Are we supposed to believe her, or is
this just an aspect of the stodgy school weirdness? Other aspects of
the book don't seem aligned with Great Man thinking.</p>
<hr>
<blockquote>
<p>""Which path do you intend to take, Nell?" said the Constable,
sounding very interested. "Conformity or rebellion?""</p>
<p>""Neither one. Both ways are simple-minded—they are only for people
who cannot cope with contradiction and ambiguity."" (page 356)</p>
</blockquote>
<p>She goes to seek her fortune as a writer for a particularly involved
brothel.</p>
<hr>
<blockquote>
<p>""... [Miranda] was not merely Nell's tutor. She became Nell's
mother."" (page 357, Carl Hollywood speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>""In a tribe such as the F.D.R. [First Distributed Republic], whose
view of the universe contains no absolutes, this ritual
[elaborate trust-falls] creates an artificial absolute."" (page 378,
Hackworth explaining)</p>
</blockquote>
<hr>
<p>On page 383 there's a "thirty-third level" which seems like a
throwaway reference to Masonry...</p>
<hr>
<blockquote>
<p>"... Princess Nell had become so beautiful over the years and had
developed such a fine bearing that few people would mistake her for
a commoner now, even if she were dressed in rags and walking
barefoot."</p>
<p>"... Nell wondered at that. Princesses were not genetically
different from commoners." (page 386)</p>
</blockquote>
<hr>
<blockquote>
<p>"learning the language, which was extremely pithy and made heavy use
of parentheses."</p>
</blockquote>
<p>Some Lisp? Cute reference.</p>
<hr>
<blockquote>
<p>"Her stories were being digested, not by the Primer, but by another
human being, becoming a part of that person's mind." (pages 402-403)</p>
</blockquote>
<hr>
<blockquote>
<p>"But the Primer was, itself, a Turing machine, or so she suspected;
so how could it understand Nell?"</p>
<p>"Could it be that the Primer was just a conduit, a technological
system that mediated between Nell and some human being who really
loved her?" (page 403)</p>
</blockquote>
<p>Miranda provides the voicing for whatever the Primer wants to say.</p>
<hr>
<blockquote>
<p>""Belief isn't a binary state, not here at least. Does anyone
believe anything one hundred percent?"" (page 425)</p>
</blockquote>
<hr>
<blockquote>
<p>""Society has never been good at answering these questions—the sorts
of questions you can't just look up in a reference database."" (page
428)</p>
</blockquote>
<hr>
<blockquote>
<p>"But the human mind didn't work like a digital computer and was
capable of doing some funny things." (page 433)</p>
</blockquote>
<hr>
<blockquote>
<p>"It would be more correct to say that, although it was virtuous to
save them, it was mistaken to believe that they could be raised
properly. We lacked the resources to raise them individually, and so
we raised them with books. But the only proper way to raise a child
is within a family. The Master <a href="https://china.usc.edu/confucius-analects-17">Confucius</a> could have told us as
much, had we listened to his words." (page 455, Dr. X speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>"... all of Nell's intellect, her vast knowledge and skills,
accumulated over a lifetime of intensive training, meant nothing at
all when she was confronted with a handful of organized peasants."
(page 469)</p>
</blockquote>
<hr>
<blockquote>
<p>"all of the societies that had grown up around the concept of a
centralized, hierarchical Feed." (page 498)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210422-the_diamond_age_by_stephenson/</link>
<guid>http://planspace.org/20210422-the_diamond_age_by_stephenson/</guid>
<pubDate>Thu, 22 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Learn You a Haskell for Great Good! by Lipovača</title>
<description><![CDATA[

<p>Here's a good <a href="http://learnyouahaskell.com/">book</a> you can read for free. Like it says on the
back, "Maps, Monads, Monoids, and More!" It does a great job
explaining things in ways that are helpful. The humble list can be a
functor, an applicative functor, a monoid, and a monad.</p>
<p>There's a <a href="http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html">joke</a>: "A monad is just a monoid in the category of
endofunctors, what's the problem?" This is like saying "the median is
just a medoid on the field of reals."</p>
<p>In both cases, if you don't know what the first term is, you likely
don't know what the others are. It's not a good way to explain.</p>
<p>In both cases, the explanatory terms are needlessly obscure: "endo" is
likely gratuitous; "field of reals" is probably not better than
"numbers".</p>
<p>Also in both cases, the explanation isn't complete; it describes
without defining. For the median, the L1 norm has to be specified. For
monads, the monoid function has to be <code>join</code>. See also
<a href="https://stackoverflow.com/questions/3870088/a-monad-is-just-a-monoid-in-the-category-of-endofunctors-whats-the-problem">Crockett's explanation</a> and my <a href="/20150125-monads_by_diagram/">pictures</a> showing how <code>map</code> and
<code>join</code> give you <code>bind</code>.</p>
<p>I'm not giving a complete explanation here either. Read the book! It
has <a href="https://en.wikipedia.org/wiki/Zipper_(data_structure)">zippers</a> too!</p>
<hr>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<p>Forcing non-pure stuff into <code>do</code> blocks, as seems common in Haskell,
is very reminiscent of the <a href="https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell">functional core, imperative shell</a>
pattern.</p>
<hr>
<p>Haskell's pattern-matching (often instead of conditionals) is pretty
neat. Python is getting <a href="https://mathspp.com/blog/pydonts/pattern-matching-tutorial-for-pythonic-code">something analogous</a> in 3.10.</p>
<hr>
<p>Haskell's type inference gives behavior sort of like coercion in other
languages, but without the craziness. So <code>3 + 4.5</code> will work like
you'd expect, but there's no chance <code>'3' + 4.5</code> will turn out to be
<code>'34.5'</code> (which is what happens in JavaScript).</p>
<hr>
<p>Haskell has a funny quirk in some of its ranges:</p>
<pre><code>ghci&gt; [0.1, 0.3 .. 1]
[0.1,0.3,0.5,0.7,0.8999999999999999,1.0999999999999999]</code></pre>

<p>It's surprising that 1.1 is in there, when 1 was the upper bound. This
is because of a rule that if the value is within half the step size
(for floats and things like them) then it gets included in the result.
Wacky!</p>
<hr>
<blockquote>
<p>"<em>Sets and maps from <code>Data.Set</code> and <code>Data.map</code> are implemented using
trees, but instead of normal binary search trees, they use</em> balanced
<em>binary search trees.</em>" (page 135)</p>
</blockquote>
<p>Interesting! Usually these would be hash maps... Hmm! The closest
Haskell gets to a "normal" hash map (I think <a href="https://hackage.haskell.org/package/unordered-containers-0.2.13.0/docs/Data-HashMap-Strict.html">this</a>?) is implemented
with <a href="https://en.wikipedia.org/wiki/Hash_array_mapped_trie">hash array mapped tries</a>. Also good for persistence (meaning
re-using things in memory rather than creating everything from
scratch, because we don’t mutate). Fun!</p>
<hr>
<blockquote>
<p>"We can read the type of <code>putStrLn</code> like this: <code>putStrLn</code> takes a
string and returns an <em>I/O action</em> that has a result type of <code>()</code>
(that is, the empty tuple, also known as <em>unit</em>)." (page 155)</p>
</blockquote>
<p>The wiki for <a href="https://en.wikipedia.org/wiki/Unit_type">unit type</a> is helpful for understanding why it's
called that.</p>
<hr>
<p>On page 275, he defines a pipe operator with <code>x -: f = f x</code>. Pretty
neat!</p>
<hr>
<blockquote>
<p>"While similar to a normal list, a <em>difference list</em> is actually a
function that takes a list and prepends another list to it. For
example, the difference list equivalent of a list like <code>[1,2,3]</code> is
the function <code>\xs -&gt; [1,2,3] ++ xs</code>. A normal empty list is <code>[]</code>,
whereas an empty difference list is the function <code>\xs -&gt; [] ++ xs</code>."
(page 307)</p>
</blockquote>
<p>And so we get efficient appending to linked lists!</p>
<hr>
<blockquote>
<p>"the function monad is also called the <em>reader monad</em>." (page 312)</p>
</blockquote>
<hr>
<blockquote>
<p>"For instance, if we have <code>Just (Just 9)</code>, can we make that into
<code>Just 9</code>? It turns out that any nested monadic value can be
flattened and that this is actually a property unique to monads."
(page 326)</p>
</blockquote>
<p>This makes it sound fancier than it is, I think because the author
talks about <code>bind</code> more than <code>join</code> and doesn't talk about the
<a href="/20150125-monads_by_diagram/">relationship between them</a>.</p>
<hr>
<blockquote>
<p>"We don't usually set out to make a monad with the sole purpose of
making a monad. Rather, we make a type whose purpose is to model an
aspect of some problem, and then later on, if we see that the type
represents a value with a context and can act like a monad, we give
it a <code>Monad</code> instance." (page 336)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210411-learn_you_a_haskell_for_great_good_by_lipovaca/</link>
<guid>http://planspace.org/20210411-learn_you_a_haskell_for_great_good_by_lipovaca/</guid>
<pubDate>Sun, 11 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>How to Lie with Statistics, by Huff</title>
<description><![CDATA[

<p><a href="https://en.wikipedia.org/wiki/Darrell_Huff">Darrell Huff</a> and his <a href="https://en.wikipedia.org/wiki/How_to_Lie_with_Statistics">popular 1954 book</a> have <a href="/20210330-how_to_make_the_world_add_up_by_harford/">received</a>
criticism. Huff was wrong about cigarettes and cancer, but he did warn
us that people are biased. In 142 breezy pages, the book manages to
cover quite a lot, with perhaps moderate levels of prejudice for its
time.</p>
<p><img alt="cover" src="cover.jpg"></p>
<ul>
<li>Chapter 1: “The Sample with the Built-in Bias” (sampling)</li>
<li>Chapter 2: “The Well-Chosen Average” (mean vs. median)</li>
<li>Chapter 3: “The Little Figures That Are Not There” (variance etc.)</li>
<li>Chapter 4: “Much Ado about Practically Nothing” (small differences and measurement uncertainty)</li>
<li>Chapter 5: “The Gee-Whiz Graph” (funny y-axes)</li>
<li>Chapter 6: “The One-Dimensional Picture” (dimensional distortion of comparisons)</li>
<li>Chapter 7: “The Semiattached Figure” (non-sequitur logic)</li>
<li>Chapter 8: “Post Hoc Rides Again” (correlation ≠ causation)</li>
<li>Chapter 9: “How to Statistculate” (“statistically
   manipulate”—nonsense math)</li>
<li>Chapter 10: “How to Talk Back to a Statistic” (ask questions)<ul>
<li>“Who says so?”</li>
<li>“How does he know?”</li>
<li>“What’s missing?”</li>
<li>“Did somebody change the subject?”</li>
<li>“Does it make sense?”</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>"There are at least three levels of sampling involved. Dr. Kinsey's
samples of the population (one level) are far from random ones and
may not be particularly representative, but they are enormous
samples by comparison with anything done in his field before and his
figures must be accepted as revealing and important if not
necessarily on the nose. It is possibly more important to remember
that any questionnaire is only a sample (another level) of the
possible questions and that the answer the lady gives is no more
than a sample (third level) of her attitudes and experiences on each
question." (page 23)</p>
</blockquote>
<hr>
<blockquote>
<p>"Some of the strongest feeling against public-opinion polls is found
in liberal or left-wing circles, where it is rather commonly
believed that polls are generally rigged. Behind this view is the
fact that poll results so often fail to square with the opinions and
desires of those whose thinking is not in the conservative
direction. Polls, they point out, seem to elect Republicans even
when voters shortly thereafter do otherwise." (page 26)</p>
</blockquote>
<p>Interesting historical perspective; modern concerns about polls are
not necessarily new issues.</p>
<hr>
<blockquote>
<p>"You will also learn if you read back into the tables that the
figure is based on a sample of such size that there are nineteen
chances out of twenty that the estimate—$3,107 before it was
rounded—is correct within a margin of $59 plus or minus." (pages
35-36)</p>
</blockquote>
<p>I don’t know a confidence interval technique that will give you quite
that interpretation; this could be erroneous.</p>
<hr>
<p>"Degree of significance" (p-value) is presented on page 42 as a thing
that is usually hidden from the public, which may have been (and may
still often be) the case. These days I hear more about problems with
significance tests than demands for them.</p>
<hr>
<blockquote>
<p>"It is dangerous to mention any subject having high emotional
content without hastily saying where you are for or agin it." (page
46, amusing spelling in original)</p>
</blockquote>
<hr>
<blockquote>
<p>"The <a href="https://en.wikipedia.org/wiki/Procrustes">Procrustean</a> Statistic" (graphic page 43)</p>
</blockquote>
<hr>
<blockquote>
<p>"In somewhat the same fashion those little figures
[reporting variance] that are missing from what are called
“Gessell’s norms” have produced pain in papas and mamas. Let a
parent read, as many have done in such places as Sunday rotogravure
sections, that “a child” learns to sit erect at the age of so many
months and he thinks at once of his own child. Let his child fail to
sit by the specified age and the parent must conclude that his
offspring is “retarded” or “subnormal” or something equally
invidious. Since half the children are bound to fail to sit by the
time mentioned, a good many parents are made unhappy. Of course,
speaking mathematically, this happiness is balanced by the joy of
the other fifty per cent of parents in discovering that their
children are “advanced.” But harm can come of the efforts of the
unhappy parents to force their children to conform to the norms and
thus be backward no longer." (pages 44-45)</p>
</blockquote>
<hr>
<blockquote>
<p>"<em>Newsweek</em> once showed how “U. S. Old Folks Grow Older” by means of
a chart on which appeared two male figures, one representing the
68.2-year life expectancy of today, the other the 34-year life
expectancy of 1879-1889.'"</p>
</blockquote>
<p>Here Huff is complaining that the person twice as tall appears 8 times
as massive, but there are other issues with interpreting
<a href="/20200806-life_expectancy_is_historically_misleading/">historical life expectancy</a>...</p>
<hr>
<blockquote>
<p>"Who knows what germ causes colds, particularly since it probably
isn’t a germ at all?" (page 75)</p>
</blockquote>
<p>What does he think causes colds? They knew about viruses in the 50s,
didn’t they?</p>
<hr>
<blockquote>
<p>"Let us say that during a period in which race prejudice is growing
you are employed to “prove” otherwise. It is not a difficult
assignment. Set up a poll or, better yet, have the polling done for
you by an organization of good reputation. Ask that usual cross
section of the population if they think blacks have as good a chance
as white people to get jobs. Repeat your polling at intervals so
that you will have a trend to report.</p>
<p>"Princeton’s Office of Public Opinion Research tested this question
once. What turned up is interesting that things, especially in
opinion polls, are not always what they seem. Each person who was
asked the question about jobs was also asked some questions designed
to discover if he was strongly prejudiced against blacks. It turned
out that people most strongly prejudiced were most likely to answer
Yes to the question about job opportunities. (It worked out that
about two-thirds of those who were sympathetic toward blacks did not
think the black had as good a chance at a job as a white person did,
and about two-thirds of those showing prejudice said that blacks
were getting as good breaks as whites.) It was pretty evident that
from this poll you would learn very little about employment
conditions for blacks, although you might learn some interesting
things about a man’s racial attitudes." (pages 75-76)</p>
</blockquote>
<p>A couple striking dehumanizing "blacks" vs. "white people" phrasings
here. The reportage of veiled (?) racism in survey responses still
seems relevant today.</p>
<hr>
<blockquote>
<p>"A civilian population includes infants, the old, and the ill, all
of whom have a higher death rate wherever they are." (page 85)</p>
</blockquote>
<p>It’s incidental to the point of the text here, but it’s interesting to
see a reference to infants having a high death rate. I think this
sounds out of place, today. When Huff was born in 1913, something like
ten percent of babies died before age five.
(<a href="/20200806-life_expectancy_is_historically_misleading/">historical life expectancy</a>)</p>
<hr>
<blockquote>
<p>"Keep in mind that a correlation may be real and based on real cause
and effect—and still be almost worthless in determining action in
any single case." (page 93)</p>
</blockquote>
<p>I read this as pointing to variability. Was he already thinking about
smoking?</p>
<hr>
<blockquote>
<p>"But arbitrarily rejecting statistical methods makes no sense
either. That is like refusing to read because writers sometimes use
words to hide facts and relationships rather than to reveal them."
(page 121)</p>
</blockquote>
<hr>
<blockquote>
<p>"I’ll face up to the serious purpose that I like to think lurks just
beneath the surface of this book: explaining how to look a phony
statistic in the eye and face it down; and no less important, how to
recognize sound and usable data in that wilderness of fraud to which
the previous chapters have been largely devoted." (page 122)</p>
</blockquote>
<hr>
<blockquote>
<p>"You may be familiar with the Rudolf Flesch readability formula. It
purports to measure how easy a piece of prose is to read, by such
simple and objective items as length of words and sentences. Like
all devices for reducing the imponderable to a number and
substituting arithmetic for judgment, it is an appealing idea."
(page 137)</p>
</blockquote>
<p>I’m interested in the <a href="https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests">readability stuff</a>, but it also strikes me
that the last sentence there is quite a good joke:</p>
<blockquote>
<p>"Like all devices for reducing the imponderable to a number and
substituting arithmetic for judgment, it is an appealing idea."</p>
</blockquote>
<p>That could be an epigraph!</p>    
    ]]></description>
<link>http://planspace.org/20210405-how_to_lie_with_statistics_by_huff/</link>
<guid>http://planspace.org/20210405-how_to_lie_with_statistics_by_huff/</guid>
<pubDate>Mon, 05 Apr 2021 12:00:00 -0500</pubDate>
</item>
  </channel>
</rss>
