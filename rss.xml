<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>plan ➔ space</title>
    <link>http://planspace.org/</link>
    <description>plan space from outer nine</description>
    <language>en-us</language>
    <atom:link href="http://planspace.org/rss.xml" rel="self" type="application/rss+xml" />
<item>
<title>How to be a pro (Halmos)</title>
<description><![CDATA[

<p>This is a section (pages 264-268) from
<a href="https://smile.amazon.com/I-Want-be-Mathematician-Automathography/dp/0387960783/">I want to be a mathematician</a>, by Halmos.</p>
<blockquote>
<p>Anna, one of the mathematics department secretaries at Chicago,
complained to me once when we met at a party and she had already
consumed several gin and tonics. She was a good typist, and she
didn't have much trouble picking up the art of technical,
mathematical, typing—but she hated every minute of it. You have to
look at every symbol separately, you have to keep changing "typits"
or Selectric balls, you have to shift a half space up or down for
exponents and subscripts, and you have no idea what you're doing.
"I'm not going to spend my life flipping that damned carriage up and
down", she said.</p>
<p>Another time Bruno, a well-known mathematician, asked me: "How did
you manage to make your ten lectures at the CBMS conference all the
same length? Isn't it true that some things take longer? When I did
it, some of my talks were 45 minutes, and some 75."</p>
<p>More recently still I asked Calvin, a colleague, "Can you give a
graduate student a ride to this month's Wabash functional analysis
seminar?" "No", he said, "you better get someone else. I've been
away, giving colloquium talks twice this month, and that's enough
travelling."</p>
<p>I didn't make up any of this (except the names). Do you see what
these three stories have in common? To me it's obvious, it jumps to
the eye, and it horrifies me. What Anna, Bruno, and Calvin share and
express is widespread and bad: it's the "me" attitude. It is the
attitude that says "I do only what's important to me, and I am more
important to me than the profession."</p>
<p>I think an automobile transmission mechanic should try to be the
best automobile transmission mechanic he has the talent to be, and
butlers, college presidents, shoe salesmen, and hod-carriers should
aim for perfection in their professions. Try to rise, improve
conditions if you can, and change professions if you must, but as
long as you are a hod-carrier, keep carrying those hods. If you set
out to be a mathematician, you must learn the profession, every part
of it, and then work at it, profess it, live it as best you can. If
you keep asking "what's there in it for me?", you're in the wrong
business. If you're looking for comfort, money, fame, and glory, you
probably won't get them, but if you keep trying to be a
mathematician, you might.</p>
<p>I didn't preach to Calvin, but if I had done so, my sermon would
have said that you support an activity such as the Wabash seminar
(I'll tell more about that seminar later) without even thinking
about it—it's an integral part of professional life. You go to such
seminars the way you get dressed in the morning, nod amiably to an
acquaintance you pass on the street, or brush your teeth before you
go to bed at night. Sometimes you feel like doing it and sometimes
not, but you do it always—it's a part of life and you have no
choice. You don't expect to get rewarded if you do and punished if
you don't, you don't think about it—you just do it.</p>
<p>A professional must know every part of his profession and (we all
hope) like it, and in the profession of mathematics, as in most
others, there are many parts to know. To be a mathematician you have
to know how to be a janitor, a secretary, a businessman, a
conventioneer, an educational consultant, a visiting lecturer, and,
last but not least, in fact above all, a scholar.</p>
<p>As a mathematician you will use blackboards, and you should know
which ones are good and what is the best way and the best time to
clean them. There are many kinds of chalk and erasers; would you
just as soon make do with the worst? At some lecture halls you have
no choice—you must use the overhead projector, and if you don't come
prepared with transparencies, your audience will be in trouble. Word
processors and typewriters, floppy disks and lift-off
ribbons—ignorance is never preferable to bliss. Should you ditto
your preprints, or use mimeograph, or multilith, or xerox? Who
should make decisions about these trivialities—you, or someone who
doesn't care about your stuff at all?</p>
<p>From time to time you'll be asked for advice. A manufacturer will
consult you about the best shape for a beer bottle, a dean will
consult you about the standing of his mathematics department, a
publisher will consult you about the probably sales of a proposed
textbook on fuzzy cohomology. Possibly they will be genteel and not
even mention paying for your service; at other times they will refer
delicately to an unspecified honorarium that will be forthcoming.
Would they treat a surgeon the same way, or an attorney, or an
architect? Would you? Could you?</p>
<p>I am sometimes tempted to tell people that I am a <em>real</em> doctor,
not the medical kind; my education lasted a lot longer than their
lawyer's and cost at least as much; my time and expertise are worth
at least as much as their architect's. In fact, I do not use tough
language, but I've long ago decided not to accept "honoraria" but to
charge fees, carefully spelled out and agreed on in advance. I set
my rates some years back, when I was being asked to review more
textbooks than I had time for. I'd tell the inquiring publisher that
my fee is $1.00 per typewritten page or $50.00 per hour, whichever
comes to less. Sometimes the answer was: "Oh, sorry, we didn't
really want to spend that much", and at other times it was,
matter-of-factly, "O.K., send us your bill along with your report".
The result was that I had less of that sort of work to do and got
paid more respectably for what I still did. My doctor, lawyer, and
architect friends tell me that prices have changed since I
established mine. The time has com, they say, to double the charges.
The answers, they predict, will remain the same: half "no" and half
"sure, of course".</p>
<p>A professional mathematician talks about mathematics at lunch and
at tea. The subject doesn't have to be hot new theorems and proofs
(which can make for ulcers or ecstasy, depending)—it can be a new
teaching twist, a complaint about a fiendish piece of student
skullduggery, or a rumor about an error in the proof of the four
color theorem. At many good universities there is a long-standing
tradition of brown-bag (or faculty club) mathematics lunches, and
they are an important constituent of high quality. They keep the
members of the department in touch with one another; they make it
easy for each to use the brains and the memory of all. At a few
universities I had a hand in establishing the lunch tradition, which
then took root and flourished long after I left.</p>
<p>The pros go to colloquia, seminars, meetings, conferences, and
international congresses—and they use the right word for each. The
pros invite one another to give colloquium talks at their
universities, and the visitor knows—should know—that his duty is not
discharged by one lecture delivered between 4:10 and 5:00 p.m. on
Thursday. The lunch, which gives some of the locals a chance to meet
and have a relaxed conversation with the gues, the possible
specialists' seminar for the in-group at 2:00, the pre-lecture
coffee hour at 3:00, and the post-lecture dinner and evening party
are essential parts of the visitor's job description. It makes for
an exhausting day, but that's how it goes, that's what it means to
be a colloquium lecturer.</p>
<p>Sometimes you are not just a colloquium lecturer, but the "Class of
1909 distinguished Visitor", invited to spend a whole week on the
campus, give two or three mathematics talks and one "general"
lecture, and, in between, mingle, consult, and interact. Some do it
by arriving in time for a Monday afternoon talk, squeezing in a
Tuesday colloquium at a sister university 110 miles down the road,
reappearing for a Wednesday talk and a half of Thursday (spent
mostly with the specialist crony who arranged the visit), and
catching the plane home at 6:05 p.m. Bad show—malfeasance and
nonfeasance—that's not what the idea is at all. When Bombieri came
to Bloomington, I understood much of his first lecture, almost none
of the second, and gave up on the third (answered my mail
instead)—but I got a lot out of his presence. I heard him hold forth
on meromorphic functions at lunch on Monday, explain the Mordell
conjecture over a cup of coffee Wednesday afternoon, and at dinner
Friday evening guess at the probably standing of Euler and Gauss a
hundred years from now. We also talked about clocks and children and
sport and wine. I learned some mathematics and I got a little
insight into what makes one of the outstanding mathematicians of our
time tick. He earned his keep as Distinguished Visitor, not because
he is a great mathematician (that helps!) but because he took the
job seriously. It didn't take his talent to do that; that's
something us lesser people can do too.</p>
<p>Mathematical talent is probably congenital, but aside from that the
most important attribute of a genuine professional mathematician is
scholarship. The scholar is always studying, always ready and eager
to learn. The scholar knows the connections of his specialty with
the subject as a whole; he knows not only the technical details of
his specialty, but its history and its present standing; he knows
about the others who are working on it and how far they have
reached. He knows the literature, and he trusts nobody: he himself
examines the original paper. He acquires firsthand knowledge no only
of its intellectual content, but also of the date of the work, the
spelling of the author's name, and the punctuation of the title; he
insists on getting every detail of every reference absolutely
straight. The scholar tries to be as broad as possible. No one can
know all of mathematics, but the scholar can succeed in knowing the
outline of it all: what are its parts and what are their places in
the whole?</p>
<p>These are the things, some of the things, that go to make up a
pro.</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210820-how_to_be_a_pro_halmos/</link>
<guid>http://planspace.org/20210820-how_to_be_a_pro_halmos/</guid>
<pubDate>Fri, 20 Aug 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Books for Machine Learning</title>
<description><![CDATA[

<blockquote>
<p>"for someone that doesn't have a lot of experience with machine
learning, what books would you recommend starting with? machine
learning for dummies?"</p>
</blockquote>
<hr>
<div style="display:block; float:left;">

<a href="https://www.statlearning.com/">
<img src="intro_stat_learn.png" alt="Introduction to Statistical Learning" width="24%">
</a>

<a href="https://www.manning.com/books/deep-learning-with-python">
<img src="dl_with_py.png" alt="Deep Learning with Python" width="24%">
</a>

<a href="/20210508-statistical_rethinking_by_mcelreath/">
<img src="stat_rethink.jpg" alt="Statistical Rethinking" width="24%">
</a>

<a href="http://www.mmds.org/">
<img src="mine_massive.jpg" alt="Mining of Massive Datasets" width="24%">
</a>

</div>

<hr>
<p><a href="https://www.statlearning.com/">Intro to Statistical Learning</a>: The friendly version of
<a href="https://web.stanford.edu/~hastie/ElemStatLearn/">Elements</a> has <a href="https://www.r-bloggers.com/2014/09/in-depth-introduction-to-machine-learning-in-15-hours-of-expert-videos/">MOOC videos</a> and a 2nd edition coming soon, all
free online. Is there a better intro? Maybe using Python?</p>
<p><a href="https://www.manning.com/books/deep-learning-with-python">Deep Learning with Python</a>: The creator of <a href="https://keras.io/">Keras</a> provides
pretty good explanations and code, as I recall. Is there a better
intro? Maybe something using <a href="https://pytorch.org/">PyTorch</a>?</p>
<p><a href="/20210508-statistical_rethinking_by_mcelreath/">Statistical Rethinking</a> has great explanations, examples, and
philosophical commentary for understanding Bayesian approaches.</p>
<p><a href="http://www.mmds.org/">Mining of Massive Datasets</a> is much better than its cover, with
good coverage of both more and less commonly discussed techniques (and
a <a href="https://online.stanford.edu/courses/soe-ycs0007-mining-massive-data-sets">MOOC</a>).</p>
<hr>
<h3>See also:</h3>
<ul>
<li>William Chen's <a href="http://www.wzchen.com/data-science-books">22 Free Data Science Books</a> includes three of my
   four selections.</li>
<li>My <a href="/20160320-books_for_professionals/">Books for Professionals</a> selects four titles on professional
   life.</li>
<li>My <a href="/20160322-books_for_programmers/">Books for Programmers</a> recommends for Python, JavaScript,
   Clojure, R, and git.</li>
</ul>
<hr>
<p>Thanks to a couple of colleagues who inspired this collection of
recommended books!</p>
<p>What else would you add/change in this list?</p>    
    ]]></description>
<link>http://planspace.org/20210721-books_for_machine_learning/</link>
<guid>http://planspace.org/20210721-books_for_machine_learning/</guid>
<pubDate>Wed, 21 Jul 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Wise Charlie Mental Models (cards)</title>
<description><![CDATA[

<p>These <a href="https://www.wisecharlie.com/shop">100 cards</a> are kind of cute. They summarize mental models in
the style of <a href="https://en.wikipedia.org/wiki/Charlie_Munger#%22Elementary,_worldly_wisdom%22">Charlie Munger</a>; some are distinct Munger-isms. The
descriptions aren't terribly good and there are errors. I like the
<a href="https://fs.blog/mental-models/">general idea</a>, and I like cards; these are mediocre but not bad.</p>
<p><img alt="image" src="image.jpg"></p>    
    ]]></description>
<link>http://planspace.org/20210527-wise_charlie_mental_models/</link>
<guid>http://planspace.org/20210527-wise_charlie_mental_models/</guid>
<pubDate>Thu, 27 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>The End of Everything, by Mack</title>
<description><![CDATA[

<p>Here's a fun <a href="http://www.astrokatie.com/book">book</a> by a millennial astrophysicist. I hadn't thought
about a big bang with an infinite universe before; that's fun. I would
have enjoyed more on how we know we're in a false vacuum and how fast
everything has moved over time, but it's a light pop book.</p>
<p>Ways for the universe to end:</p>
<ul>
<li>Big Crunch (gravity crushes us)</li>
<li>Heat Death (best guess; things get cold and lonely)</li>
<li>Big Rip (things eventually spread out explosively, on local scales)</li>
<li>Vacuum Decay (suddenly ice-9 but for everything)</li>
<li>Bounce (maybe we hit another 3-brane or something?)</li>
</ul>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"I knew I would only ever really be able to accept the kind of truth
I could rederive mathematically." (page 4)</p>
</blockquote>
<p>If this is the standard, you will only accept mathematical truths. The
book seems to care quite a bit about observation and measurement, so I
assume she's being rather loose with language here.</p>
<hr>
<blockquote>
<p>"Translating redshifts to speeds, the pattern Hubble detected meant
that the more distant a galaxy, the faster it's receding from us."
(page 57)</p>
</blockquote>
<p>As explained in the book, it seems like this could be read "the faster
it <em>was</em> receding from us" because light from far away is quite old. I
didn't catch it if there was an explanation of how we work out how
fast we think those distant things are moving away now.</p>
<p>This is particularly perplexing because the book explains that it
looks like (by redshift) very distant things are receding fastest,
less distant things look to be receding less fast, and the nearest
things look to be coming toward us. So my naive thought is: How do we
know that the distant things aren't currently coming toward us now?</p>
<p>There is presumably some clever way to work this out?</p>
<blockquote>
<p>"We glossed over this a bit in the previous chapter, but it turns
out that even just determining the past expansion rate is far more
difficult than it seems like it has any right to be." (page 115)</p>
</blockquote>
<p>That introduces the <a href="https://en.wikipedia.org/wiki/Cosmic_distance_ladder">distance ladder</a>, but I think still doesn't
address the above.</p>
<hr>
<blockquote>
<p>"Just like a curved fiber-optic cable can make the light inside it
turn a corner, a massive object bending space can cause light to
curve around it." (page 68)</p>
</blockquote>
<p>It isn't quite "just like" that, I think... I mean, the trampoline
analogy isn't good either...</p>
<hr>
<blockquote>
<p>"Measuring <em>distance</em> accurately over billions of light-years,
however, is a lot harder [than measuring redshift]." (page 69)</p>
</blockquote>
<p>This, I think, is very true. What does distance even mean?</p>
<hr>
<p>The play <a href="https://en.wikipedia.org/wiki/Arcadia_(play)">Arcadia</a>, quoted in the epigraph of Chapter 4, seems neat.</p>
<hr>
<blockquote>
<p>"To throw some more terminology into the mix, an evolving (i.e.,
nonconstant) dark energy is often called <em>quintessence</em>, after the
"fifth element," a mysterious something-or-other that was popular to
philosophize about in the Middle Ages and is not really much more
precisely specified now." (page 80)</p>
</blockquote>
<p>Leeloo Dallas Multipass</p>
<hr>
<blockquote>
<p>"As of this writing, supernova measurements allow us to measure the
Hubble Constant to an accuracy of 2.4 percent."</p>
<p>"Which is weird, because the number we get totally disagrees with
the value of the exact same number we derive from looking at the
cosmic microwave background." (pages 125-126)</p>
</blockquote>
<hr>
<p>How does the data suggest that we're in a local minimum vacuum? How
can we tell that?</p>
<hr>
<blockquote>
<p>"This has led physicists to suggest solutions ranging from abstract
arguments aimed at narrowing down the total range of possible
universes to philosophical debates about how to make advances in
areas of theory in which experimental evidence may never appear."
(page 161)</p>
</blockquote>
<hr>
<p>The epigraph for Chapter 8 quotes Hozier's "<a href="https://www.youtube.com/watch?v=gXq_J29V5Io">No Plan</a>" but I prefer
their "<a href="https://www.youtube.com/watch?v=0C5IS21neGA">Nobody</a>." The drums are bananas.</p>
<hr>
<blockquote>
<p>""By thinking about the end of the universe, just like with its
beginning, you can sharpen your own thinking about what you think is
happening now, and how to extrapolate. I feel like extrapolations in
fundamental physics are essential," says Hiranya Peiris, a
cosmologist at University College London." (page 179)</p>
</blockquote>
<hr>
<blockquote>
<p>"But personally, I still feel there's a big difference, in some
emotional sense, between "we go on forever" and "we don't." Nima
Arkani-Hamed feels the same way. "At the absolute, absolute deepest
level ... whether or not people explicitly admit to thinking about
it or not (and if they don't they're all the poorer for it) ... If
you think there is a purpose to life, then I at least don't know how
to find one that doesn't connect to something that transcends our
little mortality," he tells me. "I think a lot of people at some
level—again, either explicitly or implicitly—will do science or art
or something because of the sense that you do get to transcend
something. You touch something eternal. That word, eternal: very
important. It's very, very, very important."" (page 207)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210508-the_end_of_everything_by_mack/</link>
<guid>http://planspace.org/20210508-the_end_of_everything_by_mack/</guid>
<pubDate>Sat, 08 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Statistical Rethinking, by McElreath</title>
<description><![CDATA[

<p>I was fortunate to read this <a href="https://xcelab.net/rm/statistical-rethinking/">excellent book</a>. It's opinionated,
often quotable, and a fair summary is that "you can imagine your own
generative process, simulate data from it, write the model, and verify
that it recovers the true parameter values. You don't have to wait for
a mathematician to legalize the model you need." (page 376)
Recommended.</p>
<blockquote>
<p>"Thinking generatively—how the data could arise—solves many
problems. Many statistical problems cannot be solved with
statistics. All variables are measured with error. Conditioning on
variables creates as many problems as it solves. There is no
inference without assumption, but do not choose your assumptions for
the sake of inference. Build complex models one piece at a time. Be
critical. Be kind." (page 553)</p>
</blockquote>
<p>Notes by chapter:</p>
<ol>
<li><a href="#ch1">The Golem of Prague</a> (statistics, models, science)</li>
<li><a href="#ch2">Small Worlds and Large Worlds</a> (Bayes' theorem)</li>
<li><a href="#ch3">Sampling the Imaginary</a> (priors and posteriors)</li>
<li><a href="#ch4">Geocentric Models</a> (linear regression)</li>
<li><a href="#ch5">The Many Variables &amp; The Spurious Waffles</a></li>
<li><a href="#ch6">The Haunted DAG &amp; The Causal Terror</a></li>
<li><a href="#ch7">Ulysses' Compass</a> (overfitting)</li>
<li><a href="#ch8">Conditional Manatees</a> (interactions)</li>
<li><a href="#ch9">Markov Chain Monte Carlo</a></li>
<li><a href="#ch10">Big Entropy and the Generalized Linear Model</a></li>
<li><a href="#ch11">God Spiked the Integers</a> (GLMs for counts)</li>
<li><a href="#ch12">Monsters and Mixtures</a> (over-dispersion, ordered categories)</li>
<li><a href="#ch13">Models with Memory</a> (varying effects)</li>
<li><a href="#ch14">Adventures in Covariance</a></li>
<li><a href="#ch15">Missing Data and Other Opportunities</a></li>
<li><a href="#ch16">Generalized Linear Madness</a> (beyond GLMs)</li>
<li><a href="#ch17">Horoscopes</a> (conclusion)</li>
</ol>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<h3><a name="ch1" href="#ch1">Chapter 1: The Golem of Prague</a></h3>
<p>statistics, models, science</p>
<hr>
<blockquote>
<p>"What researchers need is some unified theory of golem engineering,
a set of principles for designing, building, and refining
special-purpose statistical procedures. Every major branch of
statistical philosophy possesses such a unified theory. But the
theory is never taught in introductory—and often not even in
advanced—courses. So there are benefits in rethinking statistical
inference as a set of strategies, instead of a set of pre-made
tools." (page 4)</p>
</blockquote>
<hr>
<p>I think there's a little bit of linguistic confusion between
scientific hypotheses ("I think the world works like...") and
statistical hypotheses (also called "Statistical models" in Figure
1.2).</p>
<hr>
<blockquote>
<p>"... deductive falsification never works." (page 4)</p>
</blockquote>
<p>I think this is too strong.</p>
<hr>
<blockquote>
<p>"<em>modus tollens</em>, which is Latin shorthand for “the method of
destruction.”" (page 7)</p>
</blockquote>
<hr>
<p>also: importance of <em>measurement</em></p>
<hr>
<p>He has some neat examples of evidence that's not trivial to infer
from - whether the ivory-billed woodpecker was extinct, and
faster-than-light neutrinos... To these, also add the Piltdown Man
fraud.</p>
<hr>
<h3><a name="ch2" href="#ch2">Chapter 2: Small Worlds and Large Worlds</a></h3>
<p>Bayes' theorem</p>
<hr>
<p>Neat counting example in 2.1! I tried to write up
<a href="/2013/11/11/whats-the-difference-between-bayesian-and-non-bayesian-statistics/">a similar example</a> (inspired by <a href="http://www.stat.columbia.edu/~gelman/book/">Gelman</a>) some years ago...</p>
<hr>
<p>In note 41, from page 24, McElreath advocates <a href="https://en.wikipedia.org/wiki/Cox%27s_theorem">Cox</a>-style
probability.</p>
<hr>
<p>I also wrote up (still years ago) a <a href="/2014/02/23/bayes-rule-for-ducks/">cute example</a> trying to explain
Bayes' rule, but I think it's pretty crummy relative to his
development through sections 2.1.2 and 2.1.3.</p>
<hr>
<p>I kind of miss seeing "evidence" in Bayes' rule... Maybe I like this,
with "explanation" for the other term?</p>
<pre><code>P(explanation|evidence) = P(evidence|explanation) * P(explanation)
                          ----------------------------------------
                                        P(evidence)</code></pre>

<p>(The P's everywhere would kind of obfuscate the nice counting
development he was using, but still...)</p>
<p>Then, note that <code>P(evidence|explanation)</code> is the "likelihood" of the
evidence, and that we're going to talk about that a lot.</p>
<hr>
<p>Ah, here on page 37 is his version:</p>
<pre><code>Posterior = Probability of the data * Prior
            -------------------------------
            Average probability of the data</code></pre>

<p>Also nice! He reminds me that I'm using "evidence" (above) in a
different way from using it to mean the denominator there...</p>
<p>There's also the way of doing it that's more like this:</p>
<pre><code>Posterior =     Probability of the data     * Prior
            -------------------------------
            Average probability of the data</code></pre>

<p>And then we can talk about the first term as the likelihood ratio,
which is kind of nice, but makes it less clear that the denominator is
a normalizer that can often be mostly ignored...</p>
<p>Likelihood ratio is a nice thing to think about, especially in
connection with Polya's "plausible reasoning"... Evidence that is
<em>only</em> consistent with the explanation (and no other) increases
confidence a lot.</p>
<p>There's also a nice connection to the error mode of getting the
denominator wrong and jumping to conclusions when you don't know of
another possible explanation. "I didn't think you were planning a
surprise party!" etc.</p>
<p>I don't really like "average probability of the data" as a term, I
think...</p>
<hr>
<p>On page 39, he doesn't include Hamiltonian Monte Carlo as one of the
"engines"... Is it a type of MCMC? Ah, <a href="https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo">yes</a>.</p>
<hr>
<p>Oh no! Very ugly page break from 42 to 43, with the header of a table
separated from its contents...</p>
<hr>
<p>Interesting; really not explaining what's going on with <code>dbeta</code>,
conjugate priors, etc... Probably fine?</p>
<hr>
<p>Wow! I do not understand how this Metropolis algorithm on page 45
works! I guess I can wait until Chapter 9.</p>
<hr>
<p>Ooh fun, some people have problem solutions online... Here's one:</p>
<ul>
<li>https://github.com/cavaunpeu/statistical-rethinking</li>
</ul>
<hr>
<h3><a name="ch3" href="#ch3">Chapter 3: Sampling the Imaginary</a></h3>
<p>priors and posteriors</p>
<hr>
<p>I'm reading Ellenberg's <a href="/20200925-how_not_to_be_wrong_by_ellenberg/">How Not to Be Wrong</a>, and he says on page
49: "In mathematics, you very seldom get the clearest account of an
idea from the person who invented it."</p>
<p>I have that feeling in connection with Gelman and Pearl (not sure they
completely invented things they're associated with, but still): I feel
like McElreath is doing a better job of explaining things, and it's
super nice.</p>
<p>Also Ellenberg:</p>
<blockquote>
<p>"If a tiny state like South Dakota experiences a rash of brain
cancer, you might presume that the spike is in large measure due to
luck, and you might estimate that the rate of brain cancer in the
future is likely to be closer to the overall national number. You
could accomplish this by taking some kind of weighted average of the
South Dakota rate with the national rate. But how to weight the two
numbers? That's a bit of an art, involving a fair amount of
technical labor I'll spare you here." (pages 70-71)</p>
</blockquote>
<p>I think he's referring to <a href="https://en.wikipedia.org/wiki/Multilevel_model">multi-level modeling</a>, in the Gelman
style.</p>
<hr>
<p>This common medical testing scenario appeared in a recent
LearnedLeague one-day on statistics:</p>
<blockquote>
<p>"Suppose that 1% of a population has a particular genetic mutation,
and a test for the mutation is 99% accurate for both positive and
negative cases. In other words, if someone with the mutation takes
the test, there is a 99% chance that the test comes back positive;
if someone without the mutation takes the test, there is a 99%
chance that the test comes back negative. If a randomly-selected
person takes the test and gets a positive result, what is the
probability that the person actually has the mutation? (Express your
answer as a fraction in lowest terms.)"</p>
</blockquote>
<p>I solved it by seeing that 0.01 * 0.99 == 0.99 * 0.01, which is sort
of like what McElreath says is called "frequency format" or "natural
frequencies." I definitely thought of it in terms of "quantity," but
as percentages rather than counts. I was surprised when Erica referred
to the problem as "the Bayesian" problem, because I hadn't thought of
it that way. So I agree with McElreath that it isn't uniquely Bayesian.</p>
<hr>
<blockquote>
<p>"Changing the representation of a problem often makes it easier to
address or inspires new ideas that were not available in an old
representation. In physics, switching between Newtonian and
Lagrangian mechanics can make problems much easier. In evolutionary
biology, switching between inclusive fitness and multilevel
selection sheds new light on old models. And in statistics,
switching between Bayesian and non-Bayesian representations often
teaches us new things about both approaches." (page 50)</p>
</blockquote>
<hr>
<blockquote>
<p>"I avoid discussing the analytical approach
[of conjugate priors, etc.] in this book, because very few problems
are so simple that they have exact analytical solutions like this
[the beta-binomial conjugate prior]." (page 560, note for page 51)</p>
</blockquote>
<hr>
<p>The "Why statistics can't save bad science" box on page 51 is neat.</p>
<hr>
<p>Just to establish equivalence between R and Python...</p>
<pre><code class="language-r">dbinom(6, size=9, prob=0.5)
## [1] 0.1640625</code></pre>

<pre><code class="language-python">import scipy.stats
scipy.stats.binom(n=9, p=0.5).pmf(6)
## 0.16406250000000006</code></pre>

<hr>
<p>Interesting: using "compatibility interval" rather than "credible
interval" (or "confidence interval") in the sense of "compatible with
the model and data." (page 54)</p>
<hr>
<blockquote>
<p>"Overall, if the choice of interval type
[percent interval or highest posterior density interval] makes a big
difference, then you shouldn't be using intervals to summarize the
posterior." (page 58)</p>
</blockquote>
<hr>
<blockquote>
<p>"There is no way to really be sure that software works correctly."
(page 64)</p>
</blockquote>
<hr>
<p>Hmm; his HPDI (Highest Posterior Density Interval) <a href="https://github.com/rmcelreath/rethinking/blob/3b48ec8dfda4840b9dce096d0cb9406589ef7923/R/utilities.r#L106">implementation</a>
itself relies on the implementation in <a href="https://cran.r-project.org/package=coda">coda</a>...</p>
<p>How hard is this really to implement? If you have a histogram or just
sorted counts, every left point determines one interval, so you could
do it in one pass with a little farting around to find the right point
each time, and a running smallest interval... Really not so
computation-intensive.</p>
<hr>
<pre><code class="language-r">birth1 &lt;- c(1,0,0,0,1,1,0,1,0,1,0,0,1,1,0,1,1,0,0,0,1,0,0,0,1,0,
0,0,0,1,1,1,0,1,0,1,1,1,0,1,0,1,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,
1,1,0,1,0,0,1,0,0,0,1,0,0,1,1,1,1,0,1,0,1,1,1,1,1,0,0,1,0,1,1,0,
1,0,1,1,1,0,1,1,1,1)
birth2 &lt;- c(0,1,0,1,0,1,1,1,0,0,1,1,1,1,1,0,0,1,1,1,0,0,1,1,1,0,
1,1,1,0,1,1,1,0,1,0,0,1,1,1,1,0,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,
1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,0,0,0,1,0,0,0,1,1,0,0,1,0,0,1,1,
0,0,0,1,1,1,0,0,0,0)
table(birth1, birth2)
##        birth2
##  birth1  0  1
##       0 10 39
##       1 30 21</code></pre>

<p>So really, what <em>is</em> up with this data?</p>
<hr>
<h3><a name="ch4" href="#ch4">Chapter 4: </a></h3>
<p>linear regression</p>
<hr>
<blockquote>
<p>"Linear regression is the geocentric model of applied statistics."
(page 71)</p>
</blockquote>
<hr>
<p>Frank's <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1420-9101.2009.01775.x">The common patterns of nature</a> seems pretty neat, getting
into how common distributions come from processes and information
considerations...</p>
<hr>
<blockquote>
<p>"Multiplying small numbers is approximately the same as addition."
(page 74)</p>
</blockquote>
<hr>
<p>On page 76 he shows "precision" as τ, meaning 1/σ^2, and it shows up
in the equation for the Gaussian with π, which is an example of
notation that doesn't work particularly well with
<a href="https://tauday.com/">the tau manifesto</a>.</p>
<hr>
<p>"procrustean" (on page 77): "(especially of a framework or system)
enforcing uniformity or conformity without regard to natural variation
or individuality."</p>
<hr>
<p>I like the <a href="https://en.wikipedia.org/wiki/Sparkline">spark</a> histograms!</p>
<p>Oh, neat, they're even <a href="https://github.com/rmcelreath/rethinking/blob/f9c16bb7faec8a9883d976a769824b1764d12540/R/precis.r#L72">called</a> "histosparks"...</p>
<p>And I might have guessed... they're <a href="https://rdrr.io/github/hadley/precis/src/R/histospark.R">from</a> Hadley.</p>
<p>So there are unicode characters that do blocks of various sizes, by
eighths... It looks like Hadley only uses some of them:</p>
<pre><code class="language-r">sparks &lt;- c("\u2581", "\u2582", "\u2583", "\u2585", "\u2587")
#             1/8       2/8       3/8       5/8       7/8</code></pre>

<p>Can look these up for example here: https://www.fileformat.info/info/unicode/char/2581/index.htm</p>
<p>" ▁▂▃▄▅▆▇█" has all the heights, with a normal blank at the beginning.</p>
<p>So why does Hadley only use some of the available heights? Not sure.</p>
<p>Oh look at that! In my terminal those all look fine, but in a browser (maybe it depends on font?) the half and full blocks go lower than the others! Still doesn't explain why 6/8 is missing from Hadley's list... Maybe it looks bad in other fonts?</p>
<p>Let's try it fixed-width:</p>
<pre><code> ▁▂▃▄▅▆▇█</code></pre>

<p>Yup, looks much nicer in fixed width.</p>
<p>Here's another nice place to see these: https://en.wikipedia.org/wiki/Block_Elements</p>
<hr>
<blockquote>
<p>"E. T. Jaynes (1922-1988) called this the <em>mind projection fallacy</em>,
the mistake of confusing epistemological claims with ontological
claims." (page 81)</p>
</blockquote>
<p>And a fun reference to <a href="https://bayes.wustl.edu/etj/articles/cmonkeys.pdf">Monkeys, Kangaroos, and N</a>:</p>
<blockquote>
<p>"... I think you will find that 90% of the past confusions and
controversies in statistics have been caused, not by mathematical
errors or even ideological differences; but by the technical
difficulty that the two parties had different problems in mind, and
failed to realize this. Thinking along different lines, each failed
to perceive at all what the other considered too obvious to
mention." (Jaynes)</p>
</blockquote>
<hr>
<blockquote>
<p>"There's also a tradition called <em>dimensionless analysis</em> that
advocates constructing variables so that they are unit-less ratios."
(page 94)</p>
</blockquote>
<p>I haven't heard about this as such, I think. Dimension_al_ analysis is
more well known, but not quite the same thing...</p>
<hr>
<p>Interesting to recall that in the first edition, what's now called
<code>quap</code> (quadratic approximation posterior / a posteriori?) was called
<code>map</code> (maximum a posteriori?)</p>
<hr>
<blockquote>
<p>"My experience is that many natural and social scientists have
naturally forgotten whatever they once knew about logarithms." (page
98)</p>
</blockquote>
<hr>
<blockquote>
<p>"... most social and natural scientists have never had much training
in probability theory and tend to get very nervous around ∫'s."
(page 106)</p>
</blockquote>
<hr>
<p>He repeats it in different ways here and there, but I noted it again
on page 107: I like his effort at clarity between "small world" and
"large world" claims, where small world is "assuming the model" or "in
the world of the model."</p>
<hr>
<p>When doing the quadratic example, he z-scores but does not
decorrelate... The default behavior in R (using <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/poly">poly</a>) is to
"compute orthogonal polynomials"... I'm not sure how common that is
elsewhere.</p>
<p>Okay I'll look at sklearn... Here's somebody with a nice Python
implementation:
http://davmre.github.io/blog/python/2013/12/15/orthogonal_poly But as
far as I can tell there isn't anything "built in" for Python...</p>
<hr>
<p>page 111: <code>weight.s</code> is used in one listing, while <code>weight_s</code> is used
in another, which is a very mild kind of inconsistency. (<a href="https://github.com/rmcelreath/rethinking/pull/279">PR</a>)</p>
<hr>
<blockquote>
<p>"We should feel embarrassed to use [linear models], just so we don't
become satisfied with the phenomenological explanations they
provide." (page 113)</p>
</blockquote>
<hr>
<p>I really liked section 4.5.2 on splines; I don't think I ever saw a
good explanation of splines before.</p>
<hr>
<blockquote>
<p>"Matrix algebra is a stressful topic for many scientists." (page 119)</p>
</blockquote>
<hr>
<p>In both R listings 4.76 and 4.79, it's a little unintuitive to me in
that it doesn't seem obvious that <code>w</code> is a vector. In <code>w ~ dnorm(0,
10)</code>, that <code>dnorm</code> returns just one number. Somewhere <code>quap</code> is
figuring out how many elements it needs, I guess?</p>
<hr>
<p>For question 4H8 on page 122, it asks what else would have to change
if the intercept was removed from the model. I think the answer is
just the priors on the other coefficient(s), since they'd have to get
the mean all the way to where it needs to be by themselves then.
And/or maybe the data couldn't be centered, because making the mean
zero would really hurt the ability to have the result be right? It
would still be okay if both x and y were centered, at least for simple
designs.</p>
<hr>
<h3><a name="ch5" href="#ch5">Chapter 5: The Many Variables &amp; The Spurious Waffles</a></h3>
<hr>
<blockquote>
<p>"... introduce graphical causal models as a way to design and
interpret regression models." (page 124)</p>
</blockquote>
<hr>
<blockquote>
<p>"About one thing, however, there is general agreement: Causal
inference always depends upon unverifiable assumptions." (page 124)</p>
</blockquote>
<hr>
<blockquote>
<p>"Think before you regress" (page 128)</p>
</blockquote>
<p>In the first paragraph of 5.1.1, I don't really see how Figure 5.2
tells us that only one of the predictor variables has a causal
influence...</p>
<hr>
<p>I really like <a href="http://www.dagitty.net/">dagitty</a>. Learning about it is one of the best things
in the book, in that I was wishing to find such software while reading
<a href="https://planspace.org/20200917-book_of_why/">The Book of Why</a> but didn't.</p>
<p>It is a little weird that the web interface uses ⊥ (falsum)... Hmm;
<a href="https://en.wikipedia.org/wiki/Up_tack">looking it up</a>, it seems it's the same symbol as <code>\perp</code>, which is
used for independence. Ah! The "double tack up" (⫫) is for conditional
independence! The web interface still uses ⊥ for both kinds of
independence.</p>
<hr>
<blockquote>
<p>"This is very weird notation and any feelings of annoyance on your
part are justified." (page 130)</p>
</blockquote>
<hr>
<p>The <code>coeftab</code> visualization (see page 133) is pretty nice.</p>
<hr>
<p>It took me a little bit to understand what he was getting at with the
"predictor residual plots" (page 135) but I'm glad I did, since it
connects to one of his main points about how multiple regression is
about how much a variable adds given all the other variables.</p>
<hr>
<blockquote>
<p>"Usually answers to large world questions about truth and causation
depend upon information not included in the model." (page 139)</p>
</blockquote>
<hr>
<p>The section 5.2 "Masked relationship" is neat.</p>
<hr>
<blockquote>
<p>"Taking the log of a measure translates the measure into
magnitudes." (page 148)</p>
</blockquote>
<p>What use of "magnitude" is this? Hmm... Looks like star brightness is
done via a log that is called magnitude... Just weird, because in
other domains "magnitude" refers to the <em>un</em>-logged value...</p>
<p>Seems like this is less surprising to others, and it makes sense as "<em>order of</em> magnitude."</p>
<hr>
<blockquote>
<p>"A set of DAGs with the same conditional independencies is known as
a Markov equivalence set." (page 151)</p>
</blockquote>
<hr>
<p>I was unfamiliar with <a href="https://en.wikipedia.org/wiki/Melanesia">Melanesia</a>.</p>
<hr>
<p>One page 155, he makes index variables seem fundamentally different
from indicator variables. Their notation in <code>quap</code> is different (and
nicer) but fundamentally the only difference is with index variables
you drop the intercept term (or equivalently, you have separate
intercept terms for each thing). Just reading through, I initially
thought his index variables were a real novelty, but they're not. (I'm
still curious about where he says on page 156 "It is also important to
get used to index variables, because multilevel models (Chapter 13)
depend upon them.")</p>
<hr>
<blockquote>
<p>"The mistake of accepting the null hypothesis." (page 158)</p>
</blockquote>
<hr>
<p>Question 5E3 on page 159 jokes (I think?) about the effects of amount
of funding and size of laboratory on time to PhD, but I'm not sure I
know what he thinks is funny...</p>
<hr>
<h3><a name="ch6" href="#ch6">Chapter 6: The Haunted DAG &amp; The Causal Terror</a></h3>
<hr>
<p>On page 161 he starts with Berkson's Paradox, suggesting
"selection-distortion effect" as a better name. Dave suggested a nice
example: shorter basketball players in the NBA are better 3 point
shooters.</p>
<hr>
<blockquote>
<p>"Let's bein with the least of your worries: multicollinearity."
(page 163)</p>
</blockquote>
<p>This can "smear out" your estimates, because it isn't clear which
variables to put beta weight on.</p>
<hr>
<p>Section 6.2 (page 170) uses "post-treatment bias" to refer to what I
might call a mediator, and what he later calls a "pipe" situation
(page 185).</p>
<hr>
<blockquote>
<p>"The "d" [in d-separation] stands for <em>directional</em>." (page 174)</p>
<p>"You'll often see the "d" in d-separation defined as "dependency."
That would certainly make more sense. But the term d-separation
comes from a more general theory of graphs. Directed graphs involve
d-separation and undirected graphs involve instead u-separation."
(page 563)</p>
</blockquote>
<hr>
<blockquote>
<p>"No statistical procedure can substitute for scientific knowledge
and attention to it." (page 175)</p>
</blockquote>
<hr>
<blockquote>
<p>"If a procedure cannot figure out the truth in a simulated example,
we shouldn't trust it in a real one." (page 177)</p>
</blockquote>
<hr>
<blockquote>
<p>"So I'm sorry to say that we also have to consider the possibility
that our DAG may be haunted." (page 180)</p>
</blockquote>
<p>The thing haunting it (as in the title of the chapter) is unmeasured
causes that induce collider bias, which means conditioning on things
we have can induce bias about effects we're trying to measure.</p>
<hr>
<p>I like "the four elemental confounds" on page 185. They're pretty
similar to the cases I included in
<a href="https://planspace.org/20200912-what_should_be_in_your_regression/">What should be in your regression?</a>.</p>
<hr>
<p>The explanation of shutting the back-door on pages 184-185 is better
than others I've seen, I think. And then on page 186 he shows how
everybody's favorite <a href="http://www.dagitty.net/">dagitty</a> can do it automatically.</p>
<p>Front-door isn't mentioned until page 460.</p>
<hr>
<p>On page 186, he says "Conditioning on C is the better idea, from the
perspective of efficiency, since it could also help with the precision
of the estimate of X➔Y." This seems reasonable since C is closer to Y,
but I feel like a little more explanation wouldn't have been a bad
thing here.</p>
<hr>
<blockquote>
<p>"In fact, domain specific structural causal models can make causal
inference possible even when a DAG with the same structure cannot
decide how to proceed." (page 188)</p>
</blockquote>
<p>Say more? Like, a footnote? An endnote? Some kind of reference to more
information? Seems so mysterious!</p>
<hr>
<blockquote>
<p>"Sometimes, in order to avoid multicollinearity, people inspect
pairwise correlations among predictors before including them in a
model. This is a bad procedure, because what matters it the
conditional association, not the association before the variables
are included in the model." (page 189)</p>
</blockquote>
<hr>
<h3><a name="ch7" href="#ch7">Chapter 7: Ulysses' Compass</a></h3>
<p>overfitting</p>
<hr>
<ul>
<li>7.1. The problem with parameters</li>
<li>7.2. Entropy and accuracy</li>
<li>7.3. Golem taming: regularization</li>
<li>7.4. Predicting predictive accuracy</li>
<li>7.5. Model comparison</li>
</ul>
<hr>
<p>McElreath has slides and video of his lectures <a href="https://github.com/rmcelreath/statrethinking_winter2019">online</a>.</p>
<hr>
<blockquote>
<p>"This chapter describes some of the most commonly used tools for
coping with this trade-off." (page 191, referring to the trade-off
between simplicity and accuracy)</p>
</blockquote>
<p>There's some parallel between statistical models and scientific models
generally; see <a href="https://planspace.org/20170825-characteristics_of_good_theories/">Characteristics of good theories</a>.</p>
<hr>
<blockquote>
<p>"... when we design any particular statistical model, we must decide
whether we want to understand causes or rather just predict." (page
192)</p>
</blockquote>
<hr>
<p>"Stargazing" is a cute way to criticize fixation on stars that
represent statistical significance. (page 193)</p>
<hr>
<p>On page 194 he uses "hominin" which I wasn't familiar with. Hominins
refers to humans and chimps. Add gorillas and you get hominines. Add
orangutans to that and you get hominids.</p>
<hr>
<blockquote>
<p>"In fact, Carl Friedrich Gauss originally derived the OLS procedure
in a Bayesian framework." (page 196)</p>
</blockquote>
<p>He loves pointing out this kind of thing.</p>
<hr>
<blockquote>
<p>"The point of this example is not to praise R<sup>2</sup> but to
bury it." (page 197)</p>
</blockquote>
<p>This alludes to Shakespeare's famous Marc Antony speech in Julius
Caesar: "I come to bury Caesar, not to praise him."</p>
<hr>
<blockquote>
<p>"This means the <em>actual</em> empirical variance, not the variance that R
returns with the <code>var</code> function, which is a frequentist estimator
and therefore has the wrong denominator." (page 197)</p>
</blockquote>
<p>Saucy!</p>
<hr>
<blockquote>
<p>"... model fitting can be considered a form of data compression. ...
This view of model selection is often known as minimum description
length (MDL)." (page 201)</p>
</blockquote>
<p>Wikipedia <a href="https://en.wikipedia.org/wiki/Minimum_description_length">says</a> "In its most basic form, MDL is a model selection
principle: the shortest description of the data as the best model."</p>
<p>McElreath points to <a href="https://homepages.cwi.nl/~pdg/publicationpage.html">Grünwald's</a> The Minimum Description Length
Principle.</p>
<hr>
<p>He's trying to develop "out-of-sample deviance" in 7.2 "Entropy and
accuracy" starting page 202.</p>
<hr>
<p>"Likelihood" as in the likelihood of the data, given the model, on
page 204. And he <em>really</em> likes it:</p>
<blockquote>
<p>"If you see an analysis using something else, either it is a special
case of the log scoring rule or it is possibly much worse."</p>
</blockquote>
<hr>
<p>Interesting "Rethinking" box on page 204:</p>
<blockquote>
<p>"Calibration is overrated. ... The problem is that calibrated
predictions do not have to be good."</p>
</blockquote>
<p>It has an endnote on page 563 that includes:</p>
<blockquote>
<p>"Strictly speaking, there are no "true" probabilities of events,
because probability is epistemological and nature is deterministic."</p>
</blockquote>
<hr>
<p>On page 207 he points out that when probability is zero, L'Hopital's
rule gives us 0*log(0) = 0.</p>
<hr>
<p>Endnote 110 on page 564 begins:</p>
<blockquote>
<p>"I really wish I could say there is an accessible introduction to
maximum entropy, at the level of most natural and social scientists'
math training. If there is, I haven't found it yet."</p>
</blockquote>
<p>On page 207 he just says:</p>
<blockquote>
<p>"So Bayesian updating is entropy maximization."</p>
</blockquote>
<hr>
<p>He just says "divergence" to mean Kullback-Leibler divergence, and
adds in endnote 111 on page 564:</p>
<blockquote>
<p>"For what it's worth, Kullback and Leibler make it clear in their
1951 paper that Harold Jeffreys had used this measure already in the
development of Bayesian statistics."</p>
</blockquote>
<p>There he goes again!</p>
<hr>
<blockquote>
<p>"In plainer language, the divergence is <em>the average difference in
log probability between the target (p) and model (q)</em>. This
divergence is just the difference between two entropies: The entropy
of the target distribution <em>p</em> and the <em>cross entropy</em> arising from
using <em>q</em> to predict <em>p</em>."</p>
</blockquote>
<hr>
<blockquote>
<p>"At this point in the chapter, dear reader, you may be wondering
where the chapter is headed." (page 209)</p>
</blockquote>
<hr>
<blockquote>
<p>"It's as if we can't tell how far any particular archer is from
hitting the target, but we can tell which archer gets closer and by
how much." (page 209)</p>
</blockquote>
<hr>
<blockquote>
<p>"To compute this [log-probability] score for a Bayesian model, we
have to use the entire posterior distribution. Otherwise, vengeful
angels will descend upon you." (page 210)</p>
</blockquote>
<p>His package has <code>lppd</code> for "log-pointwise-predictive-density."</p>
<blockquote>
<p>"It is also quite common to see something called the deviance, which
is like a lppd score, but multiplied by -2 so that smaller values
are better. The 2 is there for historical reasons."</p>
</blockquote>
<p>There's more explanation in endnote 112 on page 564:</p>
<blockquote>
<p>"In non-Bayesian statistics, under somewhat general conditions, a
difference between two deviances has a chi-squared distribution. The
factor of 2 is there to scale it the proper way."</p>
</blockquote>
<p>(Recall we're interested in the difference between these things; they
don't have a meaningful scale on their own.)</p>
<hr>
<p>I was briefly befuddled by the positive log-likelihoods on page 210,
but of course it's the point density, not probability, and the density
can be greater than one.</p>
<hr>
<p>On page 211 he talks about <code>log_sum_exp</code> which "takes all the
log-probabilities for a given observation, exponentiates each, sums
them, then takes the log. But it does this in a way that is
numerically stable."</p>
<p>I had cause to do this recently! It comes down to this:</p>
<pre><code class="language-python">import math

def sum_log_prob(a, b):
    return max(a, b) + math.log1p(math.exp(0 - abs(a - b)))</code></pre>

<p>I based that on a <a href="https://gasstationwithoutpumps.wordpress.com/2014/05/06/sum-of-probabilities-in-log-prob-space/">post from Kevin Karplus</a>.</p>
<p>McElreath's is:</p>
<pre><code class="language-r">log_sum_exp &lt;- function( x ) {
    xmax &lt;- max(x)
    xsum &lt;- sum( exp( x - xmax ) )
    xmax + log(xsum)
}</code></pre>

<p>(<a href="https://rdrr.io/github/rmcelreath/rethinking/src/R/distributions.r">Found</a> on rdrr.)</p>
<hr>
<blockquote>
<p>"That [two-parameter] model does worse in prediction than the model
with only 1 parameter, even though the true model does include the
additional predictor. This is because with only N=20 cases, the
imprecision of the estimate for the first predictor produces more
error than just ignoring it." (page 213)</p>
</blockquote>
<hr>
<blockquote>
<p>"When you encounter multilevel models in Chapter 13, you'll see that
their central device is to learn the strength of the prior from the
data itself. So you can think of multilevel models as adaptive
regularization, where the model itself tries to learn how skeptical
it should be." (page 216)</p>
</blockquote>
<hr>
<blockquote>
<p>"Statisticians often make fun of machine learning for reinventing
statistics under new names. But regularization is one area where
machine learning is more mature. Introductory machine learning
courses usually describe regularization. Most introductory
statistics courses do not." (page 216)</p>
</blockquote>
<hr>
<p>Section 7.4 (page 217) is "predicting predictive accuracy."</p>
<hr>
<blockquote>
<p>"It is a benign aspect of the universe that this importance
[of individual examples] can be estimated without refitting the
model." (page 217)</p>
</blockquote>
<hr>
<p>"PSIS" is "Pareto-smoothed importance sampling cross-validation."
(page 217)</p>
<hr>
<blockquote>
<p>"For ordinary linear regression with flat priors, the expected
overfitting penalty is about twice the number of parameters." (page
219)</p>
</blockquote>
<hr>
<blockquote>
<p>"AIC is of mainly historical interest now." (page 219)</p>
</blockquote>
<hr>
<p>It seems like WAIC can only be used when you have a posterior
distribution, since it relies on variance of those predictions...</p>
<hr>
<blockquote>
<p>"... in the natural and social sciences the models under
consideration are almost never the data-generating models. It makes
little sense to attempt to identify a "true" model." (page 221)</p>
</blockquote>
<hr>
<blockquote>
<p>"Watanabe recommends computing both WAIC and PSIS and contrasting
them. If there are large differences, this implies one or both
criteria are unreliable.</p>
<p>"Estimation aside, PSIS has a distinct advantage in warning the user
about when it is unreliable." (page 223)</p>
</blockquote>
<hr>
<blockquote>
<p>"A very common use of cross-validation and information criteria is
to perform model selection, which means choosing the model with the
lowest criterion value and then discarding the others. But you
should never do this." (page 225)</p>
</blockquote>
<hr>
<p>Endnote 133 references
<a href="https://www.fooledbyrandomness.com/violencenobelsymposium.pdf">The Decline of Violent Conflicts: What Do The Data Really Say?</a> which is interesting.</p>
<hr>
<blockquote>
<p>"This chapter has been a marathon." (page 235)</p>
</blockquote>
<p>And then the chapter summary doesn't even mention cross-validation!</p>
<hr>
<p>Acronyms:</p>
<ul>
<li>AIC: Akaike Information Criterion</li>
<li>BIC: Bayesian Information Criterion (aka Schwarz criterion)</li>
<li>CV: Cross-Validation</li>
<li>DIC: Deviance Information Criterion</li>
<li>D_{KL}(p, q): Kullback-Leibler divergence</li>
<li>E: Expectation</li>
<li>H(p): Entropy</li>
<li>H(p, q): Cross-entropy</li>
<li>lppd: Log Pointwise Predictive Density</li>
<li>MAP: Maximum A posteriori Probability (mode of posterior)</li>
<li>MDL: Minimum Description Length</li>
<li>N: sample size</li>
<li>PSIS: Pareto-smoothed importance sampling cross-validation</li>
<li>S(q): Sum of log probabilities</li>
<li>R^2: "variance explained" or "coefficient of determination"</li>
<li>WAIC: [Widely Applicable | Watanabe-Akaike] Information Criterion</li>
</ul>
<hr>
<p>Practice problem 7E1: State the three motivating criteria that define
information entropy.</p>
<ul>
<li>It should change smoothly with changes in the inputs.</li>
<li>When more things could happen, it should go up.</li>
<li>It should add, when you combine things.</li>
</ul>
<hr>
<p>Practice problem 7E2: Suppose a coin is weighted such that, when it is
tossed and lands on a table, it comes up heads 70% of the time. What
is the entropy of this coin?</p>
<p>Well, entropy is the negative sum of p*log(p), so:</p>
<pre><code class="language-python">import math

# Truth (as in Problem 7E1)
p = [0.7, 0.3]

# Entropy, H(p)
H = lambda p: -sum(p_i * math.log(p_i) for p_i in p)
H(p)  # 0.6108643020548935

# Candidate "models"
q = [0.5, 0.5]
r = [0.9, 0.1]

# Cross-Entropy, H(p, q), xH here because Python
xH = lambda p, q: -sum(p_i * math.log(q_i) for p_i, q_i in zip(p, q))
xH(p, q)  # 0.6931471805599453
xH(p, r)  # 0.764527888858692

# KL Divergence, D(p, q)
D = lambda p, q: sum(p_i * math.log(p_i/q_i) for p_i, q_i in zip(p, q))
D(p, q)  # 0.08228287850505178
D(p, r)  # 0.15366358680379852

# D(p, q) = H(p, q) - H(p)
D(p, q) == xH(p, q) - H(p)  # True

# We wish we could do this (use D) but we can't, because we don't have p.

# Data
d = [0, 0, 1]

# Log probability (likelihood) score
S = lambda d, p: sum(math.log(p[d_i]) for d_i in d)
S(d, q)  # -2.0794415416798357
S(d, r)  # -2.513306124309698

# True vs. predictive
S(d, p)  # -1.917322692203401
S(d, [2/3, 1/3])
         # -1.9095425048844388

# Deviance
deviance = lambda d, p: -2 * S(d, q)

# Positive log likelihoods! Gasp!

# Note the log probabilities here are really probabilities, because
# I'm just using point estimates, not real distributions. Really,
# you'll have densities, which can be greater than one.</code></pre>

<hr>
<blockquote>
<p>"Information criteria construct a theoretical estimate of the
relative out-of-sample KL divergence." (page 219)</p>
</blockquote>
<p>And he really likes them, largely forgetting about cross-validation.</p>
<hr>
<h3><a name="ch8" href="#ch8">Chapter 8: Conditional Manatees</a></h3>
<p>interactions</p>
<hr>
<p>Propeller marks on manatees are unpleasant, but DID YOU KNOW you see
those marks so much because they don't kill the manatees, so they're
still around to be seen? Manatees are mostly killed by blunt force
thwacking by the hulls of boats, not their propellers.</p>
<hr>
<blockquote>
<p>"Using GDP to measure the health of an economy is like using heat to
measure the quality of a chemical reaction." (endnote 138, page 565)</p>
</blockquote>
<hr>
<p>Why not split data to condition on some categorical variable? (page
241)</p>
<ul>
<li>For parameters that exist in both parts, "you are essentially
   making two less-accurate estimates instead of pooling all of the
   evidence".</li>
<li>"you can't easily quanitfy that uncertainty" (about "the predictive
   value of distinguishing" your parts)</li>
<li>It makes it hard to use information criteria (the comparison works
   best when the same data is in all the models under comparison)</li>
<li>Multilevel models don't split the data, and derive benefits in
   "borrowing information across categories".</li>
</ul>
<hr>
<p>On page 245, he explains (again?) that using indicator variables is
bad in the sense that it implies more uncertainty in the indicated
class (uncertainty of baseline, plus uncertainty of indicator's
coefficient).</p>
<hr>
<p>On using fancy Greek letters in your model specification:</p>
<blockquote>
<p>"If your reader cannot say the symbol's name, it could make
understanding the model harder." (page 249)</p>
</blockquote>
<hr>
<p>Section 8.2 (page 250) on "Symmetry of interactions" is pretty neat.</p>
<blockquote>
<p>"There is just no way to specify a simple, linear interaction in
which you can say the effect of some variable <em>x</em> depends upon <em>z</em>
but the effect of <em>z</em> does not depend upon <em>x</em>." (page 256)</p>
</blockquote>
<hr>
<p>In endnote 142, McElreath recommends Grafen and Hails'
<a href="https://smile.amazon.com/Statistics-STATISTICS-May-09-2002-MAY-09-2002-Hardcover/dp/B009CPMY4Y/">Modern Statistics for the Life Sciences</a>, saying "It has a rather
unique geometric presentation of some of the standard linear models."
The book has the somewhat surprising subtitle of "Learn to analyse
your own data".</p>
<hr>
<p><a href="https://en.wikipedia.org/wiki/Main_effect">Main effects</a> vs. interaction effects.</p>
<hr>
<p>On weakly informative priors:</p>
<blockquote>
<p>"If you displayed these priors to your colleagues, a reasonable
summary might be, "These priors contain no bias towards positive or
negative effects, and at the same time they very weakly bound the
effects to realistic ranges."" (page 260)</p>
</blockquote>
<hr>
<blockquote>
<p>"While you can't see them in a DAG, interactions can be important
for making accurate inferences." (page 260)</p>
</blockquote>
<hr>
<h3><a name="ch9" href="#ch9">Chapter 9: Markov Chain Monte Carlo</a></h3>
<hr>
<blockquote>
<p>"Researchers rely upon random numbers for the proper design of
experiments." (page 263)</p>
</blockquote>
<hr>
<p>In an endnote, McElreath recommends Kruschke's
<a href="https://sites.google.com/site/doingbayesiandataanalysis/">Doing Bayesian Data Analysis</a>, and it seems like it might be good.</p>
<hr>
<blockquote>
<p>"the combination of parameter values that maximizes posterior
probability, the mode, is not actually in a region of parameter
values that are highly plausible." (page 269)</p>
</blockquote>
<hr>
<blockquote>
<p>"we need MCMC algorithms that focus on the entire posterior at once,
instead of one or a few dimensions at a time like Metropolis and
Gibbs. Otherwise we get stuck in a narrow, highly curving region of
parameter space." (page 270)</p>
</blockquote>
<hr>
<blockquote>
<p>"It appears to be a quite general principle that, whenever there is
a randomized way of doing something, then there is a nonrandomized
way that delivers better performance but requires more thought."
(page 270, quoting E. T. Jaynes)</p>
</blockquote>
<hr>
<blockquote>
<p>"[The U-turn problem] just shows that the efficiency of HMC comes
with the expense of having to tune the leapfrog steps and step size
in each application." (page 274)</p>
</blockquote>
<hr>
<blockquote>
<p>"Fancy HMC samplers ... choose the leapfrog steps and step size for
you ... by conducting a warmup phase in which they try to figure out
which step size explores teh posterior efficiently. If you are
familiar with older algorithms like Gibbs sampling, which use a
burn-in phase, warmup is not like burn-in." (page 274)</p>
</blockquote>
<hr>
<h3><a name="ch10" href="#ch10">Chapter 10: Big Entropy and the Generalized Linear Model</a></h3>
<hr>
<blockquote>
<p>"Indeed, it may be that no one fully understands
[the principle of maximum entropy]." (page 303)</p>
</blockquote>
<hr>
<blockquote>
<p>"[The exponential] distribution is the core of survival and event
history analysis, which is not covered in this book." (page 315)</p>
</blockquote>
<hr>
<blockquote>
<p>"... no regression coefficient ... from a GLM every produces a
constant change on the outcome scale. ... every predictor
essentially interacts with itself, because the impact of a change in
a predictor depends upon the value of the predictor before the
change. More generally, every predictor variable effectively
interacts with every other predictor variable, whether you
explicitly model them as interactions or not." (page 318)</p>
</blockquote>
<hr>
<blockquote>
<p>"Link functions are assumptions." (page 319)</p>
</blockquote>
<p>He suggests sensitivity assumptions, presumably including trying
different link functions, which I think is the closest he comes to
talking about probit regression.</p>
<hr>
<blockquote>
<p>"... even a variable that isn't technically a confounder can bias
inference, once we have a link function." (page 320)</p>
</blockquote>
<hr>
<blockquote>
<p>"Parameter estimates do not by themselves tell you the importancce
of a predictor on the outcome." (page 320)</p>
</blockquote>
<hr>
<blockquote>
<p>"... a big beta-coefficient may not correspond to a big effect on
the outcome." (page 320)</p>
</blockquote>
<hr>
<p>He also points out on page 320 that with a different likelihood (and
so link) function, you can't compare log likelihoods (etc.) any more
because there's an (unknown) normalization constant that's different
between them.</p>
<hr>
<h3><a name="ch11" href="#ch11">Chapter 11: God Spiked the Integers</a></h3>
<p>GLMs for counts</p>
<hr>
<ul>
<li>
<ol>
<li>God spiked the integers</li>
<li>11.1. Binomial regression<ul>
<li>11.1.1. Logistic regression: Prosocial chimpanzees</li>
<li>11.1.2. Relative shark and absolute deer</li>
<li>11.1.3. Aggregated binomial: Chimpanzees again, condensed</li>
<li>11.1.4. Aggregated binomial: Graduate school admissions</li>
</ul>
</li>
<li>11.2. Poisson regression<ul>
<li>11.2.1. Example: Oceanic tool complexity</li>
<li>11.2.2. Negative binomial (gamma-Poisson) models</li>
</ul>
</li>
<li>11.3. Multinomial and categorical models<ul>
<li>11.3.1. Predictors matched to outcomes</li>
<li>11.3.2. Predictors matched to observations</li>
<li>11.3.3. Multinomial in disguise as Poisson</li>
</ul>
</li>
</ol>
</li>
</ul>
<hr>
<blockquote>
<p>"As described in Chapter 10, the Poisson model is a special case of
binomial." (page 323)</p>
</blockquote>
<p>This is a little loose, maybe; Poisson is the limit of binomial, which
isn't quite "a special case" I think...</p>
<p>Logistic regression as a special case of binomial regression, okay.</p>
<hr>
<blockquote>
<p>"There are many ways to construct new variables like this, including
mutant helper functions." (page 327)</p>
</blockquote>
<p>Mutant helper functions? Is this a common term?</p>
<hr>
<blockquote>
<p>"Let's look at these on the outcome scale:" (page 330)</p>
</blockquote>
<p>He shows a table that includes logistic regression coefficients, but
there's really no attempt to interpret them directly, which is
different from some presentations of logistic regression. He goes
directly to showing things on the probability scale. He does then show
some plots on the coefficient scale, and describes them as being "on
the logit scale," but still not a lot of effort spent on connecting
them to changes in odds etc.</p>
<hr>
<blockquote>
<p>"counting the rows in the data table is no longer a sensible way to
assess sample size." (page 340)</p>
</blockquote>
<p>(When using data that is counts of outcomes.)</p>
<hr>
<blockquote>
<p>"This isn't to say that over-parameterizing a model is always a good
idea. But it isn't a violation of any statistical principle." (page
345)</p>
</blockquote>
<hr>
<blockquote>
<p>"Keep in mind that the number of rows is not clearly the same as the
"sample size" in a count model. The relationship between parameters
and "degrees of freedom" is not simple, outside of simple linear
regressions." (page 347)</p>
</blockquote>
<hr>
<blockquote>
<p>"Any rules you've been taught about minimum sample sizes for
inference are just non-Bayesian superstitions." (page 347)</p>
</blockquote>
<hr>
<p>He really seems to want to make gamma-Poisson happen (replacing
negative binomial).</p>
<hr>
<p>Probit doesn't appear anywhere! (At least, I haven't seen it and it
isn't in the index.)</p>
<hr>
<blockquote>
<p>"In general, more than two things can happen." (page 359)</p>
</blockquote>
<hr>
<blockquote>
<p>"The conventional and natural link in this context is the
multinomial logit, also known as the softmax function." (page 359)</p>
</blockquote>
<hr>
<blockquote>
<p>"Another way to fit a multinomial/categorical model is to refactor
it into a series of Poisson likelihoods. That should sound a bit
crazy." (page 363)</p>
</blockquote>
<hr>
<blockquote>
<p>"It is important to never convert counts to proportions before
analysis, because doing so destroys information about sample size."
(page 365)</p>
</blockquote>
<hr>
<h3><a name="ch12" href="#ch12">Chapter 12: Monsters and Mixtures</a></h3>
<p>over-dispersion, ordered categories</p>
<hr>
<blockquote>
<p>"Just be sure to validate it [your model] by simulating dummy data
and then recovering the data-generating process through fitting the
model to the dummy data." (page 369)</p>
</blockquote>
<hr>
<blockquote>
<p>"continuous mixture models in which a linear model is attached not
to the observations themselves but rather to a distribution of
observations." (page 370)</p>
</blockquote>
<hr>
<blockquote>
<p>"... Poisson distributions are very narrow. The variance must equal
the mean, recall." (page 373)</p>
</blockquote>
<hr>
<blockquote>
<p>"You should not use WAIC and PSIS with these
[beta-binomial and gamma-Poisson/negative binomial] models, however,
unless you are very sure of what you are doing. The reason is that
while ordinary binomial and Poisson models can be aggregated and
disaggregated across rows in the data, without changing any causal
assumptions, the same is not true of beta-binomial and gamma-Poisson
models. The reason is that a beta-binomial or gamma-Poisson
likelihood applies an unobserved parameter to each row in the data.
When we then go to calculate log-likelihoods, how the data are
structured will determine how the beta-distributed or
gamma-distributed variation enters the model." (page 375)</p>
</blockquote>
<hr>
<blockquote>
<p>"In the sciences, there is sometimes a culture of anxiety
surrounding statistical inference. It used to be that researchers
couldn't easily construct and study their own custom models, because
they had to rely upon statisticians to properly study the models
first. This led to concerns about unconventional models, concerns
about breaking the laws of statistics. But statistical computing is
much more capable now. Now you can imagine your own generative
process, simulate data from it, write the model, and verify that it
recovers the true parameter values. You don't have to wait for a
mathematician to legalize the model you need." (page 376)</p>
</blockquote>
<p>This could almost be a summary of the book, maybe.</p>
<hr>
<blockquote>
<p>"Just treating ordered categories as continuous measures is not a
good idea."</p>
</blockquote>
<p>He offers the cumulative link function.</p>
<hr>
<blockquote>
<p>"This kind of vector, in which all the values sum to one (or any
other constant), has a special name, a simplex." (page 394)</p>
</blockquote>
<hr>
<h3><a name="ch13" href="#ch13">Chapter 13: Models with Memory</a></h3>
<p>It's the varying effects ("random effects") chapter! Multilevel models!</p>
<hr>
<blockquote>
<p>"Anterograde amnesia is bad for learning about the world." (page 399)</p>
</blockquote>
<hr>
<blockquote>
<p>"this prior is actually learned from the data." (pages 399-400)</p>
</blockquote>
<hr>
<blockquote>
<p>"When some individuals, locations, or times are sampled more than
others, multilevel models automatically cope with differing
uncertainty across these clusters. This prevents over-sampled
clusters from unfairly dominating inference." (page 400)</p>
</blockquote>
<p>This is a pretty cool property to have. The problem of data imbalance
is a challenge for many machine learning algorithms. Considering
multilevel models as a kind of solution is interesting. Not obvious
that it can be easily applied e.g. to vision models, but still, it's
interesting.</p>
<hr>
<blockquote>
<p>"When it comes to regression, multilevel regression deserves to be
the default approach. There are certainly contexts in which it would
be better to use an old-fashioned single-level model. But the
contexts in which multilevel models are superior are much more
numerous. It is better to begin to build a multilevel analysis, and
then realize it's unnecessary, than to overlook it." (page 400)</p>
</blockquote>
<p>Is this really the case? It would be neat to see an example where a
multilevel model isn't obviously needed but is better.</p>
<hr>
<p>Costs of multilevel models (page 400, paraphrase):</p>
<ul>
<li>new assumptions (priors on priors)</li>
<li>estimation challenges (requires MCMC)</li>
<li>hard to understand</li>
</ul>
<hr>
<p>Synonyms (page 401):</p>
<ul>
<li>multilevel model</li>
<li>hierarchical model</li>
<li>mixed effects model</li>
</ul>
<p>With parameters of multilevel models "most commonly known as random
effects". An endnote cites section 6 of Gelman's <a href="http://www.stat.columbia.edu/~gelman/research/published/banova7.pdf">Anova paper</a> but I
didn't find it as "entertaining" as promised. It does include the
origin of "varying effects" as a proposed better name than "random
effects":</p>
<blockquote>
<p>"We define effects (or coefficients) in a multilevel model as
<em>constant</em> if they are identical for all groups in a population and
<em>varying</em> if they are allowed to differ from group to group." (page
20 in Gelman)</p>
</blockquote>
<p>(A "group" could be an individual, depending on the nature of the
data.)</p>
<hr>
<p>I don't love that "hyperparameter" is used for parameters that are
learned from the data, even if they're a level up, because it
conflicts with the usual ML usage of "hyperparameter". It seems fair
that their priors are called hyperpriors, though.</p>
<hr>
<p>Reasons for using a Gaussian prior (page 403):</p>
<ol>
<li>convention (everybody does it)</li>
<li>pragmatism (easy to use/fit)</li>
<li>entropy (maxent if specifying only mean and variance)</li>
</ol>
<hr>
<blockquote>
<p>"Rethinking: Varying intercepts as over-dispersion. ... Compared to
a beta-binomial or gamma-Poisson model, a binomial or Poisson model
with a varying intercept on every observed outcome will often be
easier to estimate and easier to extend." (page 407)</p>
</blockquote>
<p>Oh my! A coefficient for every observation! Take that, frequentist
statisticians!</p>
<p>It would be interesting to see a direct comparison, using e.g.
beta-binomial on the one hand and multilevel on the other...</p>
<hr>
<p>Page 408 itemizes three perspectives:</p>
<ul>
<li>Complete pooling (one estimate shared by all groups)</li>
<li>No pooling (each group independently)</li>
<li>Partial pooling (multilevel model; shrinkage of group estimates)</li>
</ul>
<p>This in particular reminds me of
<a href="https://www.evanmiller.org/how-not-to-sort-by-average-rating.html">How Not To Sort By Average Rating</a>, which inspired in part my
<a href="https://planspace.org/2014/08/17/how-to-sort-by-average-rating/">How To Sort By Average Rating</a> advocating Laplace smoothing instead
of Wilson bounds.</p>
<p>If you use the grand average to determine the Laplace binomial values,
this is just like partial pooling via multilevel model, only much less
rigorous, less obviously extensible to multivariate settings, and far
easier.</p>
<p>I did a version of Laplace smoothing back when I was helping use
survey data to determine how well various medical facilities were
satisfying their patients. A ranking was desired, but ranking by raw
scores ("no pooling") made the most extreme scores nearly always
associated with the locations that had the fewest survey responses.</p>
<hr>
<blockquote>
<p>"Note that the priors are part of the model when we estimate, but
not when we simulate. Why? Because priors are epistemology, not
ontology. They represent the initial state of information of our
robot, not a statement about how nature chooses parameter values."
(page 409)</p>
</blockquote>
<hr>
<p>I enjoy that my preferred way of writing the logistic function is used
on page 411.</p>
<hr>
<blockquote>
<p>"Partial pooling isn't always better. It's just better on average in
the long run." (page 413)</p>
</blockquote>
<hr>
<blockquote>
<p>"As soon as you start trusting the machine, the machine will betray
your trust." (page 416)</p>
</blockquote>
<hr>
<blockquote>
<p>"If the individual units are exhcnagable—the index values could be
reassigned without changing the meaning of the model—then partial
pooling could help." (page 419)</p>
</blockquote>
<hr>
<blockquote>
<p>"Recall that HMC simulates the frictionless flow of a particle on a
surface." (page 420)</p>
</blockquote>
<hr>
<blockquote>
<p>"Algebra makes many things possible." (page 425)</p>
</blockquote>
<hr>
<p>Ah! Here's where he mentions Mister P: Multilevel Regression and
Post-stratification. (page 430)</p>
<hr>
<blockquote>
<p>"Selection on the outcome variable is one of the worst things that
can happen in statistics." (page 431)</p>
</blockquote>
<hr>
<h3><a name="ch14" href="#ch14">Chapter 14: Adventures in Covariance</a></h3>
<hr>
<blockquote>
<p>"... the general varying effects strategy: Any batch of parameters
with <em>exchangeable</em> index values can and probably should be pooled.
Exchangeable just means the index values have no true ordering,
because they are arbitrary labels." (page 435)</p>
</blockquote>
<hr>
<blockquote>
<p>"a way to pool information <em>across</em> parameter types—intercepts and
slopes" (page 436)</p>
</blockquote>
<hr>
<blockquote>
<p>"Finally, we'll circle back to causal inference and use our new
powers over covariance to go beyond the tools of Chapter 6
[The Haunted DAG &amp; the Causal Terror], introducing Instrumental
Variables." (pages 436-437)</p>
</blockquote>
<p>That doesn't reflect the actual order, which has IV in the middle of
the chapter...</p>
<ul>
<li>14.1 Varying slopes by construction</li>
<li>14.2 Advanced varying slopes</li>
<li>14.3 Instruments and causal designs</li>
<li>14.4 Social relations as correlated varying effects</li>
<li>14.5 Continuous categories and the Gaussian Process</li>
</ul>
<hr>
<blockquote>
<p>"In conventional multilevel models, the device that makes this
[modeling the joint population of intercepts and slopes by modeling
their covariance] possible is a joint multivariate Gaussian
distribution for all of the varying effects, both intercepts and
slopes." (page 437)</p>
</blockquote>
<hr>
<blockquote>
<p>"... we are always forced to analyze data with a model that is
misspecified: The true data-generating process is different than the
model." (page 441)</p>
</blockquote>
<hr>
<blockquote>
<p>"how you fit the model is part of the model." (page 447)</p>
</blockquote>
<hr>
<blockquote>
<p>"This [fewer effective than actual parameters] is a good example of
how varying effects adapt to the data. The overfitting risk is much
milder here than it would be with ordinary fixed effects." (page
451)</p>
</blockquote>
<p>Estimates are pooled/shrunk, so parameters don't fit "tightly" to the
data...</p>
<hr>
<blockquote>
<p>"Our interpretation of this experiment has not changed. These
chimpanzees simply did not behave in any consistently different way
in the partner treatments." (page 452)</p>
</blockquote>
<p>This chimpanzee example continues to be fairly dull, for the level of
complexity... I guess it's an example of sensitivity analysis, in a
sense, looking at it in multiple different ways? But it would be more
interesting if there were sometimes different (or any) results.</p>
<hr>
<blockquote>
<p>"There is an obvious cost to these non-centered forms: They look a
lot more confusing. Hard-to-read models and model code limit our
ability to share implementations with our colleagues, and sharing is
the principal goal of scientific computation." (page 454)</p>
</blockquote>
<hr>
<blockquote>
<p>"This last line ["Q cannot influence W except through E"] is
sometimes called the exclusion restriction. It cannot be strictly
tested, and it is often implausible."</p>
</blockquote>
<hr>
<p>The introduction to instrumental variables is based on the classic
<a href="https://www.jstor.org/stable/2937954">Does Compulsory School Attendance Affect Schooling and Earnings?</a></p>
<hr>
<blockquote>
<p>"Remember: With real data, you never know what the right answer is."
(page 456)</p>
</blockquote>
<hr>
<blockquote>
<p>"Instrumental variables are hard to understand. But there are some
excellent tools to help you. For example, the <code>dagitty</code> package
contains a function <code>instrumentalVariables</code> that will find
instruments, if they are present in a DAG." (page 459)</p>
</blockquote>
<hr>
<blockquote>
<p>"The instrumental variable model is often discussed with an
estimation procedure known as two-stage least squares (2SLS). This
procedure involves two linear regressions. The predicted values of
the first regression are fed into the second as dta, with
adjustments so that the standard errors make sense. Amazingly, when
the weather is nice, this procedure works. ... Some people mistake
2SLS for the model of instrumental variables. They are not the same
thing. Any model can be estimated through a number of different
procedures, each with its own benefits and costs." (page 460)</p>
</blockquote>
<hr>
<blockquote>
<p>"Instrumental variables are natural experiments that impersonate
randomized experiments." (page 460)</p>
</blockquote>
<hr>
<p>Discussing the front-door criterion, he points to a <a href="http://www.alexchinco.com/example-front-door-criterion/">blog post</a> and
<a href="https://www.aeaweb.org/articles?id=10.1257/pol.6.3.63">paper</a>.</p>
<hr>
<ul>
<li>Instrumental Variables</li>
<li>Front-Door Criterion</li>
<li>Regression Discontinuity</li>
</ul>
<hr>
<blockquote>
<p>"First, the correlation changes if we switch the A/B labels." (page
462)</p>
</blockquote>
<p>This is a little puzzling. Swapping axes shouldn't change correlation.</p>
<p>Ahhh... It doesn't swap the axes (unless there are only two
participants, or an even number that all pair off sufficiently
nicely, or the relabeling is otherwise sufficiently "nice"...</p>
<p>Why does this happen...</p>
<p>Some labeling is essentially arbitrary, so that "giver" and "receiver"
switch.</p>
<p>Consider a three-point graph. Our "point of view" node is attached to
two others. Label them however you want, the give/receive with us
remains the same. But when you switch those two, give/receive change
direction between them, and if they're not equal, that will send a
point over the diagonal and change the correlation.</p>
<p>Cool.</p>
<hr>
<blockquote>
<p>"Social Relations Model, or SRM" (page 462)</p>
</blockquote>
<hr>
<blockquote>
<p>"The general approach is known as Gaussian Process regression. This
name is unfortunately wholly uninformative about what it is for and
how it works." (page 468)</p>
</blockquote>
<p>I like the phrase the author uses to describe GP regression:
"continuous categories".</p>
<hr>
<blockquote>
<p>"phylogenic, or <a href="https://en.wikipedia.org/wiki/Patrocladogram">patristic</a>, distance." (page 481)</p>
</blockquote>
<hr>
<blockquote>
<p>"<a href="https://www.carlboettiger.info/2013/10/11/is-it-time-to-retire-pagels-lambda.html">Pagel's lambda</a>" (page 482)</p>
</blockquote>
<hr>
<blockquote>
<p>"Biologists tend to use phylogenies under a cloud of superstition
and fearful button pushing." (page 482)</p>
</blockquote>
<hr>
<blockquote>
<p>"Gaussian processes represent a practical method of extending the
varying effects strategy to continuous dimensions of similarity,
such as spatial, network, phylogenic, or any other abstract distance
between entities in the data." (page 485)</p>
</blockquote>
<hr>
<p>The <a href="https://mc-stan.org/docs/2_26/stan-users-guide/gaussian-process-regression.html">Stan documenation</a> has more on fitting GP regressions.</p>
<p>I think the thing that keeps this kind of GP from fitting the data
perfectly, as is <a href="https://planspace.org/20181226-gaussian_processes_are_not_so_fancy/">often the case</a> with GPs, is the eta term...</p>
<p>But really, why doesn't it fit the data perfectly? In the primates
example, there's a correlation matrix that clearly includes ones...</p>
<p>Oh! It's because the kernel matrix doesn't enter into the mean! ...
Well, that's the case for the primates example, anyway...</p>
<p>So the effect of just changing the covariance matrix is like this:</p>
<pre><code class="language-r">install.packages('mvtnorm')
library(mvtnorm)

data &lt;- c(1, 1, -1, -1)

# the mean here defaults to c(0, 0, 0, 0)

# "standard" 4d normal (identity for covariance matrix)
dmvnorm(data)
# 0.003428083

# covariance matrix that expects clustering
sigma &lt;- matrix(c(1, 0.5, 0, 0,
                  0.5, 1, 0, 0,
                  0, 0, 1, 0.5,
                  0, 0, 0.5, 1), nrow=4)
dmvnorm(data, sigma=sigma)
# 0.008902658 (more likely than when assuming independence)</code></pre>

<p>So when expecting clustering, you don't have to explain via the mean
as much...</p>
<p>For the primates example, he gets a significant coefficient on group
size, then he makes it go away via covariance, and then he uses a
different covariance and gets it back...</p>
<blockquote>
<p>"This [the second] model annihilates group size—the posterior mean
is almost zero and there is a lot of mass on both sides of zero. The
big change from the previous model suggests that there is a lot of
clustering of brain size in the tree and that this produces a
spurious relationship with group size, which also clusters in the
tree." (page 482)</p>
</blockquote>
<p>This is a little weird, isn't it? Just because the relationship
clusters in the tree, that doesn't mean there isn't a relationship,
right? There are at least two interpretations: (a) bigger groups and
bigger brains co-evolved, in this part of the tree, and (b) this part
of tree just happens to have both bigger groups and bigger brains. I
guess it's a potential confound?</p>
<p>In the final example he gets less covariance and the coefficient on
brain size comes back. Which model is more right? Doesn't seem very
obvious to me.</p>
<p>Ah: For the earlier example, it's a Poisson regression anyway, so it's
not obvious it could fit perfectly anyway, because of the link
function.</p>
<p>And the multi-variate normal bit has mean zero! It can only pull out
of the mean zero distribution with given covariance (which is
constrained by prior so variance isn't very big). So there's really no
chance of fitting perfectly.</p>
<hr>
<h3><a name="ch15" href="#ch15">Chapter 15: Missing Data and Other Opportunities</a></h3>
<ul>
<li>15.1. "Measurement error" (Oh! Like Nate Silver with polls!)</li>
<li>15.2. "Missing data"</li>
<li>15.3. "Categorical errors and discrete absences" (sum over options)</li>
</ul>
<hr>
<blockquote>
<p>"A big advantage of Bayesian inference is that it obviates the need
to be clever. ... There's no need to be clever when you can be
ruthless." (page 489)</p>
</blockquote>
<p>(The ruthlessness is ruthlessness in applying rules of conditional
probability.)</p>
<hr>
<blockquote>
<p>"And that's the real trick of the Bayesian approach: to apply
conditional probability in all places, for data and parameters."
(page 490)</p>
</blockquote>
<hr>
<blockquote>
<p>"Bayes is an honest partner. It is not afraid to hurt your
feelings." (page 491)</p>
</blockquote>
<hr>
<blockquote>
<p>"The big take home point for this section is that when you have a
distribution of values, don't reduce it down to a single value to
use in a regression." (page 497)</p>
</blockquote>
<hr>
<blockquote>
<p>"This [considering covariance between errors] is computationally
similar to how we did instrumental variable regression in the
previous chapter." (page 498)</p>
</blockquote>
<p>It sounds like instrumental variables are often (originally?) about
measurement error, but I don't completely understand how...</p>
<hr>
<blockquote>
<p>"Use your background knowledge to write down a generative model or
models, simulate data from these models in order to understand the
inferential risks, and design a statistical approach that can work
at least in theory." (page 499)</p>
</blockquote>
<hr>
<blockquote>
<p>"So there will be a posterior distribution for each missing value."
(page 505)</p>
</blockquote>
<p>In the model, when we <em>have</em> data, the distribution we enter is
interpreted as a <em>likelihood</em>, but when we <em>don't have</em> data (it's
missing), the distribution is interpreted as a prior... Neat!</p>
<hr>
<blockquote>
<p>"Implementing an imputation model can be done several ways. All of
the ways are a little awkward, because the locations of missing
values have to be respected, and that means plenty of index
management." (page 506)</p>
</blockquote>
<hr>
<blockquote>
<p>"Doing better is good." (page 511)</p>
</blockquote>
<hr>
<blockquote>
<p>"If you aren't comfortable dropping incomplete cases, then you
shouldn't be comfortable using multiple imputation either." (page
511)</p>
</blockquote>
<p>This is maybe a little strong; he's explaining here that multiple
imputation is an approximation of the technique he's advocating, after
all.</p>
<hr>
<p>He refs this paper, which has some missing data:
<a href="https://www.nature.com/articles/s41586-019-1043-4">Complex societies precede moralizing gods throughout world history</a>.</p>
<hr>
<blockquote>
<p>"HMC just doesn't do discrete variables." (page 516)</p>
</blockquote>
<hr>
<blockquote>
<p>"This all sounds too good to be true. It is all true. But
implementing it is not at all obvious." (page 517)</p>
</blockquote>
<hr>
<blockquote>
<p>"This chapter highlights the general principles of the book, that
effective statistical modeling requires both careful thought about
how the data were generated and delicate attention to numerical
algorithms. Neither can lift inference alone." (page 521)</p>
</blockquote>
<h3><a name="ch16" href="#ch16">Chapter 16: Generalized Linear Madness</a></h3>
<p>beyond GLMs</p>
<hr>
<ul>
<li>16.1. "Geometric people"</li>
<li>16.2. "Hidden minds and observed hehavior"</li>
<li>16.3. "Ordinary differential nut cracking"</li>
<li>16.4. "Population dynamics"</li>
</ul>
<hr>
<blockquote>
<p>"GLMs (or GLMMs)" (page  526)</p>
</blockquote>
<p>"GLMM" is "<a href="https://en.wikipedia.org/wiki/Generalized_linear_mixed_model">Generalized linear mixed model</a>" where "mixed" means
adding "random effects" in addition to "fixed effects" which means
doing something hierarchical, essentially. Varying effects, per
individual, group, etc.</p>
<hr>
<blockquote>
<p>"Useful mathematical modeling typically involves ridiculous
assumptions." (page 527)</p>
</blockquote>
<p>The 1985 "Consider a Spherical Cow: A Course in Environmental Problem
Solving" doesn't seem to be the origin of the <a href="https://en.wikipedia.org/wiki/Spherical_cow">spherical cow</a>, but
it's still fun.</p>
<p>Three cites here:</p>
<ul>
<li><a href="https://uberty.org/wp-content/uploads/2015/07/Levins-1966-Model_Building.pdf">The Strategy of Model Building in Population Biology</a></li>
<li><a href="https://www.journals.uchicago.edu/doi/abs/10.1086/341764">Using False Models to Elaborate Constraints on Processes: Blending Inheritance in Organic and Cultural Evolution</a>, which includes in its abstract: "Scientific models may be more useful for false assumptions they make than true ones when one is interested not in the fit of the model, but in the form of the residuals."</li>
<li><a href="https://www.taylorfrancis.com/chapters/edit/10.4324/9781315173726-14/models-stupid-need-paul-smaldino">Models Are Stupid, and We Need More of Them</a></li>
</ul>
<hr>
<blockquote>
<p>"One of the major advantages of having a scientifically inspired
model is that the parameters have meanings." (page 528)</p>
</blockquote>
<hr>
<blockquote>
<p>"The key, as always is to think generatively." (page 531)</p>
</blockquote>
<hr>
<p><a href="https://www.nature.com/articles/s41598-018-38392-8">Learning curves and teaching when acquiring nut-cracking in humans and chimpanzees</a></p>
<hr>
<blockquote>
<p>"no lag beyond one period makes any causal sense." (page 543)</p>
</blockquote>
<p>I think this is too strong, and he walks it back a little...</p>
<hr>
<ul>
<li><a href="http://www.scholarpedia.org/article/State_space_model">State Space Model (SSM)</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hidden_Markov_model">Hidden Markov Model (HMM)</a></li>
</ul>
<hr>
<blockquote>
<p>"Sometimes all this nonsense is okay, if all you care about is
forecasting. But often these models don't even make good forecasts,
because getting the future right often depends upon having a decent
causal model." (page 543)</p>
</blockquote>
<hr>
<p>This particular model is a famous one, the <a href="https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations">Lotka-Volterra Model</a>.
It models simple predator-prey interactions and demonstrates several
important things about ecological dynamics. Lots can be proved about
it without using any data at all. For example, the population tends to
be unstable, cycling up and down like in Figure 16.6. This is
interesting because it suggests that, while nature is more
complicated, all that is necessary to see cyclical population dynamics
is captured in a stupidly simple model. (page 544)</p>
<hr>
<blockquote>
<p>"The hidden states are the causes. The measurements don't cause
anything." (page 549)</p>
</blockquote>
<hr>
<h3><a name="ch17" href="#ch17">Chapter 17: Horoscopes</a></h3>
<p>conclusion</p>
<hr>
<blockquote>
<p>"Thinking generatively—how the data could arise—solves many
problems. Many statistical problems cannot be solved with
statistics. All variables are measured with error. Conditioning on
variables creates as many problems as it solves. There is no
inference without assumption, but do not choose your assumptions for
the sake of inference. Build complex models one piece at a time. Be
critical. Be kind." (page 553)</p>
</blockquote>
<hr>
<blockquote>
<p>"Philosophers of science actually have a term, <em>the pessimistic
induction</em>, for the observation that because most science has been
wrong, most science is wrong." (page 554)</p>
</blockquote>
<hr>
<p><a href="https://journals.sagepub.com/doi/full/10.1177/1745691612459059">A Vast Graveyard of Undead Theories: Publication Bias and Psychological Science’s Aversion to the Null</a></p>
<hr>
<blockquote>
<p>"Even retracted papers continue to be cited." (page 555)</p>
</blockquote>
<p>This makes me wonder whether there could be some proactive system to
inform authors of such issues... "I see you cited this paper; did you
know?"</p>
<hr>
<blockquote>
<p>"The data and its analysis are the scientific product. The paper is
just an advertisement." (page 555)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210508-statistical_rethinking_by_mcelreath/</link>
<guid>http://planspace.org/20210508-statistical_rethinking_by_mcelreath/</guid>
<pubDate>Sat, 08 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Scout Mindset, by Galef</title>
<description><![CDATA[

<p>The metaphor is soldier vs. scout. The advice is broadly good. With no
real discussion of epistemology but an implicit (roughly positivist?)
assumed worldview, I felt interesting foundational discussion was
elided. There was also little directly on “hard” (not yet known or
unknowable) questions. My critique is principally that I wanted more.</p>
<ul>
<li><a href="#more">Quotes and notes</a></li>
<li><a href="#outline">Slightly expanded table of contents</a></li>
</ul>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<h3><a name="more" href="#more">Quotes and notes</a></h3>
<hr>
<blockquote>
<p>"our judgment isn’t limited by knowledge nearly as much as it’s
limited by attitude." (page x)</p>
</blockquote>
<hr>
<blockquote>
<p>"In “Persuasion,” we saw that law students who are randomly assigned
to one side of a moot court case become confident, after reading the
case materials, that their side is morally and legally in the right.
But that confidence doesn’t help them persuade the judge. On the
contrary, law students who are more confident in the merits of their
own side are significantly <em>less</em> likely to win the case—perhaps
because they fail to consider and prepare for the rebuttals to their
arguments." (page 27)</p>
</blockquote>
<p>This cites <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/667711?journalCode=jls">Eigen and Listokin</a>, and I don’t have access or
inclination to read the paper just now, but it seems like there’s a
claim here like “confidence causes bad performance” and I wonder
whether possible confounds have been considered. To me, “lower quality
lawyer causes both confidence and bad performance” seems plausible.</p>
<hr>
<blockquote>
<p>"Having an accurate map doesn’t help you very much when you’re
allowed to travel only one path." (page 40)</p>
</blockquote>
<hr>
<p>Page 45 starts an exploration of Kahan’s famous paper on
<a href="https://www.nature.com/articles/nclimate1547" title="The polarizing impact of science literacy and numeracy on perceived climate change risks">scientific polarization increasing with education</a>. Perhaps in an
effort to avoid alienating any readers, the tools of the scout are not
applied to settle the question of whether global warming is real. The
opportunity to engage one way or another with the idea of
<a href="https://en.wikipedia.org/wiki/Na%C3%AFve_realism_(psychology)" title="Naïve realism">naive realism</a> is not taken.</p>
<p>In Harford’s <a href="https://planspace.org/20210330-how_to_make_the_world_add_up_by_harford/#golden">treatment</a> of Kahan, I really appreciated the emphasis
on <em>curiosity</em> being essential for “scout-like” thinking.</p>
<hr>
<p>I think I hadn’t seen the idea of Blind Data Analysis mentioned on
page 55, citing <a href="https://www.nature.com/news/how-scientists-fool-themselves-and-how-they-can-stop-1.18517">Nuzzo</a>. Nice! Will keep this in mind.</p>
<hr>
<blockquote>
<p>"It [being critical of a study with undesirable results] prompted me
to go back through the studies I had been planning to cite in my
favor, and scrutinize their methodology for flaws, just as I had
done with the pro-soldier mindset study. (Sadly, this ended up
disqualifying most of them.)" (page 68)</p>
</blockquote>
<p>I’m not sure to what extent this is a joke; I thought it was funny as
I read it. But seriously, I wish people generally would <a href="https://www.paperswithoutcode.com/">say more</a>
about determinations such as this.</p>
<hr>
<p>I might be a soldier on this, but I don’t love quantifying uncertainty
in the manner of the calibration game introduced starting on page 75.
I thought a little bit about why.</p>
<ul>
<li>For simple matters of fact, uncertainty is ignorance. It just isn’t
   that interesting, or useful. You can go check and get 100% (or
   close) confidence.</li>
<li>For predictions about the future, there are interesting questions
   about what confidence means (is the universe deterministic? what is
   knowable?) and I think there’s no way to know whether your
   prediction <em>at a given time</em> is calibrated. The advice is to update
   your estimate over time, after all. If I say event <em>x</em> (to be
   evaluated in a week) is 20% likely today but 10% likely tomorrow,
   was I "right" at those respective times? Did the probability
   change, or just my estimate? Is there such a thing as "correct
   probability given what you know," likely different from true
   probability?</li>
<li>For difficult propositions, there is no oracle; you can’t
   calibrate. Worse, consensus can change over time. When it was
   consensus, what confidence in <a href="https://en.wikipedia.org/wiki/Aether_(classical_element)">aether</a> would have been
   appropriate? How confident should you be in a research result
   before it comes out that an error in analysis invalidates it? How
   confident should you be in a value judgment?</li>
<li>If we’re serious about quantifying confidence, shouldn’t we also
   estimate confidence in our confidence? Like: I’m 60% confident,
   plus or minus 10pp. This seems necessary, to allow for things like
   mistaken beliefs about current evidence. It also seems silly.</li>
</ul>
<p>I’m not sure I have any really coherent argument here. I agree with
the general idea of being aware of how sure you are. Somehow I don’t
like the exercise of writing down numbers for it.</p>
<p>There is an interesting topic of decision-making in the face of low
confidence. What do you do when you know you’re not sure? (Ramble,
seems to be my answer.) Maybe out of scope for the book.</p>
<hr>
<blockquote>
<p>"The reality is that there’s no clear divide between the
“decision-making” and “execution” stages of pursuing a goal. Over
time, your situation will change, or you’ll learn new information,
and you’ll need to revise your estimate of the odds." (page 110)</p>
</blockquote>
<p>I really agree with this. Planning can be valuable, but following the
plan to the letter is often not.</p>
<hr>
<p>Galef discusses low (10%, 30%) early estimates of “success” from Musk
and Bezos (starting page 111). Exploring why they would take such
chances, she mentions both expected value (10% of huge is still big)
and the idea that even “failure” would be fairly positive. I think
expected value is almost always the wrong way to think about
significant choices (especially one-shot choices with unclear odds)
and I don’t really believe it’s how people tend to think (or should).
I think the question of whether something is
<a href="/20181204-worth_doing_even_if_it_fails/">worth doing, even if it fails</a> is the right question. So I think
the balance of emphasis is off here. Expected value is a simple tool,
a hammer that people reach for <a href="/2012/06/04/expected-value-is-not-useful-for-making/">too often</a>, simplifying problems too
far. I wouldn’t even mention it in this setting.</p>
<hr>
<blockquote>
<p>"You might think these principles sound obvious and that you know
them already. But “knowing” a principle, in the sense that you read
it and say, “Yes, I know that,” is different from having
internalized it in a way that actually changes how you think." (page
144)</p>
</blockquote>
<hr>
<blockquote>
<p>"In his book <em>Sources of Power</em>, decision researcher Gary Klein
cites this [explaining away signs of a problem] as one of the top
three causes of bad decisions. He calls it a “de minimus error,” an
attempt to minimize the inconsistency between observations and
theory. Each new piece of evidence that doesn’t fit a doctor’s
medical diagnosis can be explained away or dismissed as a fluke, so
the doctor never realizes her initial diagnosis was wrong." (page
165)</p>
</blockquote>
<hr>
<p><a href="https://www.pnas.org/content/115/37/9216">Exposure to opposing views on social media can increase political polarization</a> cited in chapter 12.</p>
<hr>
<p><a href="http://www.paulgraham.com/identity.html">Keep your identity small</a> cited in chapter 14.</p>
<hr>
<blockquote>
<p>"They [a group of citizen scientists] also dove into the politics of
government research, familiarizing themselves with how funding was
structured and how the drug trials were conducted. The
disorganization they discovered alarmed them. “It sort of felt like
reaching the Wizard of Oz,” said one activist named Mark Harrington.
“You’ve gotten to the center of the whole system and there’s just
this schmuck behind a curtain.”" (page 212)</p>
</blockquote>
<p>Cites <a href="https://www.penguinrandomhouse.com/books/209900/how-to-survive-a-plague-by-david-france/">How to Survive a Plague</a>.</p>
<hr>
<h3><a name="outline" href="#outline">Slightly expanded table of contents</a></h3>
<ul>
<li>Introduction<ul>
<li>Realize that truth isn't in conflict with your other goals</li>
<li>Learn tools that make it easier to see clearly</li>
<li>Appreciate the emotional rewards of scout mindset</li>
</ul>
</li>
<li>Part 1: The case for scout mindset<ul>
<li>Chapter 1: Two types of thinking<ul>
<li>“Can I believe it?” vs. “Must I believe it?”</li>
</ul>
</li>
<li>Chapter 2: What the soldier is protecting</li>
<li>Chapter 3: Why truth is more valuable than we realize</li>
</ul>
</li>
<li>Part 2: Developing self-awareness<ul>
<li>Chapter 4: Signs of a scout<ul>
<li>Do you tell other people when you realize they were right?</li>
<li>How do you react to personal criticism?</li>
<li>Do you ever prove yourself wrong?</li>
<li>Do you take precautions to avoid fooling yourself?</li>
<li>Do you have any good critics?</li>
<li>Can you point to occasions in which you were in soldier
   mindset?</li>
</ul>
</li>
<li>Chapter 5: Noticing bias<ul>
<li>The double standard test</li>
<li>The outsider test</li>
<li>The conformity test</li>
<li>The selective skeptic test</li>
<li>The status quo bias test</li>
<li>Core skill: "a sense that your judgments are
   <em>contingent</em>—that what seems true or reasonable or fair or
   desirable can change when you mentally vary some feature of
   the question that should have been irrelevant." (page 87)</li>
</ul>
</li>
<li>Chapter 6: How sure are you?<ul>
<li>Core skill: "being able to tell the difference between the
   feeling of <em>making a claim</em> and the feeling of <em>actually
   trying to guess what's true</em>." (page 87)</li>
</ul>
</li>
</ul>
</li>
<li>Part 3: Thriving without illusion<ul>
<li>Chapter 7: Coping with reality</li>
<li>Chapter 8: Motivation without self-deception</li>
<li>Chapter 9: Influence without overconfidence</li>
</ul>
</li>
<li>Part 4: Changing your mind<ul>
<li>Chapter 10: How to be wrong</li>
<li>Chapter 11: Lean in to confusion</li>
<li>Chapter 12: Escape your echo chamber</li>
</ul>
</li>
<li>Part 5: Rethinking identity<ul>
<li>Chapter 13: How beliefs become identities</li>
<li>Chapter 14: Hold your identity lightly</li>
<li>Chapter 15: A scout identity</li>
</ul>
</li>
</ul>
<!-- https://twitter.com/planarrowspace/status/1388919415660548102 -->    
    ]]></description>
<link>http://planspace.org/20210502-the_scout_mindset_by_galef/</link>
<guid>http://planspace.org/20210502-the_scout_mindset_by_galef/</guid>
<pubDate>Sun, 02 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Simple Front Door Regression</title>
<description><![CDATA[

<p>If you have a mediator, you can estimate effects despite confounding,
which is neat. The idea is like flip of <a href="/20210430-a_simple_instrumental_variable/">instrumental variables</a>;
here the constructed non-confounded variable is what’s not explained
by the confounded one. A <a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation#Interpretation_as_two-stage_least_squares">two-stage regression</a> illustrates the
idea.</p>
<p>We seek to estimate the impact of <em>x</em> on <em>y</em>, where they’re both
influenced by <em>u</em>.</p>
<p><img alt="front door scenario" src="front_door.jpg"></p>
<p>Unfortunately, <em>u</em> is <em>u</em>nobserved, so we can’t control for it.
But lo, there is <em>z</em>, a perfect mediator between <em>x</em> and <em>y</em>. Let’s
simulate data where all the true coefficients are one.</p>
<!-- set.seed(101) -->

<pre><code class="language-r">u = rnorm(100)
x = u + rnorm(100)
z = x + rnorm(100)
y = u + z + rnorm(100)</code></pre>

<p>Regressing naively, we get an incorrect estimate for the effect of <em>x</em>
on <em>y</em>.</p>
<pre><code class="language-r">summary(lm(y ~ x))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.54648    0.09848  15.704   &lt;2e-16 ***</code></pre>

<p>Luckily, <em>z</em> is in there, and it isn’t confounded with <em>u</em>.</p>
<p>But how do we use it? Throwing it in the regression doesn’t help.</p>
<pre><code class="language-r">summary(lm(y ~ x + z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            0.46175    0.15517   2.976  0.00369 **
##  z            1.02436    0.12740   8.041  2.2e-12 ***</code></pre>

<p>A fancier model-fitting approach is needed. Here’s an illustrative
two-stage regression, ignoring standard error concerns.</p>
<p>Stage one: Do a regression using <em>x</em> to predict <em>z</em>. Note the
coefficient on <em>x</em>. Then get the residuals for <em>z</em> from that model,
which I’ll call <em>z_not_from_x</em>. This uses the non-confounding of <em>z</em>
with <em>u</em> to make a “version of” (maybe a component of) <em>z</em> that is
independent of <em>u</em> (because it’s independent of <em>x</em>): the variation of
<em>z</em> not due to <em>x</em> (or <em>u</em>).</p>
<p>Stage two: Do a regression using <em>z_not_from_x</em> to predict <em>y</em>.</p>
<p>Multiplying the coefficients from the two models gives the effect of
<em>x</em> on <em>y</em>.</p>
<pre><code class="language-r">summary(lm(z ~ x))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x           1.058940   0.060797  17.418   &lt;2e-16 ***
z_not_from_x = residuals(lm(z ~ x))
summary(lm(y ~ z_not_from_x))
##               Estimate Std. Error t value Pr(&gt;|t|)
##  z_not_from_x   1.0244     0.2889   3.546 0.000601 ***
1.058940 * 1.0244  # Estimate for x on y
##  1.084778</code></pre>

<p>We’ve recovered a fair estimate of the true parameter for <em>x</em>, despite
not using the unobserved confound <em>u</em>!</p>
<p>Here’s the same thing as above but with the <code>lavaan</code> <a href="https://lavaan.ugent.be/">package</a> for
<a href="https://en.wikipedia.org/wiki/Structural_equation_modeling">SEM</a>, following <a href="http://www.felixthoemmes.com/blog/the-front-door-criterion-in-linear-parametric-models/">Thoemmes</a>.</p>
<pre><code class="language-r">model = "z ~ x_on_z * x
         y ~ z_on_y * z
         x ~~ y  # Allow x and y to still covary
         x_on_y := x_on_z * z_on_y"
summary(sem(model, data.frame(x=x, z=z, y=y)))
##                   Estimate  Std.Err  z-value  P(&gt;|z|)
##    x_on_z            1.059    0.060   17.594    0.000
##    z_on_y            1.024    0.125    8.164    0.000
##    x_on_y            1.085    0.146    7.406    0.000</code></pre>

<p>So there’s standard errors for you!</p>
<hr>
<h3>Other cases</h3>
<p>This example goes well with a collection of four simpler ("back door")
regression situations, <a href="/20200912-what_should_be_in_your_regression/">What should be in your regression?</a> It goes
especially well with its cousin, <a href="/20210430-a_simple_instrumental_variable/">A simple Instrumental Variable</a>.</p>
<hr>
<h3>More complicated cases</h3>
<p>The <a href="http://www.dagitty.net/">dagitty</a> tools seems to be a great way to analyze a given
situation (expressed as a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>) and figure out what you can do with
it.</p>
<p>Maybe regression discontinuity is another kind of case?</p>    
    ]]></description>
<link>http://planspace.org/20210501-simple_front_door_regression/</link>
<guid>http://planspace.org/20210501-simple_front_door_regression/</guid>
<pubDate>Sat, 01 May 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>A simple Instrumental Variable</title>
<description><![CDATA[

<p>Instrumental variables can let you estimate effects despite
confounding, which is pretty neat. The idea is sort of that the
instrument helps identify a non-confounded version of a variable, as
illustrated in the over-simplified version of
<a href="https://en.wikipedia.org/wiki/Instrumental_variables_estimation#Interpretation_as_two-stage_least_squares">two-stage least squares</a> below.</p>
<p>We seek to estimate the impact of <em>x</em> on <em>y</em>, where they’re both
influenced by <em>u</em>.</p>
<p><img alt="diagram of simple instrumental variable setup" src="simple_iv.jpg"></p>
<p>Unfortunately, <em>u</em> is <em>u</em>nobserved, so we can’t control for it.
But lo, there is <em>z</em> influencing <em>x</em>. Let’s simulate data where all
the true coefficients are one.</p>
<!-- set.seed(42) -->

<pre><code class="language-r">u = rnorm(100)
z = rnorm(100)
x = u + z + rnorm(100)
y = u + x + rnorm(100)</code></pre>

<p>Regressing naively, we get an incorrect estimate for the effect of <em>x</em>
on <em>y</em>.</p>
<pre><code class="language-r">summary(lm(y ~ x))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.35260    0.07697  17.573   &lt;2e-16 ***</code></pre>

<p>Luckily, <em>z</em> is an “instrument,” satisfying three requirements
(following <a href="https://xcelab.net/rm/statistical-rethinking/">McElreath</a>):</p>
<ul>
<li><em>z</em> is independent of <em>u</em></li>
<li><em>z</em> is not independent of <em>x</em></li>
<li><em>z</em> doesn’t influence <em>y</em> except through <em>x</em></li>
</ul>
<p>But how do we use the instrument? Throwing it in the regression makes
things <em>worse</em>:</p>
<pre><code class="language-r">summary(lm(y ~ x + z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.52949    0.09207  16.612  &lt; 2e-16 ***
##  z           -0.54659    0.17099  -3.197  0.00188 **</code></pre>

<p>A fancier model-fitting approach is needed. McElreath points out that
two-stage least squares is not the only way to do this, and also that
there should be some adjustments to make the standard errors make
sense. I’m going to ignore adjustments and just try to get some
intuition from how two-stage least squares works.</p>
<p>Stage one: Do a regression using <em>z</em> to predict <em>x</em>. Then get the
predictions for <em>x</em> from that model, which I’ll call <em>x_from_z</em>. This
uses the independence of <em>z</em> from <em>u</em> to make a “version of” (maybe a
component of) <em>x</em> that is independent of <em>u</em>: the variation of <em>x</em> due
to <em>z</em>.</p>
<p>Stage two: Do a regression using <em>x_from_z</em> to predict <em>y</em>.</p>
<pre><code class="language-r">x_from_z = predict(lm(x ~ z))
summary(lm(y ~ x_from_z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x_from_z     1.03978    0.23886   4.353  3.3e-05 ***</code></pre>

<p>We’ve recovered a fair estimate of the true parameter for <em>x</em>, despite
not using the unobserved confound <em>u</em>!</p>
<p>Here’s the same thing as above but with the <code>ivreg</code> <a href="https://john-d-fox.github.io/ivreg/">package</a>,
correcting the standard error:</p>
<pre><code class="language-r">summary(ivreg(y ~ x | z))
##              Estimate Std. Error t value Pr(&gt;|t|)
##  x            1.03978    0.13844   7.511 2.77e-11 ***</code></pre>

<p>You could also use <a href="https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo">HMC</a> as in <a href="https://xcelab.net/rm/statistical-rethinking/">McElreath</a> §14.3.</p>
<hr>
<h3>Simpler cases</h3>
<p>This example of an instrumental variable situation extends the earlier
collection of four simpler regression situations,
<a href="/20200912-what_should_be_in_your_regression/">What should be in your regression?</a></p>
<hr>
<h3>More complicated cases</h3>
<p>The <a href="http://www.dagitty.net/">dagitty</a> tools seems to be a great way to analyze a given
situation (expressed as a <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">DAG</a>) and figure out what you should
control for and/or whether there are instruments you can use to
estimate a given effect.</p>
<p>There’s also the front-door criterion, which I’m not yet sure how to
fit a model for. Maybe I’ll try to write something up eventually.</p>
<p>Maybe regression discontinuity is another kind of case?</p>    
    ]]></description>
<link>http://planspace.org/20210430-a_simple_instrumental_variable/</link>
<guid>http://planspace.org/20210430-a_simple_instrumental_variable/</guid>
<pubDate>Fri, 30 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Diamond Age, by Stephenson</title>
<description><![CDATA[

<p>This <a href="https://www.nealstephenson.com/the-diamond-age.html">novel</a> about an educational book invites comparison to its
subject. Stephenson's pedagogy walks you through Chekhov's armory,
dense with mental condensation nuclei, firing guns at the end but
maintaining ambiguity. Steam punk nanotech is backdrop for a My Fair
Lady story and revolution, with themes of <a href="https://en.wikipedia.org/wiki/Mind%E2%80%93body_dualism">dualism</a> and generally
flawed humans.</p>
<p><img alt="cover" src="cover.jpg"></p>
<h3>Economics and technology</h3>
<p>I read Diamond Age because it was mentioned in <a href="https://planspace.org/20210401-trekonomics_by_saadia/">Trekonomics</a>. They
have a technology like a replicator, but it doesn't really feel like a
post-scarcity world because its use is centrally controlled/limited.</p>
<blockquote>
<p>"... the Feed is not a system of control and oppression, as CryptNet
would maintain. It is the only way order can be maintained in modern
society—if everyone possessed a Seed, anyone could produce weapons
whose destructive power rivalled that of Elizabethan nuclear
weapons." (page 384, Hackworth speaking unconvincingly)</p>
</blockquote>
<p>The Seed, never quite achieved in the book, is a nanotech magic bean
that promises to usher in a decentralized post-scarcity world, like
farming communes where you can grow anything effortlessly, biological
or mechanical. Its creation is opposed by the less obviously
destructive factions based on fear of loss of control.</p>
<p>Some of the rich and powerful are referred to as "Equity Lords," which
is an interesting title, especially in relation to modern tech
companies where people have equity to varying degrees, or more
generally in connection with people who own stock in the markets.</p>
<h3>Anti-relativism</h3>
<blockquote>
<p>"Finkle-McGraw began to develop an opinion that was to shape his
political views in later years, namely, that while people were not
<em>genetically</em> different, they were <em>culturally</em> as different as they
could possibly be, and that some cultures were simply better than
others. This was not a subjective value judgment, merely an
observation that some cultures thrived and expanded while others
failed. It was a view implicitly shared by nearly everyone but, in
those days, never voiced." (pages 20-21)</p>
<p>"[Nell's mother] didn't like craftsmen, she said, because they were
too much like actual Victorians, always spouting all kinds of crap
about how one thing was better than another thing, which eventually
led, she explained, to the belief that some people were better than
others." (page 185)</p>
<p>"it is upon moral qualities that a society is ultimately founded.
All the prosperity and technological sophistication in the world is
of no use without that foundation—we learned this in the late
twentieth century, when it became unfashionable to teach these
things." (page 322, Miss Matheson speaking)</p>
</blockquote>
<p>The "Neo-Victorian" group is largely a reaction to techno-hedonism. It
reminds me of how it can seem these days that wealthier people are
more likely to choose old-fashioned wooden toys and the like for their
children, more likely to avoid screen time.</p>
<p>In the extreme, I think this kind of view takes a form like
<a href="https://www.amazon.com/Absolute-Relativism-Dictatorship-What-about/dp/1933919469">Absolute Relativism: The New Dictatorship</a>.</p>
<h3>Rugged individualism</h3>
<blockquote>
<p>"Grandfather loved to tell stories of these criminals, how they had
tried to excuse their own crimes by pleading that they were
economically disadvantaged or infected with the disease of substance
abuse, and how the Lone Eagles—many of whom had overcome poverty or
addiction themselves—had dispatched them with firing squads and left
them posted around the edge of their territory as NO TRESPASSING
signs that even the illiterate could read." (pages 405-406)</p>
<p>"... the usual crowd of starving peasants and professional amputees"
(page 449)</p>
</blockquote>
<p>For one thing, it's pretty clearly not a post-scarcity society. For
another, it's not very shy about seeming to blame people for not doing
better for themselves despite this.</p>
<h3>Tribalism</h3>
<p>There's a lot of tribalism, much of it racial/racist. I think the
reasoning was that with the dissolution of traditional governments,
people needed to form their own equivalents more than they previously
did, but this wasn't super clear to me.</p>
<p>The major conflict, which develops mostly in the background until the
end of the book, is a second <a href="https://en.wikipedia.org/wiki/Boxer_Rebellion">Boxer Rebellion</a>.</p>
<p>It's not clear whether the ends justify the means, but there's at
least a chance the Seed could be a good idea. Would tribalism recede
in a true post-scarcity environment?</p>
<h3>Dualism</h3>
<p>Nanotechnology represents the material, physical world.</p>
<blockquote>
<p>"But [Hackworth, the nanotech engineer] had felt the need to go
beyond that—he had wanted to reach beyond mere matter and into
someone's soul." (page 188)</p>
</blockquote>
<p>Mercifully, there's no mention of quantum mechanics to introduce false
confusion. The technology is very physical in the classical sense;
nanotech computers use "rod logic" to achieve their results. With the
Neo-Victorians, it contributes to a steam punk vibe.</p>
<p>The discussion of dualism is extended to computing, with a substantial
exploration of Turing machines.</p>
<blockquote>
<p>"... a Turing machine, no matter how complex, was not human. It had
no soul. It could not do what a human did." (page 442)</p>
</blockquote>
<p>There's also no mention of <a href="https://en.wikipedia.org/wiki/Hypercomputation">hypercomputation</a>... An amusing thought:
is hypercomputation fundamentally dualist (implying non-physical
phenomena)?</p>
<h3>Education</h3>
<p>I'm interested in educational technology. It's largely <a href="/20201028-failure_to_disrupt_by_reich/">failed</a> to
revolutionize education so far, but many like <a href="https://moores.samaltman.com/">Altman</a> hold out hope
for "AI teachers that can diagnose and explain exactly what a student
doesn’t understand" and the like.</p>
<p>What is the goal of education? The instigator of the creation of the
AI teaching books says he wants to encourage subversion, but he also
thinks the effect of this will be creating people who tend to agree
with him.</p>
<blockquote>
<p>"You encourage subversiveness because you think that it will have an
effect opposite to what one might naively suppose." (page 365, Carl
Hollywood addressing Finkle-McGraw)</p>
</blockquote>
<p>Of the girls who get the three "original" books with voices done by
remote human voice actors, one girl becomes an actor in a strange
troupe, one joins a faction opposed to that of Finkle-McGraw (though
he thinks she'll return eventually), and one works scripts at a
specialist brothel and then eventually stymies (at least briefly) a
revolution that threatens a person she loves. Is this successful
education? Maybe?</p>
<p>There are also hundreds of thousands of girls who were raised by books
with computer-generated voices. Their books were also further modified
by Hackworth.</p>
<blockquote>
<p>"At this point, John Percival Hackworth, almost without thinking
about it and without appreciating the ramifications of what he was
doing, devised a trick and slipped it in under the radar of the
Judge and Dr. X and all of the other people in the theatre, who were
better at noticing tricks than most other people in the world.
"While I'm at it, if it pleases the court, I can also," Hackworth
said, most obsequiously, "make changes in the content so that it
will be more suitable for the unique cultural requirements of the
Han readership."" (page 180)</p>
</blockquote>
<p>Everybody who gets the Chinese-language version of the Primer goes on
to form the "mouse army" that serves Nell for unclear reasons toward
the end of the book.</p>
<p>Diamond Age definitely suggests that valuable aspects of human
development work best (or only) through human interaction. Multiple
times the importance of culture generally is emphasized. The AI book
is not necessarily any more enlightened than other kinds of education.
Maybe it can stand in for ed tech that is just a computerized version
of antique methods, despite all its customization.</p>
<p>There are other comments about education, but Stephenson sometimes
seems to be effectively free-associating, suggesting different aspects
to connect and consider.</p>
<hr>
<h3>More selected quotes</h3>
<hr>
<blockquote>
<p>"By nature, men are nearly alike; by practice, they get to be wide
apart." (epigraph, quoting <a href="https://china.usc.edu/confucius-analects-17">Confucius</a>)</p>
</blockquote>
<hr>
<blockquote>
<p>"A sizable investment, but the best a father could make." (page 78,
referring to education)</p>
</blockquote>
<hr>
<blockquote>
<p>"... Nell knew better than to fret over things she could not
change." (page 123)</p>
</blockquote>
<p>The Primer seems to have helped make Nell a <a href="/20210107-enchiridion_in_52_sentences/">stoic</a>.</p>
<hr>
<blockquote>
<p>"If the Coastal Republic had believed in the <em>existence</em> of virtue,
it could at least have aspired to hypocrisy." (page 144)</p>
</blockquote>
<hr>
<blockquote>
<p>"He is worth a thousand lesser engineers." (page 170, Dr. X
referring to Hackworth)</p>
</blockquote>
<hr>
<p>On page 184, the Primer is described as "a <a href="https://en.wikipedia.org/wiki/Propaedeutics">Propædeutic</a>
Enchiridion."</p>
<hr>
<blockquote>
<p>"She often put it under her pillow, though, and sometimes she even
woke up in the middle of the night and heard it whispering things to
her that she had just been dreaming about." (page 184)</p>
</blockquote>
<p>This seems to imply that the Primer employed some kinds of
subconscious programming techniques...</p>
<hr>
<blockquote>
<p>"But I think it is not likely to be the only instance in which real
life turns out to be more complicated than what you have seen in the
book." (page 281, Constable Moore speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>""Nell," the Constable continued, indicating through his tone of
voice that the lesson was concluding, "the difference between
ignorant people and educated people is that the latter know more
facts. But that has nothing to do with whether they are stupid or
intelligent. The difference between stupid and intelligent
people—and this is true whether or not they are well-educated—is
that intelligent people can handle subtlety. They are not baffled by
ambiguous or even contradictory situations—in fact, they expect them
and are apt to become suspicious when things seem overly
straightforward.</p>
<p>"In your Primer you have a resource that will make you highly
educated, but it will never make you intelligent. That comes from
life. Your life up to this point has given you all of the experience
you need to be intelligent, but you have to think about those
experiences. If you don't think about them, you'll be
psychologically unwell. If you do think about them, you will become
not merely educated but intelligent" (page 283)</p>
</blockquote>
<hr>
<blockquote>
<p>"She appears to be learning new material that isn't explicitly
covered in the Primer, and she's developing more sophisticated forms
of social interaction, suggesting that she's spending more time
around a higher class of people." (pages 284-285, Miranda speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>"And there was an ocean of history to be learned: first biblical,
Greek, and Roman, and then the history of many other peoples around
the world that essentially served as backdrop for History of the
English-Speaking Peoples." (page 312, describing the stodgy school)</p>
</blockquote>
<hr>
<blockquote>
<p>"Miss Stricken handled the big payoff at the end of each period and
at the end of each unit. She stormed in to explain what conclusion
they were being led to and to make sure that all of them got it."
(page 313)</p>
</blockquote>
<hr>
<blockquote>
<p>"She was tormented by the irrationality of this place." (page 319,
referring to the stodgy school)</p>
</blockquote>
<hr>
<blockquote>
<p>"Now, there was a time when we believed that what a human mind could
accomplish was determined by genetic factors. Piffle, of course, but
it looked convincing for many years, because distinctions between
tribes were so evident. Now we understand that it's all cultural.
That, after all, is what a culture is—a group of poeple who share in
common certain acquired traits." (page 321, Miss Matheson speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>"It is the hardest thing in the world to make educated Westerners
pull together," Miss Matheson went on. "That is the job of people
like Miss Stricken. We must forgive them their imperfections. She is
like an avatar—do you children know about avatars? She is the
physical embodiment of a principle. That principle is that outside
the comfortable and well-defended borders of our phyle is a hard
world that will come and hurt us if we are not careful. It is not an
easy job to have. We must all feel sorry for Miss Stricken." (page
323)</p>
</blockquote>
<hr>
<p>On pages 353 and 354 Miss Matheson goes on about how Nell is special.
"You are different." and so on. Are we supposed to believe her, or is
this just an aspect of the stodgy school weirdness? Other aspects of
the book don't seem aligned with Great Man thinking.</p>
<hr>
<blockquote>
<p>""Which path do you intend to take, Nell?" said the Constable,
sounding very interested. "Conformity or rebellion?""</p>
<p>""Neither one. Both ways are simple-minded—they are only for people
who cannot cope with contradiction and ambiguity."" (page 356)</p>
</blockquote>
<p>She goes to seek her fortune as a writer for a particularly involved
brothel.</p>
<hr>
<blockquote>
<p>""... [Miranda] was not merely Nell's tutor. She became Nell's
mother."" (page 357, Carl Hollywood speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>""In a tribe such as the F.D.R. [First Distributed Republic], whose
view of the universe contains no absolutes, this ritual
[elaborate trust-falls] creates an artificial absolute."" (page 378,
Hackworth explaining)</p>
</blockquote>
<hr>
<p>On page 383 there's a "thirty-third level" which seems like a
throwaway reference to Masonry...</p>
<hr>
<blockquote>
<p>"... Princess Nell had become so beautiful over the years and had
developed such a fine bearing that few people would mistake her for
a commoner now, even if she were dressed in rags and walking
barefoot."</p>
<p>"... Nell wondered at that. Princesses were not genetically
different from commoners." (page 386)</p>
</blockquote>
<hr>
<blockquote>
<p>"learning the language, which was extremely pithy and made heavy use
of parentheses."</p>
</blockquote>
<p>Some Lisp? Cute reference.</p>
<hr>
<blockquote>
<p>"Her stories were being digested, not by the Primer, but by another
human being, becoming a part of that person's mind." (pages 402-403)</p>
</blockquote>
<hr>
<blockquote>
<p>"But the Primer was, itself, a Turing machine, or so she suspected;
so how could it understand Nell?"</p>
<p>"Could it be that the Primer was just a conduit, a technological
system that mediated between Nell and some human being who really
loved her?" (page 403)</p>
</blockquote>
<p>Miranda provides the voicing for whatever the Primer wants to say.</p>
<hr>
<blockquote>
<p>""Belief isn't a binary state, not here at least. Does anyone
believe anything one hundred percent?"" (page 425)</p>
</blockquote>
<hr>
<blockquote>
<p>""Society has never been good at answering these questions—the sorts
of questions you can't just look up in a reference database."" (page
428)</p>
</blockquote>
<hr>
<blockquote>
<p>"But the human mind didn't work like a digital computer and was
capable of doing some funny things." (page 433)</p>
</blockquote>
<hr>
<blockquote>
<p>"It would be more correct to say that, although it was virtuous to
save them, it was mistaken to believe that they could be raised
properly. We lacked the resources to raise them individually, and so
we raised them with books. But the only proper way to raise a child
is within a family. The Master <a href="https://china.usc.edu/confucius-analects-17">Confucius</a> could have told us as
much, had we listened to his words." (page 455, Dr. X speaking)</p>
</blockquote>
<hr>
<blockquote>
<p>"... all of Nell's intellect, her vast knowledge and skills,
accumulated over a lifetime of intensive training, meant nothing at
all when she was confronted with a handful of organized peasants."
(page 469)</p>
</blockquote>
<hr>
<blockquote>
<p>"all of the societies that had grown up around the concept of a
centralized, hierarchical Feed." (page 498)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210422-the_diamond_age_by_stephenson/</link>
<guid>http://planspace.org/20210422-the_diamond_age_by_stephenson/</guid>
<pubDate>Thu, 22 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Learn You a Haskell for Great Good! by Lipovača</title>
<description><![CDATA[

<p>Here's a good <a href="http://learnyouahaskell.com/">book</a> you can read for free. Like it says on the
back, "Maps, Monads, Monoids, and More!" It does a great job
explaining things in ways that are helpful. The humble list can be a
functor, an applicative functor, a monoid, and a monad.</p>
<p>There's a <a href="http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html">joke</a>: "A monad is just a monoid in the category of
endofunctors, what's the problem?" This is like saying "the median is
just a medoid on the field of reals."</p>
<p>In both cases, if you don't know what the first term is, you likely
don't know what the others are. It's not a good way to explain.</p>
<p>In both cases, the explanatory terms are needlessly obscure: "endo" is
likely gratuitous; "field of reals" is probably not better than
"numbers".</p>
<p>Also in both cases, the explanation isn't complete; it describes
without defining. For the median, the L1 norm has to be specified. For
monads, the monoid function has to be <code>join</code>. See also
<a href="https://stackoverflow.com/questions/3870088/a-monad-is-just-a-monoid-in-the-category-of-endofunctors-whats-the-problem">Crockett's explanation</a> and my <a href="/20150125-monads_by_diagram/">pictures</a> showing how <code>map</code> and
<code>join</code> give you <code>bind</code>.</p>
<p>I'm not giving a complete explanation here either. Read the book! It
has <a href="https://en.wikipedia.org/wiki/Zipper_(data_structure)">zippers</a> too!</p>
<hr>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<p>Forcing non-pure stuff into <code>do</code> blocks, as seems common in Haskell,
is very reminiscent of the <a href="https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell">functional core, imperative shell</a>
pattern.</p>
<hr>
<p>Haskell's pattern-matching (often instead of conditionals) is pretty
neat. Python is getting <a href="https://mathspp.com/blog/pydonts/pattern-matching-tutorial-for-pythonic-code">something analogous</a> in 3.10.</p>
<hr>
<p>Haskell's type inference gives behavior sort of like coercion in other
languages, but without the craziness. So <code>3 + 4.5</code> will work like
you'd expect, but there's no chance <code>'3' + 4.5</code> will turn out to be
<code>'34.5'</code> (which is what happens in JavaScript).</p>
<hr>
<p>Haskell has a funny quirk in some of its ranges:</p>
<pre><code>ghci&gt; [0.1, 0.3 .. 1]
[0.1,0.3,0.5,0.7,0.8999999999999999,1.0999999999999999]</code></pre>

<p>It's surprising that 1.1 is in there, when 1 was the upper bound. This
is because of a rule that if the value is within half the step size
(for floats and things like them) then it gets included in the result.
Wacky!</p>
<hr>
<blockquote>
<p>"<em>Sets and maps from <code>Data.Set</code> and <code>Data.map</code> are implemented using
trees, but instead of normal binary search trees, they use</em> balanced
<em>binary search trees.</em>" (page 135)</p>
</blockquote>
<p>Interesting! Usually these would be hash maps... Hmm! The closest
Haskell gets to a "normal" hash map (I think <a href="https://hackage.haskell.org/package/unordered-containers-0.2.13.0/docs/Data-HashMap-Strict.html">this</a>?) is implemented
with <a href="https://en.wikipedia.org/wiki/Hash_array_mapped_trie">hash array mapped tries</a>. Also good for persistence (meaning
re-using things in memory rather than creating everything from
scratch, because we don’t mutate). Fun!</p>
<hr>
<blockquote>
<p>"We can read the type of <code>putStrLn</code> like this: <code>putStrLn</code> takes a
string and returns an <em>I/O action</em> that has a result type of <code>()</code>
(that is, the empty tuple, also known as <em>unit</em>)." (page 155)</p>
</blockquote>
<p>The wiki for <a href="https://en.wikipedia.org/wiki/Unit_type">unit type</a> is helpful for understanding why it's
called that.</p>
<hr>
<p>On page 275, he defines a pipe operator with <code>x -: f = f x</code>. Pretty
neat!</p>
<hr>
<blockquote>
<p>"While similar to a normal list, a <em>difference list</em> is actually a
function that takes a list and prepends another list to it. For
example, the difference list equivalent of a list like <code>[1,2,3]</code> is
the function <code>\xs -&gt; [1,2,3] ++ xs</code>. A normal empty list is <code>[]</code>,
whereas an empty difference list is the function <code>\xs -&gt; [] ++ xs</code>."
(page 307)</p>
</blockquote>
<p>And so we get efficient appending to linked lists!</p>
<hr>
<blockquote>
<p>"the function monad is also called the <em>reader monad</em>." (page 312)</p>
</blockquote>
<hr>
<blockquote>
<p>"For instance, if we have <code>Just (Just 9)</code>, can we make that into
<code>Just 9</code>? It turns out that any nested monadic value can be
flattened and that this is actually a property unique to monads."
(page 326)</p>
</blockquote>
<p>This makes it sound fancier than it is, I think because the author
talks about <code>bind</code> more than <code>join</code> and doesn't talk about the
<a href="/20150125-monads_by_diagram/">relationship between them</a>.</p>
<hr>
<blockquote>
<p>"We don't usually set out to make a monad with the sole purpose of
making a monad. Rather, we make a type whose purpose is to model an
aspect of some problem, and then later on, if we see that the type
represents a value with a context and can act like a monad, we give
it a <code>Monad</code> instance." (page 336)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210411-learn_you_a_haskell_for_great_good_by_lipovaca/</link>
<guid>http://planspace.org/20210411-learn_you_a_haskell_for_great_good_by_lipovaca/</guid>
<pubDate>Sun, 11 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>How to Lie with Statistics, by Huff</title>
<description><![CDATA[

<p><a href="https://en.wikipedia.org/wiki/Darrell_Huff">Darrell Huff</a> and his <a href="https://en.wikipedia.org/wiki/How_to_Lie_with_Statistics">popular 1954 book</a> have <a href="/20210330-how_to_make_the_world_add_up_by_harford/">received</a>
criticism. Huff was wrong about cigarettes and cancer, but he did warn
us that people are biased. In 142 breezy pages, the book manages to
cover quite a lot, with perhaps moderate levels of prejudice for its
time.</p>
<p><img alt="cover" src="cover.jpg"></p>
<ul>
<li>Chapter 1: “The Sample with the Built-in Bias” (sampling)</li>
<li>Chapter 2: “The Well-Chosen Average” (mean vs. median)</li>
<li>Chapter 3: “The Little Figures That Are Not There” (variance etc.)</li>
<li>Chapter 4: “Much Ado about Practically Nothing” (small differences and measurement uncertainty)</li>
<li>Chapter 5: “The Gee-Whiz Graph” (funny y-axes)</li>
<li>Chapter 6: “The One-Dimensional Picture” (dimensional distortion of comparisons)</li>
<li>Chapter 7: “The Semiattached Figure” (non-sequitur logic)</li>
<li>Chapter 8: “Post Hoc Rides Again” (correlation ≠ causation)</li>
<li>Chapter 9: “How to Statistculate” (“statistically
   manipulate”—nonsense math)</li>
<li>Chapter 10: “How to Talk Back to a Statistic” (ask questions)<ul>
<li>“Who says so?”</li>
<li>“How does he know?”</li>
<li>“What’s missing?”</li>
<li>“Did somebody change the subject?”</li>
<li>“Does it make sense?”</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>"There are at least three levels of sampling involved. Dr. Kinsey's
samples of the population (one level) are far from random ones and
may not be particularly representative, but they are enormous
samples by comparison with anything done in his field before and his
figures must be accepted as revealing and important if not
necessarily on the nose. It is possibly more important to remember
that any questionnaire is only a sample (another level) of the
possible questions and that the answer the lady gives is no more
than a sample (third level) of her attitudes and experiences on each
question." (page 23)</p>
</blockquote>
<hr>
<blockquote>
<p>"Some of the strongest feeling against public-opinion polls is found
in liberal or left-wing circles, where it is rather commonly
believed that polls are generally rigged. Behind this view is the
fact that poll results so often fail to square with the opinions and
desires of those whose thinking is not in the conservative
direction. Polls, they point out, seem to elect Republicans even
when voters shortly thereafter do otherwise." (page 26)</p>
</blockquote>
<p>Interesting historical perspective; modern concerns about polls are
not necessarily new issues.</p>
<hr>
<blockquote>
<p>"You will also learn if you read back into the tables that the
figure is based on a sample of such size that there are nineteen
chances out of twenty that the estimate—$3,107 before it was
rounded—is correct within a margin of $59 plus or minus." (pages
35-36)</p>
</blockquote>
<p>I don’t know a confidence interval technique that will give you quite
that interpretation; this could be erroneous.</p>
<hr>
<p>"Degree of significance" (p-value) is presented on page 42 as a thing
that is usually hidden from the public, which may have been (and may
still often be) the case. These days I hear more about problems with
significance tests than demands for them.</p>
<hr>
<blockquote>
<p>"It is dangerous to mention any subject having high emotional
content without hastily saying where you are for or agin it." (page
46, amusing spelling in original)</p>
</blockquote>
<hr>
<blockquote>
<p>"The <a href="https://en.wikipedia.org/wiki/Procrustes">Procrustean</a> Statistic" (graphic page 43)</p>
</blockquote>
<hr>
<blockquote>
<p>"In somewhat the same fashion those little figures
[reporting variance] that are missing from what are called
“Gessell’s norms” have produced pain in papas and mamas. Let a
parent read, as many have done in such places as Sunday rotogravure
sections, that “a child” learns to sit erect at the age of so many
months and he thinks at once of his own child. Let his child fail to
sit by the specified age and the parent must conclude that his
offspring is “retarded” or “subnormal” or something equally
invidious. Since half the children are bound to fail to sit by the
time mentioned, a good many parents are made unhappy. Of course,
speaking mathematically, this happiness is balanced by the joy of
the other fifty per cent of parents in discovering that their
children are “advanced.” But harm can come of the efforts of the
unhappy parents to force their children to conform to the norms and
thus be backward no longer." (pages 44-45)</p>
</blockquote>
<hr>
<blockquote>
<p>"<em>Newsweek</em> once showed how “U. S. Old Folks Grow Older” by means of
a chart on which appeared two male figures, one representing the
68.2-year life expectancy of today, the other the 34-year life
expectancy of 1879-1889.'"</p>
</blockquote>
<p>Here Huff is complaining that the person twice as tall appears 8 times
as massive, but there are other issues with interpreting
<a href="/20200806-life_expectancy_is_historically_misleading/">historical life expectancy</a>...</p>
<hr>
<blockquote>
<p>"Who knows what germ causes colds, particularly since it probably
isn’t a germ at all?" (page 75)</p>
</blockquote>
<p>What does he think causes colds? They knew about viruses in the 50s,
didn’t they?</p>
<hr>
<blockquote>
<p>"Let us say that during a period in which race prejudice is growing
you are employed to “prove” otherwise. It is not a difficult
assignment. Set up a poll or, better yet, have the polling done for
you by an organization of good reputation. Ask that usual cross
section of the population if they think blacks have as good a chance
as white people to get jobs. Repeat your polling at intervals so
that you will have a trend to report.</p>
<p>"Princeton’s Office of Public Opinion Research tested this question
once. What turned up is interesting that things, especially in
opinion polls, are not always what they seem. Each person who was
asked the question about jobs was also asked some questions designed
to discover if he was strongly prejudiced against blacks. It turned
out that people most strongly prejudiced were most likely to answer
Yes to the question about job opportunities. (It worked out that
about two-thirds of those who were sympathetic toward blacks did not
think the black had as good a chance at a job as a white person did,
and about two-thirds of those showing prejudice said that blacks
were getting as good breaks as whites.) It was pretty evident that
from this poll you would learn very little about employment
conditions for blacks, although you might learn some interesting
things about a man’s racial attitudes." (pages 75-76)</p>
</blockquote>
<p>A couple striking dehumanizing "blacks" vs. "white people" phrasings
here. The reportage of veiled (?) racism in survey responses still
seems relevant today.</p>
<hr>
<blockquote>
<p>"A civilian population includes infants, the old, and the ill, all
of whom have a higher death rate wherever they are." (page 85)</p>
</blockquote>
<p>It’s incidental to the point of the text here, but it’s interesting to
see a reference to infants having a high death rate. I think this
sounds out of place, today. When Huff was born in 1913, something like
ten percent of babies died before age five.
(<a href="/20200806-life_expectancy_is_historically_misleading/">historical life expectancy</a>)</p>
<hr>
<blockquote>
<p>"Keep in mind that a correlation may be real and based on real cause
and effect—and still be almost worthless in determining action in
any single case." (page 93)</p>
</blockquote>
<p>I read this as pointing to variability. Was he already thinking about
smoking?</p>
<hr>
<blockquote>
<p>"But arbitrarily rejecting statistical methods makes no sense
either. That is like refusing to read because writers sometimes use
words to hide facts and relationships rather than to reveal them."
(page 121)</p>
</blockquote>
<hr>
<blockquote>
<p>"I’ll face up to the serious purpose that I like to think lurks just
beneath the surface of this book: explaining how to look a phony
statistic in the eye and face it down; and no less important, how to
recognize sound and usable data in that wilderness of fraud to which
the previous chapters have been largely devoted." (page 122)</p>
</blockquote>
<hr>
<blockquote>
<p>"You may be familiar with the Rudolf Flesch readability formula. It
purports to measure how easy a piece of prose is to read, by such
simple and objective items as length of words and sentences. Like
all devices for reducing the imponderable to a number and
substituting arithmetic for judgment, it is an appealing idea."
(page 137)</p>
</blockquote>
<p>I’m interested in the <a href="https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests">readability stuff</a>, but it also strikes me
that the last sentence there is quite a good joke:</p>
<blockquote>
<p>"Like all devices for reducing the imponderable to a number and
substituting arithmetic for judgment, it is an appealing idea."</p>
</blockquote>
<p>That could be an epigraph!</p>    
    ]]></description>
<link>http://planspace.org/20210405-how_to_lie_with_statistics_by_huff/</link>
<guid>http://planspace.org/20210405-how_to_lie_with_statistics_by_huff/</guid>
<pubDate>Mon, 05 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Trekonomics, by Saadia</title>
<description><![CDATA[

<p>This is the <a href="https://en.wikipedia.org/wiki/Trekonomics">best book</a> on Star Trek economics that I've read
(sorry, <a href="/20201109-economics_of_star_trek_by_webb/" title="The Economics of Star Trek, by Webb">Webb</a>). Personal, erudite, and optimistic, <a href="https://www.inkshares.com/books/trekonomics">it</a> suggests
that post-scarcity has started, and that while there's still a long
way to go, we can work merrily to advance farther.</p>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"It is almost a paradox to state it this way, but in a society where
nothing is scarce and consequently where work is no longer a
prerequisite for survival, finding good reasons to work becomes
paramount, the defining existential question that everyone has to
ask themselves." (pages 44-45)</p>
</blockquote>
<hr>
<blockquote>
<p>"For those who can't swing it, the imperative to build a meaningful
life through work becomes a source of unbearable anxiety." (page 58)</p>
</blockquote>
<hr>
<p>The <a href="https://en.wikipedia.org/wiki/RepRap_project">RepRap project</a> to make a 3D printer that can print copies of
itself is pretty neat!</p>
<hr>
<blockquote>
<p>"As with most open-source projects, what is learned and invented
along the way is as valuable as the stated goal." (page 79)</p>
</blockquote>
<hr>
<p><a href="https://en.wikipedia.org/wiki/CFM_International_LEAP">LEAP</a> stands for "Leading Edge Aviation Propulsion."</p>
<hr>
<p>On page 86 he mentions "Pareto improvement" which refers to a change
that helps something and hurts nothing else, which is a neat idea from
<a href="https://en.wikipedia.org/wiki/Pareto_efficiency">Pareto efficiency</a> (not to be confused with the
<a href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto principle</a>). I think a <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">ROC curve</a> should represent a
Pareto frontier...</p>
<hr>
<blockquote>
<p>"Empirical data suggests that given enough time, all rival goods are
either substituted or become nonrival." (page 100)</p>
</blockquote>
<hr>
<p>The emphasis on reputation as a motivator is interesting. Thinking of
modern social media, which is a kind of focus on reputation, it seems
like a system with risks. It matters whose opinion you value. If you
spend all your time on public reputation management and none on quiet
work, for example, reputation may be a distraction rather than a
focusing agent.</p>
<hr>
<p>There's some fairly naive exponential extrapolation of economic
productivity to the 24th century... Seems like some discussion of
exponential vs. sigmoid might be appropriate...</p>
<hr>
<blockquote>
<p>"Our culture hungers for the cheap thrills of apocalypse." (page
106)</p>
</blockquote>
<hr>
<blockquote>
<p>"News of our imminent demise has been greatly exaggerated." (page
107)</p>
</blockquote>
<hr>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Elinor_Ostrom">Elinor Ostrom</a>, <em>Governing the Commons: The Evolution of
Institutions for Collective Action</em> (Cambridge: Cambridge University
Press, 1990), p. 183. It is hands-down one of the most important
books of the past fifty years."</p>
</blockquote>
<hr>
<blockquote>
<p>"Without rules or regulations, be they self-imposed or enforced by
an external intrumentality (an agency or a government),
overconsumption is almost always guaranteed. Such rules and
regulations are extremely hard to devise, and enforcement is very
complex." (page 121)</p>
</blockquote>
<hr>
<blockquote>
<p>"Thanks to science and political activism, we mustered the power to
ban lead in domestic products. However, the public health
consequences and the costs borne by society were enormous (including
but not limited to widespread disruption of prefrontal cortex
development in children, leading to significant increases in violent
crime). We let oil and car companies free ride on the back of
society. It would have taken much longer to ban lead had it not been
for the heroic work of Caltech geochemist <a href="https://en.wikipedia.org/wiki/Clair_Cameron_Patterson">Clair Patterson</a>."
(page 122)</p>
</blockquote>
<hr>
<blockquote>
<p>"Free riding takes place at a myriad of points in the overall
system, from individuals to corporations to states. Many private
economic actors routinely engage in various forms of legal and
illegal tax evasion, weakening the very same public institutions
that help and guarantee their business. This is free riding, but on
government. The usual self-servicing argument that everybody does it
anyway does not make the practice any less craven or repellent. The
managers and stockholders of these multinational corporations are
perfectly aware that they are breaching the contract between their
companies and society as a whole. Basically, they behave no better
than Third World dictators who stuff stolen cash in Swiss vaults.
Only a residual sense of guilt about the extent of their free riding
makes them publicize their paltry philanthropic efforts and their
so-called corporate-citizenship initiatives. They operate with the
dread of getting caught, and thus aggressively support political
parties, economists, and opinion makers who agitate against taxes
out of naive philosophical principles. The perverse result is that
all too often and in too many countries, the party of the free
market, which in truth should defend open society, progress, and
civic spirit, ends up as the party of tax evasion, monopoly, and
free riding." (page 124)</p>
</blockquote>
<hr>
<p>Saadia recommends <a href="https://en.wikipedia.org/wiki/Stalker_(1979_film)">Stalker</a>, which is based on <a href="https://en.wikipedia.org/wiki/Roadside_Picnic">Roadside Picnic</a>.</p>
<hr>
<blockquote>
<p>"<a href="https://en.wikipedia.org/wiki/The_Dispossessed"><em>The Dispossessed</em></a> specifically makes the case that
post-scarcity is not so much a matter of material wealth or natural
bounty, but an organizational option for society." (page 143)</p>
</blockquote>
<hr>
<blockquote>
<p>"By the time <em>Next Generation</em> rolls around, the conflict between
the messy present and the aspirational future has been resolved.
Stoicism has won. The <em>Enterprise</em>'s new crew is all Spock and no
Kirk." (page 172)</p>
</blockquote>
<hr>
<p>Keynes' 1930 <a href="https://www.aspeninstitute.org/wp-content/uploads/files/content/upload/Intro_and_Section_I.pdf">Economic Possibilities for our Grandchildren</a></p>
<hr>
<blockquote>
<p>"Even more pointedly, if we take a step back from Hollywood's
romance of space travel, with its gizmos and its aliens, we may soon
come to the rather disquieting realization that we <em>already</em> live in
Keynes's, and therefore <em>Star Trek</em>'s, cornucopia. Economic bliss is
just very unevenly distributed, to paraphrase science-fiction author
William Gibson." (page 211)</p>
</blockquote>
<hr>
<blockquote>
<p>"If you believe that <em>Star Trek</em> is about space travel, you are
taking it too literally." (page 215)</p>
</blockquote>
<hr>
<blockquote>
<p>"We are an incredibly sedentary species." (page 216)</p>
</blockquote>
<hr>
<p><a href="https://en.wikipedia.org/wiki/Alcubierre_drive">Alcubierre drive</a> is a specific kind of warp drive.</p>
<hr>
<p><a href="https://www.researchgate.net/publication/286996693_Economics_and_the_Fermi_paradox">Economics and the Fermi paradox</a>: Maybe it's just not worth it to
go to space.</p>
<hr>
<p><a href="https://mason.gmu.edu/~rhanson/dreamautarky.html">Dreams of Autarky</a>: Doux commerce for everything.</p>
<hr>
<blockquote>
<p>"In a world where work is no longer compulsary, it must become truly
meaningful." (page 223)</p>
</blockquote>
<hr>
<blockquote>
<p>"The zero-marginal cost society, as economist and essayist Jeremy
Rifkin calls it, is an everyday, practical reality." (page 230)</p>
</blockquote>
<hr>
<blockquote>
<p>"While nominally the subject of monetary transactions, everything
that matters is as good as free to many of us. When allocation
decisions consist in choosing between your new iPhone
storage-capacity options or the trim of the car, then you know you
have whittled down your ninety-nine problems to the last few
marginal ones. For all intents and purposes, and save for a few
minor imperfections, the global economy already acts as one massive
replicator." (page 232)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210401-trekonomics_by_saadia/</link>
<guid>http://planspace.org/20210401-trekonomics_by_saadia/</guid>
<pubDate>Thu, 01 Apr 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Software Engineering at Google</title>
<description><![CDATA[

<p>I read <a href="https://www.oreilly.com/library/view/software-engineering-at/9781492082781/">this</a> over half a year with a book club of colleagues at
work, one chapter per week, which is part of why I have such a lot of
notes below. Interesting stuff! Even when it isn't perfectly
applicable to my own work, it's neat to peek a little bit inside the
giant company.</p>
<p><img alt="cover" src="cover.jpg"></p>
<ol>
<li><a href="#ch1">What is Software Engineering?</a></li>
<li><a href="#ch2">How to Work Well on Teams</a></li>
<li><a href="#ch3">Knowledge Sharing</a></li>
<li><a href="#ch4">Engineering for Equity</a></li>
<li><a href="#ch5">How to Lead a Team</a></li>
<li><a href="#ch6">Leading at Scale</a></li>
<li><a href="#ch7">Measuring Engineering Productivity</a></li>
<li><a href="#ch8">Style Guides and Rules</a></li>
<li><a href="#ch9">Code Review</a></li>
<li><a href="#ch10">Documentation</a></li>
<li><a href="#ch11">Testing Overview</a></li>
<li><a href="#ch12">Unit Testing</a></li>
<li><a href="#ch13">Test Doubles</a></li>
<li><a href="#ch14">Larger Testing</a></li>
<li><a href="#ch15">Deprecation</a></li>
<li><a href="#ch16">Version Control and Branch Management</a></li>
<li><a href="#ch17">Code Search</a></li>
<li><a href="#ch18">Build Systems and Build Philosophy</a></li>
<li><a href="#ch19">Critique: Google's Code Review Tool</a></li>
<li><a href="#ch20">Static Analysis</a></li>
<li><a href="#ch21">Dependency Management</a></li>
<li><a href="#ch22">Large-Scale Changes</a></li>
<li><a href="#ch23">Continuous Integration</a></li>
<li><a href="#ch24">Continuous Delivery</a></li>
<li><a href="#ch25">Compute as a Service</a></li>
</ol>
<hr>
<h3>Chapter 1: <a href="#ch1" name="ch1">What is Software Engineering?</a></h3>
<hr>
<blockquote>
<p>"It's <em>programming</em> if 'clever' is a compliment, but it's <em>software
engineering</em> if 'clever' is an accusation." (page 10)</p>
</blockquote>
<p>A colleague notes: "I don’t even think clever in programming should be
a compliment most times. Elegance deserves a compliment, though."</p>
<hr>
<blockquote>
<p>"... the goal is consensus, not unanimity." (page 18)</p>
</blockquote>
<p>I haven't thought about it much before, but if consensus isn't
unanimity, it's hard to define.</p>
<hr>
<blockquote>
<p>"Efficiency gains from keeping engineers happy, focused, and engaged
can easily dominate other factors, simply because focus and
productivity are so variable, and a 10-to-20% difference is easy to
imagine." (pages 18-19)</p>
</blockquote>
<hr>
<blockquote>
<p>"We often say, "Google is a data-driven culture." In fact, that's a
simplification: even when there isn't <em>data</em>, there might still be
<em>evidence</em>, <em>precedent</em>, and <em>argument</em>." (page 19)</p>
</blockquote>
<p>Also, page 24 adds "<em>assumption</em>."</p>
<hr>
<p>Discussion of whether to use an existing thing, fork it to modify it,
or build your own, on page 22...</p>
<hr>
<h3>Chapter 2: <a href="#ch2" name="ch2">How to Work Well on Teams</a></h3>
<p>This chapter is largely a short version of <a href="/20151118-debugging_teams/">Debugging Teams</a> by the
same author, which is very welcome.</p>
<hr>
<blockquote>
<p>"Many humans have the instinct to find and worship idols." (page 28)</p>
</blockquote>
<hr>
<blockquote>
<p>"The Genius Myth is the tendency that we as humans need to ascribe
the success of a team to a single person/leader." (page 28)</p>
</blockquote>
<hr>
<blockquote>
<p>"The vast majority of the work at Google (and at most companies!)
doesn't require genius-level intellect, but 100% of the work
requires a minimal level of social skills." (page 29)</p>
</blockquote>
<hr>
<blockquote>
<p>"Hopefully most engineers recognize that it is better to be one part
of a successful project than the critical part of a failed project."
(page 31)</p>
</blockquote>
<hr>
<blockquote>
<p>"We think the middle ground
[between individual offices and open floor plans] is really the best
solution. Group teams of four to eight people together in small
rooms (or large offices) to make it easy (and non-embarrassing) for
spontaneous conversation to happen." (page 33)</p>
</blockquote>
<p>This is similar to advice in <a href="/20200523-peopleware_productive_projects_and_teams/">Peopleware</a>.</p>
<hr>
<blockquote>
<p>"If less-knowledgeable [or, really, any] people on your team feel
that there's a barrier to asking you a question, it's a problem:
finding the right balance is an art." (page 33)</p>
</blockquote>
<hr>
<h3>Chapter 3: <a href="#ch3" name="ch3">Knowledge Sharing</a></h3>
<hr>
<p>The problem of "all-or-nothing expertise" (page 44)</p>
<hr>
<blockquote>
<p>"Tribal and written knowledge complement each other." (page 46)</p>
</blockquote>
<hr>
<p>They reference <a href="https://rework.withgoogle.com/blog/five-keys-to-a-successful-google-team/">The five keys to a successful Google team
</a>, which are:</p>
<ul>
<li>Psychological safety: Can we take risks on this team without
   feeling insecure or embarrassed?</li>
<li>Dependability: Can we count on each other to do high quality work
   on time?</li>
<li>Structure &amp; clarity: Are goals, roles, and execution plans on our
   team clear?</li>
<li>Meaning of work: Are we working on something that is personally
   important for each of us?</li>
<li>Impact of work: Do we fundamentally believe that the work we’re
   doing matters?</li>
</ul>
<hr>
<blockquote>
<p>"... Moma, Google's intranet search engine." (page 51)</p>
</blockquote>
<hr>
<blockquote>
<p>"YAQS ("Yet Another Question System") is a Google-internal version
of a Stack Overflow-like website" (page 52)</p>
</blockquote>
<p>a Google-internal version of a Stack Overflow-like website</p>
<hr>
<p>g3doc is pretty neat. Described more in: <a href="https://www.usenix.org/conference/srecon16europe/program/presentation/macnamara">The Knowledge: Towards a Culture of Engineering Documentation</a></p>
<hr>
<p>https://codelabs.developers.google.com/</p>
<hr>
<p>This stuff on readability is interesting, since the Google meaning of
readability is not the same as the usual meaning of readability. It
helps me better understand such <a href="https://tilde.news/s/zghf2x/what_are_all_jeff_dean_facts">Jeff Dean facts</a> as:</p>
<ul>
<li>"Jeff Dean once bit a spider, the spider got super powers and C++
   readability."</li>
<li>"Jeff Dean has punch card readability."</li>
<li>"Jeff Dean has binary readability."</li>
<li>"Jeff Dean acquired Sawzall readability after writing 58 lines of
   Sawzall code. As part of his readability review, he pointed out a
   flaw in the style guide which was promptly corrected by the
   reviewer."</li>
<li>"Jeff got Java readability with only 8 lines of code."</li>
<li>"Jeff Dean has Perl Readability. (TRUE)"</li>
</ul>
<hr>
<p>Engelbart's <a href="https://www.dougengelbart.org/content/view/115/000/">Bootstrapping Organizations Into the 21st Century</a> is
largely about knowledge sharing.</p>
<hr>
<h3>Chapter 4: <a href="#ch4" name="ch4">Engineering for Equity</a></h3>
<hr>
<p>In discussing "technology to scan, capture, and identify people
walking down the street" (page 73) it kind of highlights how fraught
discussions of ethics are: Is the problem "racial variance in facial
recognition" or is the problem doing facial recognition <em>at all</em>?</p>
<hr>
<blockquote>
<p>"Google now offers statistical training within the context of AI to
help ensure that datasets are not intrinsically biased." (page 74)</p>
</blockquote>
<p>I asked for more info: https://twitter.com/planarrowspace/status/1317130678643941379</p>
<hr>
<blockquote>
<p>"Ratings, although an important way to measure performance during a
specific period, are not predictive of future performance and should
not be used to gauge readiness for a future role or qualify an
internal candidate for a different team." (page 77)</p>
</blockquote>
<hr>
<h3>Chapter 5: <a href="#ch5" name="ch5">How to Lead a Team</a></h3>
<hr>
<blockquote>
<p>"A <em>Manager</em> is a leader of people, whereas a <em>Tech Lead</em> leads
technology efforts." (page 81)</p>
</blockquote>
<p>Both of these (and the <em>Tech Lead Manager</em>, when one person does both
roles) seem to be tied to a team (in contrast to "matrix" style).</p>
<hr>
<blockquote>
<p>"Most TLs are also individual contributors, which often forces them
to choose between doing something quickly themselves or delegating
it to a team member to do (sometimes) more slowly." (page 82)</p>
</blockquote>
<hr>
<p><a href="https://takeout.google.com/">Google Takeout</a> is a public-facing tool
(also?) now. (page 83)</p>
<hr>
<blockquote>
<p>"Before the computing age, "management" and "labor" might have taken
on almost antagonistic roles, with the manager wielding all of the
power and labor requiring collective action to achieve its own ends.
But that isn't how modern software companies work." (page 86)</p>
</blockquote>
<p>This seems... incomplete.</p>
<hr>
<blockquote>
<p>"Traditional managers worry about how to get things done, whereas
great managers worry about what things get done (and trust their
team to figure out how to do it)." (page 87)</p>
</blockquote>
<hr>
<blockquote>
<p>"If your employees are so uninterested in their job that they
actually need traditional-manager babysitting to be convinced to
work, <em>that</em> is your real problem."</p>
</blockquote>
<hr>
<blockquote>
<p>"[with low performers] It almost always requires temporary
micromanagement, ..." (page 90)</p>
</blockquote>
<hr>
<p>On page 95, the emphasis on asking questions (rather than giving
direct advice, etc.) is a good reminder.</p>
<hr>
<h3>Chapter 6: <a href="#ch6" name="ch6">Leading at Scale</a></h3>
<hr>
<ul>
<li>Always Be Deciding<ul>
<li>Identify blinders</li>
<li>Identify trade-offs</li>
<li>Decide</li>
</ul>
</li>
<li>Always Be Leaving<ul>
<li>Build a "self-driving" team</li>
</ul>
</li>
<li>Always Be Scaling<ul>
<li>Important versus urgent</li>
<li>Learn to drop balls</li>
<li>Protecting your energy</li>
</ul>
</li>
</ul>
<hr>
<blockquote>
<p>"... if you agree that your mission is to build a self-driving
organization, the main mechanism of teaching is through delegation."
(page 113)</p>
</blockquote>
<hr>
<blockquote>
<p>"You give them an assignment, let them fail, and then try again and
again." (page 113)</p>
</blockquote>
<hr>
<blockquote>
<p>"One technique for fighting the feeling that you don't know what
you're doing is to simply pretend that <em>some</em> expert out there knows
exactly what to do, and that they're simply on vacation and you're
temporarily subbing in for them. It's a great way to remove the
personal stakes and give yourself permission to fail and learn."
(page 116)</p>
</blockquote>
<hr>
<blockquote>
<p>"... over time, as you grow older, your overall stamina builds up.
Early in your career, working eight hours a day in an office can
feel like a shock; you come home tired and dazed. But just like
training for a marathon, your brain and body build up larger
reserves of stamina over time." (page 120)</p>
</blockquote>
<hr>
<blockquote>
<p>"Your brain operates in natural 90-minute cycles." (page 121)</p>
</blockquote>
<p>They reference <a href="https://en.wikipedia.org/wiki/Basic_rest%E2%80%93activity_cycle">BRAC</a> (Basic Rest-Activity Cycle)... I'm not sure
how much formal research evidence there really is, but I'm still down
with taking breaks every once in a while.</p>
<hr>
<h3>Chapter 7: <a href="#ch7" name="ch7">Measuring Engineering Productivity</a></h3>
<hr>
<p>The "Triage: Is It Even Worth Measuring?" section starting page 125
reminds me of <a href="https://en.wikipedia.org/wiki/Cassie_Kozyrkov">Cassie Kozyrkov</a>'s "decision science" stuff, focusing
on statistics for decision-making.</p>
<hr>
<p>On page 127 they imagine "there's a major funding deadline
approaching" which makes me wonder what this means inside Google. How
is funding determined?</p>
<hr>
<p>On page 129 they start talking about Goals/Signals/Metrics (GSM). They
identify QUANTS categories (Quality of the code, Attention from
engineers, Intellectual complexity, Tempo and velocity, Satisfaction).
It seems like this is related to the <a href="https://www.productplan.com/glossary/heart-framework/">HEART framework</a> (Happiness,
Engagement, Adoption, Retention, Task success) which also uses GSM.</p>
<hr>
<p>Page 129 also references Dijkstra's
<a href="https://www.cs.utexas.edu/users/EWD/transcriptions/EWD10xx/EWD1036.html">On the cruelty of really teaching computing science</a> in a footnote.</p>
<hr>
<blockquote>
<p>"Although academic literature has proposed many proxies for code
quality, none of them have truly captured it. For readability, we
had a decision of either using a poor proxy and possibly making a
decision based on it, or simply acknowledging that this is a point
that cannot currently be measured. Ultimately, we decided not to
capture this as a quantitative measure, though we did ask engineers
to self-rate their code quality." (page 133)</p>
</blockquote>
<hr>
<blockquote>
<p>"It has routinely been our experience at Google that when the
quantitative and qualitative metrics disagree, it was because the
quantitative metrics were not capturing the expected result." (page
133)</p>
</blockquote>
<hr>
<blockquote>
<p>"There is a temptation to use such metrics to evaluate individual
engineers, or perhaps even to identify high and low performers.
Doing so would be counterproductive, though. If productivity metrics
are used for performance reviews, engineers will be quick to game
the metrics, and they will no longer be useful for measuring and
improving productivity across the organization. The only way to make
these measurements work is to let go of the idea of measuring
individuals and embrace measuring the aggregate effect." (page 134)</p>
</blockquote>
<hr>
<blockquote>
<p>"Qualitative metrics should also align with the quantitative
metrics; if they do not, it is likely the quantitative metrics that
are incorrect." (page 138)</p>
</blockquote>
<hr>
<h3>Chapter 8: <a href="#ch8" name="ch8">Style Guides and Rules</a></h3>
<hr>
<blockquote>
<p>"... our C++ rules disallow use of exceptions, a language feature
widely used outside of Google code." (page 142)</p>
</blockquote>
<hr>
<blockquote>
<p>"SREs, library engineers, and code janitors" (page 147)</p>
</blockquote>
<p>I didn't know Google used the term "code janitor"... I found at least
one <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37755.pdf">ref</a> that also uses "janitors."</p>
<hr>
<p>Page 149 mentions <a href="https://github.com/bazelbuild/starlark">Starlark</a>, which I don't think I'd heard of
before.</p>
<hr>
<blockquote>
<p>"We place higher value on simplified, straightforward code that is
easier to understand and maintain." (page 150)</p>
</blockquote>
<hr>
<blockquote>
<p>"... multiple inheritance, something explicitly forbidden for all
other C++ code." (page 151)</p>
</blockquote>
<hr>
<p>I used to like the NumPy comment guidelines, but these days I prefer
the Google <a href="https://google.github.io/styleguide/pyguide#38-comments-and-docstrings">ones</a> mentioned on page 152.</p>
<hr>
<p>I hadn't realized that Google had their own Python autoformatter, as
mentioned on page 161. Seems like <a href="https://github.com/google/yapf">yapf</a> is very similar to
<a href="https://github.com/psf/black">black</a>.</p>
<hr>
<h3>Chapter 9: <a href="#ch9" name="ch9">Code Review</a></h3>
<hr>
<blockquote>
<p>“At Google, reviewers may even directly share suggested edits with
an author within the code review tool itself.” (page 503)</p>
</blockquote>
<p>GitLab does this, but only for single-line changes, as far as I
know...</p>
<hr>
<blockquote>
<p>“After you check that piece of code into the codebase, it is no
longer yours in any case.” (page 507)</p>
</blockquote>
<hr>
<blockquote>
<p>“Probably the most important practice to keep the code review
process nimble is to keep changes small.” (page 509)</p>
</blockquote>
<hr>
<blockquote>
<p>“A change description should indicate its type of change on the
first line, as a summary. The first line is prime real estate and is
used to provide summaries within the code review tool itself, to act
as the subject line in any associated emails, and to become the
visible line Google engineers see in a history summary within Code
Search (see Chapter 17), so that first line is important.” (page
512)</p>
</blockquote>
<hr>
<blockquote>
<p>"Keep Reviewers to a Minimum" (page 514)</p>
</blockquote>
<hr>
<h3>Chapter 10: <a href="#ch10" name="ch10">Documentation</a></h3>
<hr>
<blockquote>
<p>“At Google, our most successful efforts have been when documentation
is treated like code and incorporated into the traditional
engineering workflow, making it easier for engineers to write and
maintain simple documents.” (page 530)</p>
</blockquote>
<hr>
<blockquote>
<p>“When we deprecated GooWiki, we found that around 90% of the
documents had no views or updates in the previous few months.” (page
593)</p>
</blockquote>
<p>And they focus a lot on staleness etc. being connected to <em>ownership</em>.</p>
<hr>
<blockquote>
<p>“...one thing we’ve found is that it helps to keep your documents
<em>short</em>.” (page 548)</p>
</blockquote>
<hr>
<blockquote>
<p>“Most teams at Google require an approved design document before
starting work on any major project. A software engineer typically
writes the proposed design document using a specific design doc
template approved by the team. Such documents are designed to be
collaborative, so they are often shared in Google Docs, which has
good collaboration tools. Some teams require such design documents
to be discussed and debated at specific team meetings, where the
finer points of the design can be discussed or critiqued by experts.
In some respects, these design discussions act as a form of code
review before any code is written.” (page 560)</p>
</blockquote>
<hr>
<blockquote>
<p>“If comments are the unit tests of documentation, conceptual
documents are the integration tests.” (page 568)</p>
</blockquote>
<hr>
<blockquote>
<p>“At Google, we often attach “freshness dates” to documentation. Such
documents note the last time a document was reviewed, and metadata
in the documentation set will send email reminders when the document
hasn’t been touched in, for example, three months. Such freshness
dates, as shown in the following example—and tracking your documents
as bugs—can help make a documentation set easier to maintain over
time, which is the main concern for a document” (page 585)</p>
</blockquote>
<hr>
<blockquote>
<p>“If you can’t explain it and can’t define it, you probably haven’t designed it well enough.” (page 187)</p>
</blockquote>
<hr>
<h3>Chapter 11: <a href="#ch11" name="ch11">Testing Overview</a></h3>
<hr>
<blockquote>
<p>“The more and faster you want to change your systems, the more you
need a fast way to test them. The act of writing tests also improves
the design of your systems.” (page 594)</p>
</blockquote>
<hr>
<ul>
<li>write tests</li>
<li>run tests</li>
<li>react when tests fail</li>
</ul>
<hr>
<p>Benefits:</p>
<ul>
<li>less debugging</li>
<li>increased confidence in changes</li>
<li>improved documentation</li>
<li>simpler reviews</li>
<li>thoughtful design</li>
<li>fast, high-quality releases</li>
</ul>
<hr>
<blockquote>
<p>“We have come to the conclusion that there are two distinct
dimensions for every test case: size and scope. Size refers to the
resources that are required to run a test case: things like memory,
processes, and time. Scope refers to the specific code paths we are
verifying.”</p>
</blockquote>
<hr>
<blockquote>
<p>“in brief, <em>small</em> tests run in a single process, <em>medium</em> tests run
on a single machine, and <em>large</em> tests run wherever they want”</p>
</blockquote>
<hr>
<p>The <a href="https://testing.googleblog.com/">Google Testing Blog</a> includes their "testing on the toilet"
one-pagers.</p>
<hr>
<blockquote>
<p>“Code coverage can provide some insight into untested code, but it
is not a substitute for thinking critically about how well your
system is tested.”</p>
</blockquote>
<hr>
<ul>
<li>Orientation classes</li>
<li>Test certified</li>
<li>Testing on the toilet</li>
</ul>
<hr>
<p>pH: Project Health</p>
<hr>
<h3>Chapter 12: <a href="#ch12" name="ch12">Unit Testing</a></h3>
<hr>
<blockquote>
<p>“Because they make up such a big part of engineers’ lives, Google
puts a lot of focus on <em>test maintainability</em>. Maintainable tests
are ones that “just work”: after writing them, engineers don’t need
to think about them again until they fail, and those failures
indicate real bugs with clear causes. The bulk of this chapter
focuses on exploring the idea of maintainability and techniques for
achieving it.”</p>
</blockquote>
<hr>
<blockquote>
<p>“a brittle test is one that fails in the face of an unrelated change
to production code that does not introduce any real bugs”</p>
</blockquote>
<hr>
<blockquote>
<p>"Strive for Unchanging Tests"</p>
</blockquote>
<hr>
<blockquote>
<p>"Test via Public APIs"</p>
</blockquote>
<p>Or: <a href="http://xunitpatterns.com/Principles%20of%20Test%20Automation.html#Use%20the%20Front%20Door%20First">Use the front door first</a></p>
<hr>
<blockquote>
<p>"Test State, Not Interactions"</p>
</blockquote>
<p>That is, test the <em>result</em>, not <em>how</em> it's achieved.</p>
<hr>
<blockquote>
<p>"Make Your Tests Complete and Concise"</p>
</blockquote>
<hr>
<p>"given, when, then" or "arrange, act, assert"</p>
<hr>
<blockquote>
<p>"Don't Put Logic in Tests"</p>
</blockquote>
<hr>
<blockquote>
<p>“The lesson is clear: in test code, stick to straight-line code over
clever logic, and consider tolerating some duplication when it makes
the test more descriptive and meaningful.”</p>
</blockquote>
<hr>
<p>DAMP (Descriptive and Meaningful Phrases) rather than pure DRY (Don't
Repeat Yourself)</p>
<hr>
<blockquote>
<p>“test infrastructure must always have its own tests.”</p>
</blockquote>
<hr>
<h3>Chapter 13: <a href="#ch13" name="ch13">Test Doubles</a></h3>
<hr>
<p>The tl;dr on page 280 is a pretty good summary:</p>
<blockquote>
<ul>
<li>A real implementation should be preferred over a test double.</li>
<li>A fake is often the ideal solution if a real implementation can't
  be used in a test.</li>
<li>Overuse of stubbing leads to tests that are unclear and brittle.</li>
<li>Interaction testing should be avoided when possible: it leads to
  tests that are brittle because it exposes implementation details
  of the system under test.</li>
</ul>
</blockquote>
<hr>
<blockquote>
<p>"[Tests using mocking frameworks] required constant effort to
maintain while rarely finding bugs." (page 259)</p>
</blockquote>
<hr>
<p>They talk about dependency injection, which I think is generally a
good idea, especially if you can separate in the style of "functional
shell, imperative core" so that you're testing mostly pure functions.</p>
<p>I hadn't known about "automated dependency injection frameworks" -
maybe they're neat?</p>
<ul>
<li>https://github.com/google/guice</li>
<li>https://github.com/google/dagger</li>
</ul>
<p>Are there any for Python? At least one:</p>
<ul>
<li>https://python-dependency-injector.ets-labs.org/</li>
</ul>
<p>I'm not sure I want to use it... It seems mostly for very
object-oriented designs, though I could be wrong.</p>
<p>The book also says:</p>
<blockquote>
<p>"With dynamically typed languages such as Python or JavaScript, it
is possible to dynamically replace individual functions or object
methods. Dependency injection is less important in these languages
because this capability makes it possible to use real
implementations of dependencies in tests while only overriding
functions or methods of the dependency that are unsuitable for
tests." (page 261)</p>
</blockquote>
<p>I mean, I guess so, but I don't love that style either.</p>
<p>I agree more with this:</p>
<blockquote>
<p>"Code written without testing in mind typically needs to be
refactored or rewritten before you can add appropriate tests." (page
261)</p>
</blockquote>
<hr>
<p>Techniques for using test doubles:</p>
<ul>
<li>Faking: A parallel implementation stands in</li>
<li>Stubbing: Force something to return a specific value</li>
<li>Interaction testing: Check that something <em>was</em> called (don't
   actually call it)</li>
</ul>
<p>But: Prefer real implementations ("classical testing")</p>
<hr>
<blockquote>
<p>"Stubbing leaks implementation details of your code into your test."
(page 273)</p>
</blockquote>
<hr>
<blockquote>
<p>"Another downside of interaction testing is that it utilizes
implementation details of the system under test" (page 276)</p>
</blockquote>
<p>aka "change-detector tests"</p>
<hr>
<h3>Chapter 14: <a href="#ch14" name="ch14">Larger Testing</a></h3>
<hr>
<blockquote>
<p>"At Google, configuration changes are the number one reason for our
major outages." (page 284)</p>
</blockquote>
<hr>
<blockquote>
<p>"Without clear ownership, a test rots." (page 285)</p>
</blockquote>
<hr>
<p>On page 286 they mention "C/J Build" as Google's "first continuous
build framework" and TAP as its replacement. Mike Bland has an
interesting <a href="https://mike-bland.com/2012/06/21/chris-jay-continuous-build.html">history</a> of the "Chris/Jay continuous build" and the
"Test Automation Platform."</p>
<hr>
<p>On page 289, I think they may have their math wrong. They say two 10%
inaccurate things have a combined likelihood of a bug of 99% (1 -
(0.1 * 0.1)). I think they're trying to do one minus the probability
of no bugs, which should be (1 - (0.9 * 0.9)), or 19%. That's higher
than 10%, but it isn't as bad as 99%. I'm not sure what they intended
here.</p>
<hr>
<p>They advocate "record/replay proxies" as a testing technique, rather
than faking things out more completely, in contrast with
<a href="https://martinfowler.com/articles/consumerDrivenContracts.html">consumer-driven contracts</a>. They point to some <a href="https://github.com/googleapis/google-cloud-go/blob/master/rpcreplay/doc.go">Go source</a> (with
comments) for <code>rpcreplay</code>.</p>
<hr>
<blockquote>
<p>"At Google, we have a specialized engineering role of "Test
Engineer," and one of the things we look for in a good test engineer
is the ability to outline a test strategy for our products." (page
296)</p>
</blockquote>
<hr>
<p>They refer on page 299 to <a href="https://en.wikipedia.org/wiki/Bug_bash">bug bashes</a>.</p>
<hr>
<p>Google has <a href="https://www.infoq.com/news/2019/06/chaos-community-day-v4/">Catzilla</a>, which is analogous to <a href="https://netflix.github.io/chaosmonkey/">Chaos Monkey</a>.</p>
<hr>
<blockquote>
<p>"Rater evaluation is critical for nondeterministic systems like
machine learning systems for which there is no clear correct answer,
only a notion of better or worse." (page 304)</p>
</blockquote>
<hr>
<p>Google has published about <a href="https://research.google/pubs/pub36356/">Dapper</a>, which I think is a fancy system
for getting and tracking unique IDs through request chains, to help
with debugging etc.</p>
<hr>
<p>This chapter had the most glitches (typos, a paragraph that appeared
twice, etc.) of any in the book so far, I think.</p>
<hr>
<h3>Chapter 15: <a href="#ch15" name="ch15">Deprecation</a></h3>
<hr>
<blockquote>
<p>"<em>code is a liability, not an asset</em>" (page 312)</p>
</blockquote>
<hr>
<blockquote>
<p>"In health care, this phenomenon is known as "<a href="https://psnet.ahrq.gov/primer/alert-fatigue">alert fatigue</a>.""</p>
</blockquote>
<hr>
<blockquote>
<p>"These sorts of important-not-urgent cleanup tasks are a great use
of 20% time and provide engineers exposure to other parts of the
codebase." (page 320)</p>
</blockquote>
<p>I thought 20% time was supposed to be more fun than that.</p>
<hr>
<p>There isn't an obvious deprecation system in Python, as far as I know.
There is a built-in <code>DeprecationWarning</code>. There is a <a href="https://pypi.org/project/deprecation/">package</a> but
you have to install it. If you already have TensorFlow installed, you
can use <code>tensorflow.contrib.framework.deprecated</code> from it (in TF
1.14.0).</p>
<hr>
<h3>Chapter 16: <a href="#ch16" name="ch16">Version Control and Branch Management</a></h3>
<hr>
<p>The chapter is by Titus Winters, and he refers to what Google does as
"trunk-based development." I think he also likes to say "live at head"
to mean largely the same thing. He references <a href="https://www.devops-research.com/research.html" title="DevOps Research and Assessment organization">DORA</a>, who agrees,
and was aquired by Google.</p>
<hr>
<p>I was reminded of the bad old days at a previous employer, where for
some code we couldn't version control we would pass around a big green
translucent serving platter to represent "having a lock" on the code.</p>
<hr>
<p>A commit is like an instantaneous lock/edit/unlock.</p>
<hr>
<blockquote>
<p>"... considering common <em>usage</em>, both the centralized and DVCS
[Distributed Version Control System] models are largely
interchangeable:" (page 333)</p>
</blockquote>
<hr>
<p>Hard to not want to nit-pick the focus on time (cf. Time, Clocks, and
the Ordering of Events in a Distributed System) and think of Git's
time-free approach. Apparently Google's versions are incrementing
integers?</p>
<blockquote>
<p>"Monotonically increasing version numbers, rather than commit
hashes, are particularly troublesome. Many systems and scripts have
grown up in the Google developer ecosystem that assume that the
numeric ordering of commits is the same as the temporal
order–undoing those hidden dependencies is difficult." (page 333)</p>
</blockquote>
<hr>
<p>Google's main version control system, for the giant monorepo, is
called Piper. I think I saw somewhere that it used to be Perforce?</p>
<hr>
<pre><code>Abseil : C++ :: Guava : Java</code></pre>

<hr>
<p>Seems like Java "shading" is (a little bit) like Python's dunderscore
mangling, but specifically for dependencies. Google hates dependency
conflicts.</p>
<hr>
<p>On page 343 they reference <a href="https://itrevolution.com/book/the-phoenix-project">The Phoenix Project</a>: A Novel About IT,
DevOps, and Helping Your Business Win. Apparently it advocates
"reducing work-in-progress" among other things.</p>
<hr>
<blockquote>
<p>"Our various teams have all sorts of policies about release branches
given that relatively few teams have arrived at the sort of rapid
release cadence promised by CD [Continuous Delivery] that obviates
the need or desire for a release branch." (page 344)</p>
</blockquote>
<hr>
<blockquote>
<p>"<a href="https://jlbp.dev/what-is-a-diamond-dependency-conflict">diamond dependencies</a>" (page 345)</p>
</blockquote>
<hr>
<blockquote>
<p>"We expect a shift in VCS technology that assumes constant network
availability, focusing more on storage and build in the cloud to
avoid transmitting unnecessary files and artifacts." (page 348)</p>
</blockquote>
<p>I like not having to be connected all the time.</p>
<hr>
<blockquote>
<p>"Long-lived dev branches are not a good default plan." (page 349)</p>
</blockquote>
<p>Agree.</p>
<hr>
<p>They really advocate "for interrepository dependencies to be
unpinned/"at head"/"trunk based."" I think this must make sense when
you're running a ton of interdependent things. Most of my work is on
quite independent projects, like a statistical analysis that can run
with its own universe of dependencies that never need to be aligned
with any other repo's dependencies. For my stuff, pinning dependencies
pretty aggressively is good for reproducibility.</p>
<hr>
<h3>Chapter 17: <a href="#ch17" name="ch17">Code Search</a></h3>
<hr>
<p>The old "external Code Search" is described <a href="https://en.wikipedia.org/wiki/Google_Code_Search">on Wikipedia</a>.</p>
<p>Hmm! There is some <a href="https://developers.google.com/code-search">public Google code search</a>, not mentioned in the
text. It... doesn't seem great? But maybe I don't know what to look
for.</p>
<p>Hmm! Google's <code>RE2</code> regular expression engine is <a href="https://github.com/google/re2">open source</a> and
has a <a href="https://pypi.org/project/google-re2/">Python wrapper</a>. Looks like the trade-off is speed in
exchange for "various PCRE features (e.g. backreferences, look-around
assertions) are not supported".</p>
<hr>
<p>Ah! I thought so! Yegge was behind <a href="https://en.wikipedia.org/wiki/Google_Kythe#Grok">Grok</a>, which became/merged with
<a href="https://kythe.io/">Kythe</a>, which knows all about programming.</p>
<hr>
<p>One page 353 they advocate "using named types rather than generic
things like strings or integers, because it's then easy to find all
usages." Okay.</p>
<hr>
<p>On page 354 they mention "how to compute a fingerprint for integer
values efficiently" and I think that could be referring to getting the
hash of something; are they talking about hashing integers? Are these
integers so big that they can't just be their own hashes? Or is that
cheating?</p>
<hr>
<p>On page 357 there's a screenshot of a log viewer that seems to be
called "Analog" but I think it's different from the
<a href="https://en.wikipedia.org/wiki/Analog_(program)">web log analyzer</a> of that name...</p>
<hr>
<p>They have a <a href="https://github.com/Tendrl/documentation/wiki/Best-Practices-for-Response-Times-and-Latency">surprising reference</a> for the "responsive if latencies
are below 200 ms" bit on page 359.</p>
<hr>
<p>The code for the <a href="https://github.com/google/codesearch">old internal Google code search</a> is up, and also
you can read <a href="https://swtch.com/~rsc/regexp/regexp4.html">Russ Cox</a> explaining it. Trigrams!</p>
<hr>
<p>The reference to searching 20GB/s is now <a href="https://www.scalyr.com/blog/searching-1tb-sec-systems-engineering-before-algorithms/">searching 1.5TB/s</a>!</p>
<p>Had to go Wayback, but there's also <a href="https://web.archive.org/web/20190830155843/volnitsky.com/project/str_search">a bunch on substring matching</a>.</p>
<hr>
<p>Summarizing Google's code search history:</p>
<ul>
<li><code>grep</code></li>
<li>trigram</li>
<li><a href="https://en.wikipedia.org/wiki/Suffix_array">suffix array</a></li>
<li>token-based sparse n-gram (uses Google's "primary indexing and search stack")</li>
</ul>
<p>They describe moving the inverted index from memory to flash storage,
which I guess probably isn't relevant to the current state.</p>
<hr>
<p>On page 369 they mention "low recall accuracy" and go on to say that
means "nonmatches need to be filtered out of the result set." I think
they're using "recall accuracy" to mean "precision"?</p>
<hr>
<h3>Chapter 18: <a href="#ch18" name="ch18">Build Systems and Build Philosophy</a></h3>
<hr>
<p>Did they seriously just have a whole chapter on build systems and not
mention <a href="https://en.wikipedia.org/wiki/Make_(software)">make</a>? They mention "Ant, Maven, Gradle, Grunt, and Rake"
(page 376) but can't mention <a href="https://en.wikipedia.org/wiki/Make_(software)">make</a>?</p>
<hr>
<p>There's some disconnect between their "engineers love the build
system" and the footnote that says "83% of Googlers reported being
satisfied with the build system" (page 371).</p>
<hr>
<ul>
<li>Google's internal "Blaze" build tool<ul>
<li><a href="https://buck.build/">Buck</a>, a Facebook tool apparently inspired by Blaze</li>
<li><a href="https://www.pantsbuild.org/">Pants</a>, a tool inspired by Blaze</li>
<li><a href="https://bazel.build/">Bazel</a>, the open source Blaze</li>
</ul>
</li>
</ul>
<hr>
<p>They point out that the artifact-based input/output structure of Bazel
is analogous to functional programming. That's true. In this way,
Bazel is similar to lots of DAG-based systems, like <a href="https://airflow.apache.org/docs/apache-airflow/stable/index.html">Airflow</a>,
<a href="https://github.com/ajschumacher/ajschumacher.github.io/issues/86">etc.</a></p>
<hr>
<p>They mention C++ can include other files and that this is an issue for
knowing what's changed, but I didn't see that they described Bazel
having a solution for this...</p>
<hr>
<p>They mention "the 1:1:1 rule" on page 391 but don't really explain it.
Finding an <a href="https://v1.pantsbuild.org/build_files.html">old version</a> of their link:</p>
<blockquote>
<p>"The idiom of having one target per directory, representing a single
package, is sometimes referred to as the 1:1:1 rule."</p>
</blockquote>
<p>So that's 1 directory, 1 target, 1 package.</p>
<hr>
<blockquote>
<p>"<a href="https://github.com/bazelbuild/bazel-gazelle">Gazelle</a> is a Bazel build file generator for Bazel projects. It
natively supports Go and protobuf, and it may be extended to support
new languages and custom rule sets."</p>
</blockquote>
<hr>
<blockquote>
<p>"Automatically managed dependencies
["*", "+", "&gt;" in version specifications] can be convenient for
small projects, but they're usually a recipe for disaster on
projects of nontrivial size or that are being worked on by more than
one engineer." (page 394)</p>
</blockquote>
<hr>
<blockquote>
<p>"... we enforce a strict <a href="https://opensource.google/docs/thirdparty/oneversion/"><em>One-Version Rule</em></a> for all third-party
dependencies in our internal codebase." (page 394)</p>
</blockquote>
<hr>
<p>A thought I had in connection with all this monorepo stuff is: Is this
part of the motivation for microservices? A microservice can (in
theory?) just expose an API but otherwise have an isolated codebase,
OS, etc. It seems like Google jumps through a lot of hoops and
introduces a lot of coordination in order to make the monorepo work...</p>
<hr>
<p>The advice (page 396) to mirror external dependencies so you don't
depend on somebody continuing to host them the same way is pretty good
advice. (Continues to use Docker Hub base images etc...)</p>
<hr>
<h3>Chapter 19: <a href="#ch19" name="ch19">Critique: Google's Code Review Tool</a></h3>
<hr>
<p>On page 400 they reference Google's "web-based code editing tool". On
page 406 it's "Cider, an online IDE for editing source code stored in
the cloud". I don't see much about it online, but there is this fun
<a href="https://github.com/jhuangtw/xg2xg">table</a> showing Google-internal things and how they map to
non-Google things.</p>
<hr>
<blockquote>
<p>"In emergency cases, the author can forcefully commit their changes
and have it reviewed after commit." (page 402)</p>
</blockquote>
<p>Nice to have in a pinch; could allow abuse but still.</p>
<hr>
<p>They mention on page 403 that their diff does move detection, which
many diff tools don't do terribly well... I wonder if theirs is much
better.</p>
<hr>
<p>I saw somebody online who likes Critique and they said
https://reviewable.io/ is the closest publicly available tool...</p>
<hr>
<p>Apparently Critique does screenshot diffs of UIs generated by code,
which is neat. (page 404)</p>
<hr>
<blockquote>
<p>"When users drill down to the file level, Critique provides a UI
widget with a compact display of the chain of snapshot versions of a
file;" (page 404)</p>
</blockquote>
<hr>
<p>This "Zapfhahn" test coverage tool seemed to be mentioned (page 406)
only in this book, outside of Google... Similarly for the "GwsQ" for
passing code review to someone in a list automatically.</p>
<hr>
<p>I like this behavior of Critique:</p>
<blockquote>
<p>"As mentioned earlier, comments are drafted as-you-go, but then
"published" atomically, as shown in Figure 19-7. This allows authors
and reviewers to ensure that they are happy with their comments
before sending them out." (page 409)</p>
</blockquote>
<hr>
<p>On page 414 they say "each commit is reviewed separately" but I think
they must mean each "change set" or branch (in the case of git)...</p>
<hr>
<h3>Chapter 20: <a href="#ch20" name="ch20">Static Analysis</a></h3>
<hr>
<p>Google's static analysis system: <a href="https://research.google/pubs/pub43322/" title="Tricorder: Building a Program Analysis Ecosystem">Tricorder</a></p>
<hr>
<blockquote>
<p>"Static analysis tools at Google must scale to the size of Google's
multibillion-line codebase. To do this, analysis tools are shardable
and incremental. Instead of analyzing entire large projects, we
focus analyses on files affected by a pending code change, and
typically show analysis results only for edited files or lines."
(page 418)</p>
</blockquote>
<p>This is different from most usages of "scaling" that I've seen. "We
scale by not trying to scale." I mean, I guess it is a kind of
scaling?</p>
<p>Also on page 423, they make it sound like analysis is always
single-function (not involving more of the codebase).</p>
<hr>
<blockquote>
<p>"Research about static analysis tools traditionally focused on
reducing false negatives; in practice, low false-positive rates are
often critical for developers to actually want to use a tool–who
wants to wade through hundreds of false reports in search of a few
true ones?" (page 419-420)</p>
</blockquote>
<hr>
<blockquote>
<p>"An issue is an "effective false positive" if developers did not
take some positive action after seeing the issue." (page 420)</p>
</blockquote>
<hr>
<p>On page 421 they mention <a href="https://github.com/google/Refaster">Refaster</a>, which has been eaten by
<a href="https://errorprone.info/">Error Prone</a>.</p>
<hr>
<blockquote>
<p>"Seven of these [more than 100] analyzers are themselves plug-in
systems that have hundreds of additional checks, again contributed
from developers across Google." (page 422)</p>
</blockquote>
<p>I hadn't thought of this before! How crazy: My plug-in has plug-ins!</p>
<hr>
<blockquote>
<p>"before we established clear feedback channels, many developers
would just ignore analysis results they did not understand." (page
423)</p>
</blockquote>
<hr>
<blockquote>
<p>"Instead of reenabling customizability, we asked users why they were
annoyed and found all kinds of bugs and false positives with the
linters. For example, the C++ linter also ran on Objective-C files
but produced incorrect, useless results. ... In short, user
customization resulted in hidden bugs and suppressing feedback."
(page 425)</p>
</blockquote>
<p>Some humans do work at Google!</p>
<hr>
<blockquote>
<p>"We have found repeatedly that developers ignore compiler warnings."
(page 427)</p>
</blockquote>
<hr>
<h3>Chapter 21: <a href="#ch21" name="ch21">Dependency Management</a></h3>
<hr>
<p>C++ has a <a href="https://en.cppreference.com/w/cpp/language/definition">one definition rule</a>.</p>
<hr>
<blockquote>
<p>"Within Google, there is a constant stream of guidance directed to
our engineers to help them consider this difference between "I got
it to work" and "this is working in a supported fashion."" (page
435)</p>
</blockquote>
<hr>
<p>Russ Cox stuff:</p>
<ul>
<li><a href="https://research.swtch.com/deps">Our Software Dependency Problem</a></li>
<li><a href="https://research.swtch.com/vgo-import">Semantic Import Versioning</a><ul>
<li>Not Russ Cox, but this is related to <a href="https://www.youtube.com/watch?v=oyLBGkS5ICk&amp;ab_channel=ClojureTV">Clojure</a> having the
   same idea about making major versions separate packages,
   really.</li>
</ul>
</li>
<li><a href="https://research.swtch.com/vgo-mvs">Minimal Version Selection</a></li>
</ul>
<hr>
<p>On page 439 they mention <a href="https://www.boost.org/">Boost</a> as a library with "no compatibility promise" that is "particularly risky"—which makes me wonder whether this is why Google has its own linalg packages, including (at least) <a href="https://github.com/google/gemmlowp">gemmlowp</a>.</p>
<hr>
<p>"SAT" as in "SAT-solver" is an <a href="https://en.wikipedia.org/wiki/Boolean_satisfiability_problem">unsatisfying</a> name because it is not
an initialism, as far as I can tell.</p>
<hr>
<blockquote>
<p>"Live at Head ... is theoretically sound, but places new and costly
burdens on participants in a dependency network." (page 442)</p>
</blockquote>
<hr>
<blockquote>
<p>"Prefer languages that have good control over public/private access
to APIs of all forms." (page 445)</p>
</blockquote>
<hr>
<blockquote>
<p>"there is some loss of fidelity in this compression of software
changes into version numbers." (page 448)</p>
</blockquote>
<hr>
<blockquote>
<p>"the model of dependency management given infinite resources is
effectively that of the Live at Head model." (page 452)</p>
</blockquote>
<hr>
<p>I was interested in the example of open-sourcing <a href="https://github.com/gflags/gflags">gflags</a>, which
illustrated some of the costs/risks to a company of open-sourcing a
thing.</p>
<hr>
<p>It does kind of seem like a lot of Google's pain with regard to
dependencies is self-inflicted in the sense of existing largely
because they insist on the monorepo. I guess that's the trade-off:
they like the monorepo so much, they'll fight dependency management
fights a lot.</p>
<hr>
<blockquote>
<p>"external users of an API cost a lot more to maintain than internal
ones." (page 455)</p>
</blockquote>
<hr>
<blockquote>
<p>"When evaluating whether to release something, be aware of the
long-term risks: externally shared dependencies are often much more
expensive to modify over time." (page 455)</p>
</blockquote>
<hr>
<p>The author advocates for using testing to resolve empirically whether
"a new set of versions work together" which could work if you really
trust that everything is well tested.</p>
<hr>
<h3>Chapter 22: <a href="#ch22" name="ch22">Large-Scale Changes</a></h3>
<hr>
<blockquote>
<p>"Although funding and staffing a team to run these kinds of
migrations can seem like an additional cost, it is actually just
internalizing the externalities that an unfunded mandate creates,
with the additional benefits of economies of scale." (page 462)</p>
</blockquote>
<hr>
<p>The author's paper: <a href="https://ieeexplore.ieee.org/abstract/document/8443579">Non-Atomic Refactoring and Software Sustainability</a></p>
<hr>
<blockquote>
<p>"The SREs who run Google's production services have a mantra: "No
Haunted Graveyards." A haunted graveyard in this sense is a system
that is so ancient, obtuse, or complex that no one dares enter it.
Haunted graveyards are often business-critical systems that are
frozen in time because any attempt to change them could cause the
system to fail in incomprehensible ways, costing the business real
money. They pose a real existential risk and can consume an
inordinate amount of resources." (page 464)</p>
</blockquote>
<hr>
<blockquote>
<p>"perhaps the most important support for LSCs has been the evolution
of cultural norms around large-scale changes and the oversight given
to them." (page 468)</p>
</blockquote>
<hr>
<ul>
<li><a href="https://ieeexplore.ieee.org/abstract/document/6676954">Large-Scale Automated Refactoring Using ClangMR</a> (C++)</li>
<li><a href="https://cacm.acm.org/magazines/2018/4/226371-lessons-from-building-static-analysis-tools-at-google/">JavacFlume</a> is the same idea but for Java</li>
<li><a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41876.pdf">Scalable, Example-Based Refactorings with Refaster</a> (also for Java)</li>
</ul>
<hr>
<blockquote>
<p>"As a rule of thumb, we've long held that if a change requires more
than 500 edits, it's usually more efficient for an engineer to learn
and execute our change-generation tools rather than manually execute
that edit. For experienced "code janitors," that number is often
much smaller." (page 470)</p>
</blockquote>
<hr>
<p><a href="https://opensource.google/docs/glossary/#rosie">Rosie</a> is "An internal tool for doing large scale cleanups and code
changes. It splits a large patch into smaller pieces which can be
reviewed, tested, and submitted independently."</p>
<hr>
<blockquote>
<p>"languages that tend to be viewed as more focused on developer
productivity tend to be more difficult to maintain." (page 471)</p>
</blockquote>
<hr>
<ul>
<li><a href="https://talks.golang.org/2016/refactor.article">Codebase Refactoring (with help from Go)</a></li>
<li><a href="https://github.com/google/google-java-format">google-java-format</a></li>
<li><a href="https://clang.llvm.org/docs/ClangFormat.html">clang-format</a> (for C++)</li>
</ul>
<hr>
<h3>Chapter 23: <a href="#ch23" name="ch23">Continuous Integration</a></h3>
<hr>
<p>TAP (Test Automation Platform) playing a key role again here...</p>
<hr>
<blockquote>
<p>"Relying heavily on feature-flag-guarding is a common paradigm for
Continuous Delivery" (page 482)</p>
</blockquote>
<hr>
<blockquote>
<p>"By improving test output readability, you automate the
understanding of feedback." (page 483)</p>
</blockquote>
<hr>
<p>They reference <a href="https://sre.google/sre-book/automation-at-google/">The Evolution of Automation at Google</a> (oh right! <a href="https://sre.google/sre-book/table-of-contents/">The SRE book</a> is online!)</p>
<hr>
<p>There's this idea of "green head" as the point just beyond head in the
"live at head" sense... Interesting. There isn't just a single head,
really? Close to, but not quite? "Green head" is the latest change
that's passed tests but not yet committed... Could there be multiple
green heads, then, if people are working on different things?</p>
<hr>
<p><a href="https://kubernetes.io/blog/2015/04/borg-predecessor-to-kubernetes/">Borg: The Predecessor to Kubernetes</a></p>
<hr>
<p><a href="https://sre.google/sre-book/release-engineering/">Rapid</a> (the release automation tool) is in the SRE book too.</p>
<hr>
<p>They mention on page 485 that tests to run can be "selected based on a
model that predicts their likelihood of detecting a failure." I wonder
what sorts of models they use. (Are they learned?)</p>
<hr>
<p>On pages 494-495, she mentions a "Build Cop" role as the person who
takes responsibility for getting builds green. Interesting.</p>
<hr>
<blockquote>
<p>"Engineers who want to spend less time waiting end up making
smaller, targeted changes, which is a win for everyone." (page 496)</p>
</blockquote>
<p>Benefits of things being slow.</p>
<hr>
<h3>Chapter 24: <a href="#ch24" name="ch24">Continuous Delivery</a></h3>
<hr>
<blockquote>
<p>"There is a saying among educators that no lesson plan survives its
first contact with the student body." (page 505)</p>
</blockquote>
<p>This seems to be traceable really to a military quote from
<a href="https://en.wikiquote.org/wiki/Helmuth_von_Moltke_the_Elder">von Moltke</a>, usually paraphrased as "No plan survives contact with
the enemy."</p>
<hr>
<blockquote>
<p>"One of our codebases, YouTube, is a large, monolithic Python
application." (page 507)</p>
</blockquote>
<hr>
<blockquote>
<p>"A key to reliable continuous releases is to make sure engineers
"flag guard" <em>all changes</em>." (page 508, emphasis in original)</p>
</blockquote>
<hr>
<blockquote>
<p>"One issue we noticed when doing deployments to Android was that we
could expect a statistically significant change in user metrics
<em>simply from pushing an update</em>. This meant that even if we made no
changes to our product, pushing an update could affect device and
user behavior in ways that were difficult to predict. As a result,
although canarying the update to a small percentage of user traffic
could give us good information about crashes or stability problems,
it told us very little about whether the newer version of our app
was in fact better than the older one." (page 512, emphasis in
original)</p>
</blockquote>
<hr>
<blockquote>
<p>"One release responsibility is to protect the product from the
developers." (page 514)</p>
</blockquote>
<hr>
<h3>Chapter 25: <a href="#ch25" name="ch25">Compute as a Service</a></h3>
<hr>
<p><a href="https://research.google/pubs/pub43438/">Large-scale cluster management at Google with Borg</a></p>
<hr>
<p>On page 519 they mention <a href="https://prometheus.io/">Prometheus</a> and <a href="https://github.com/grafana/grafana">Grafana</a> somewhat
confusingly with Grafana mentioned first, while Prometheus is more of
a data source for Grafana, so I think it makes more sense to list
Prometheus first... Probably capabilities overlap, I guess.</p>
<hr>
<blockquote>
<p>"Google has chosen, long ago, that the latency degradation due to
disk swap is so horrible that an out-of-memory kill and a migration
to a different machine is universally preferable—so in Google's
case, it's always an out-of-memory kill." (page 521)</p>
</blockquote>
<hr>
<p>On page 522 they mention <a href="https://github.com/google/lmctfy">LMCTFY</a>, which I think I wasn't aware of.
An old open source version of Google's containerization, which isn't
developed any more as Docker ate the world. Of course there's also
<a href="https://en.wikipedia.org/wiki/Singularity_(software)">Singularity</a>, and I hear people like <a href="https://firecracker-microvm.github.io/">Firecracker</a>, etc.</p>
<hr>
<blockquote>
<p>"The canonical framework for doing this
[distributing work across workers] at Google was MapReduce, later
replaced by Flume." (page 526)</p>
</blockquote>
<hr>
<p><a href="https://research.google/pubs/pub48030/">Fast key-value stores: An idea whose time has come and gone</a></p>
<hr>
<blockquote>
<p>"Note that retries need to be implemented correctly—with backoff,
graceful degradation and tools to avoid cascading failures like
<a href="https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/">jitter</a>."</p>
</blockquote>
<hr>
<blockquote>
<p>"One useful tool to help with idempotency is client-assigned
identifiers: if you are creating something (e.g., an order to
deliver a pizza to a specific address), the order is assigned some
identifier by the client; and if an order with that identifier was
already recorded, the server assumes it's a repeated request and
reports success (it might also validate that the parameters of the
order match)." (page 529)</p>
</blockquote>
<hr>
<p>On page 536 they mention <a href="https://openwhisk.apache.org/">OpenWhisk</a> and <a href="https://knative.dev/">Knative</a>. Looks like
both help run serverless stuff; Knative is more closely tied to
Kubernetes.</p>
<hr>
<blockquote>
<p>"To take one specific instance of that
[compromises around system control], the Google Code Jam team
(running a programming contest for thousands of participants, with a
frontend running on Google AppEngine) had a custom-made script to
hit the contest webpage with an artificial traffic spike several
minutes before the contest start, in order to warm up enough
instances of the app to serve the actual traffic that happened when
the contest started. This worked, but it's the sort of hand-tweaking
(and also hacking) that one would hope to get away from by choosing
a serverless solution." (page 542)</p>
</blockquote>
<hr>
<p>Interesting to see a mention of <a href="https://en.wikipedia.org/wiki/Platform_as_a_service">Zimki</a>, the short-lived PaaS...</p>
<hr>
<h3>Afterward</h3>
<hr>
<blockquote>
<p>"The passage of time and the importance of change cannot be
ignored." (page 550)</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210331-software_engineering_at_google/</link>
<guid>http://planspace.org/20210331-software_engineering_at_google/</guid>
<pubDate>Wed, 31 Mar 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>How to Make the World Add Up, by Harford</title>
<description><![CDATA[

<p>Looks like I got the <a href="https://timharford.com/books/worldaddup/">UK edition</a> rather than the <a href="https://timharford.com/books/datadetective/">US edition</a> (US
title: "The Data Detective"). Ties to audio are evident, from frequent
citations of podcasts to the titling and overall style. Probably good
as an audiobook too. I liked it a lot. Plenty of good examples and a
humane focus on aspects of understanding data that are too often
neglected.</p>
<h3>“Ten Rules for Thinking Differently About Numbers” (rules re-worded)</h3>
<ol>
<li><a href="#ch1">Be aware of your emotions.</a></li>
<li><a href="#ch2">Consider both first-person experience and statistical views.</a></li>
<li><a href="#ch3">Understand what definitions really mean.</a></li>
<li><a href="#ch4">Put things in appropriate context.</a></li>
<li><a href="#ch5">Be aware of publication bias and significance testing generally.</a></li>
<li><a href="#ch6">Consider what's missing (especially as a result of bias).</a></li>
<li><a href="#ch7">Overfitting can happen; models may be bad; demand transparency.</a></li>
<li><a href="#ch8">Value good official statistics.</a></li>
<li><a href="#ch9">Be skeptical of visualizations.</a></li>
<li><a href="#ch10">Keep an open mind.</a></li>
</ol>
<p>And the Golden rule: <a href="#golden">Be curious</a></p>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"I worry about a world in which many people will believe anything,
but I worry far more about one in which people believe nothing
beyond their own preconceptions." (page 15)</p>
</blockquote>
<p>He references <a href="https://en.wikipedia.org/wiki/How_to_Lie_with_Statistics">How to Lie With Statistics</a> but laments the
associated cynicism.</p>
<hr>
<h3>Chapter 1: <a href="#ch1" name="ch1">Be aware of your emotions.</a></h3>
<hr>
<blockquote>
<p>"Sometimes, we want to be fooled." (page 23)</p>
</blockquote>
<hr>
<blockquote>
<p>"All the statistical expertise in the world will not prevent you
believing claims you shouldn't believe and dismissing facts you
shouldn't dismiss." (page 23)</p>
</blockquote>
<hr>
<blockquote>
<p>"One survey of gay and bisexual men in the United States found that
almost half believed HIV did not cause AIDS and more than half
believed the standard treatments did more harm than good." (page 29)</p>
</blockquote>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/20571892/">"There is no proof that HIV causes AIDS": AIDS denialism beliefs among people living with HIV/AIDS</a></li>
<li><a href="https://psycnet.apa.org/record/2007-12149-013">Conspiracy beliefs and trust in information about HIV/AIDS among minority men who have sex with men</a></li>
</ul>
<hr>
<blockquote>
<p>"If doubt is the weapon, detail is the ammunition." (page 37)</p>
</blockquote>
<p>Interesting comparison: "Must I believe this?" vs. "Can I believe
this?" With more detail, there are more things to find fault with, and
also more things to find convincing.</p>
<hr>
<blockquote>
<p>"We can learn to control our emotions—that is part of the process of
growing up." (page 42)</p>
</blockquote>
<hr>
<h3>Chapter 2: <a href="#ch2" name="ch2">Consider both first-person experience and statistical views.</a></h3>
<hr>
<blockquote>
<p>"Sometimes personal experience tells us one thing, the statistics
tell us something quite different, and both are true." (page 54)</p>
</blockquote>
<hr>
<blockquote>
<p>"Though a factor of sixteen is hardly a small effect, lung cancer is
itself scarce enough to confuse our intuitions. The world is full of
patterns that are too subtle or too rare to detect by eyeballing
them, and a pattern doesn't need to be very subtle or rare to be
hard to spot without a statistical lens." (page 54)</p>
</blockquote>
<hr>
<blockquote>
<p>"<a href="https://youarenotsosmart.com/2017/07/20/yanss-101-naive-realism-rebroadcast/">Naive realism</a> can lead us badly astray when we confuse our
personal perspective on the world with some universal truth. We are
surprised when an election goes against us: everyone in our social
circle agreed with us, so why did the nation vote otherwise? Opinion
polls don't always get it right, but I can assure you they have a
better track record of predicting elections that simply talking to
your friends." (page 57)</p>
</blockquote>
<p>This <a href="https://en.wikipedia.org/wiki/Na%C3%AFve_realism_(psychology)">naive realism thing</a> is interesting. I think it's
fundamentally the assumption that other people are basically the same
as us except for what they've experienced, so if only they saw that
article in The Atlantic, then we'd agree?</p>
<hr>
<blockquote>
<p>"These news reports are data, in a way. They're just not
representative data. But they certainly influence our views of the
world." (page 59)</p>
</blockquote>
<hr>
<blockquote>
<p>"Social scientists have long understood that statistical metrics are
at their most pernicious when they are being used to control the
world, rather than try to understand it. Economists tend to cite
their colleague Charles Goodhart, who wrote in 1975: 'Any observed
statistical regularity will tend to collapse once pressure is placed
upon it for control purposes.' (Or, more pithily: 'When a measure
becomes a target, it ceases to be a good measure.') Psychologists
turn to Donald T. Campbell, who around the same time explained: 'The
more any quantitative social indicator is used for social
decision-making, the more subject it will be to corruption pressures
and the more apt it will be to distort and corrupt the social
processes it is intended to monitor.'" (page 62)</p>
</blockquote>
<p>Citations from page 299:</p>
<blockquote>
<p>"Charles Goodhart, 'Problems of Monetary Management: The U.K.
Experience,' in Anthony S. Courakis (ed.), <em>Inflation, Depression,
and Economic Policy in the West</em>, London: Mansell, 1981, pp. 111-46.
The original paper was presented at a conference in 1975."</p>
<p>"Donald T. Campbell, 'Assessing the impact of planned social
change,' <em>Evaluation and Program Planning</em>, 2(1), 1979—an earlier
version was published in 1976 and a conference paper existed in
1974."</p>
</blockquote>
<p>Love the thorough sourcing!</p>
<hr>
<blockquote>
<p>"Muhammad Yunus, an economist, microfinance pioneer and winner of
the Nobel Peace Prize, has contrasted the 'worm's eye view' of
personal experience with the 'bird's eye view' that statistics can
provide. The worm and the bird see the world very differently, and
Professor Yunus is right to emphasize the advantage of seeing it up
close." (page 64)</p>
</blockquote>
<hr>
<h3>Chapter 3: <a href="#ch3" name="ch3">Understand what definitions really mean.</a></h3>
<hr>
<p>Around page 70, interesting stuff on differences in infant mortality
rates being impacted by differences in how things are classified: if a
pregnancy ends without a live baby at week 22 or 23, is that a
miscarriage or the death of an infant? See for example the cited
<a href="https://pubmed.ncbi.nlm.nih.gov/25252091/">International comparisons of infant mortality and related factors: United States and Europe, 2010 </a></p>
<hr>
<blockquote>
<p>"Even the year of death, 2017, isn't as straightforward as you might
think. For example, in the UK in 2016, the homicide rate rose
sharply. This was because an official inquest finally ruled that
ninety-six people who died in a crush at the Hillsborough football
stadium in 1989 had been unlawfully killed. Initially seen as an
accident, those deaths officially became homicides in 2016. This is
an extreme example, but there are often delays between when somebody
died and when the cause of death was officially registered." (page
77)</p>
</blockquote>
<hr>
<blockquote>
<p>"Clarity should come first; advocacy can come once we understand the
facts." (page 78)</p>
</blockquote>
<hr>
<blockquote>
<p>"It is not always clear whether someone intended to kill themselves;
sometimes people intended only to hurt themselves but died by
accident. In the UK, the Office for National Statistics draws a
clear line: if the child is fifteen or over, the death is assumed to
be deliberate; under the age of fifteen, it is assumed to be an
accident." (page 80)</p>
</blockquote>
<hr>
<h3>Chapter 4: <a href="#ch4" name="ch4">Put things in appropriate context.</a></h3>
<hr>
<p>Cute idea re: <a href="https://www.npr.org/sections/money/2017/12/29/574666409/the-50-year-newspaper">50-year newspaper</a>.</p>
<hr>
<blockquote>
<p>"Less illuminating [than a meaningful comparison] is the habit of
writing something along the lines of 'if the US national debt was a
pile of dollar bills it would stretch all the way to space/to the
moon/to the sun'. Some journalists seem to think this is a great way
to put a big number into context. Is it? Generally I find myself
stupider at reaching the end of such sentences. Do you know how many
dollar bills there are in a pile a yard high? (About eight thousand.
I had to look it up, of course. Anyone would.) Space is generally
regarded as being 100 kilometres above us, the moon is nearly
400,000 kilometres away, and the sun 150 million kilometres away—so
a pile that stretches to the sun is a lot bigger than one that
stretches to space. By my calculations, the US national debt would
be a pile of dollar bills reaching to the moon six times. Happy now?
I find it much clearer to note that it is about $70,000 per US
citizen." (page 100)</p>
</blockquote>
<hr>
<blockquote>
<p>"The good stories are everywhere. They are not made memorable by
their rarity; they are made forgettable by their ubiquity." (page
104)</p>
</blockquote>
<hr>
<blockquote>
<p>"In the first chapter, I advised trying to notice your feelings
about the claim; in the second chapter, constructively
sense-checking the claim against your personal experience; in the
third chapter, asking yourself if you really understand what the
claim means. These are all simple, common-sense suggestions, and in
this chapter I've added a fourth: step back and look for information
that can put the claim into context." (page 108)</p>
</blockquote>
<hr>
<h3>Chapter 5: <a href="ch5" name="ch5">Be aware of publication bias and significance testing generally.</a></h3>
<hr>
<blockquote>
<p>"If you have a result that looks publishable but fragile, the logic
of science tells you to try to disprove it. Yet the logic of
academic grants and promotions tells you to publish at once, and for
goodness sake don't prod it too hard." (page 120)</p>
</blockquote>
<hr>
<blockquote>
<p>"In general, more data is better. But if data are gathered bit by
bit, testing as we go, then the standard statistical tests aren't
valid. Those tests assume that the data have simply been gathered,
then tested—not that scientists have collected some data, tested
them, and then maybe collected a bit more." (page 121)</p>
</blockquote>
<hr>
<blockquote>
<p>"Daniel Kahneman himself dramatically raised the profile of the
issue [of reproducibility/reliability of research] when he wrote an
open <a href="https://www.nature.com/news/polopoly_fs/7.6716.1349271308!/suppinfoFile/Kahneman%20Letter.pdf">letter</a> to psychologists in the field warning them of a
looming 'train wreck' if they could not improve the credibility of
their research." (page 127)</p>
</blockquote>
<hr>
<blockquote>
<p>"The 'interestingness' filter is enormously powerful." (page 128)</p>
</blockquote>
<hr>
<blockquote>
<p>"There are encouraging signs that more researchers are welcoming
replication efforts. For example, in 2010, political scientists
Brendan Nyhan and Jason Reifler published a study on what became
known as 'the backfire effect'—in brief, that people were more
likely to believe a false claim if they'd been shown a fact-check
that debunked the claim. This caused a moral panic among some
journalists, particularly after the rise of Donald Trump.
Fact-checking only makes matters worse! It hit that perfect
counterintuitive sweet spot. But Nyhan and Reifler encouraged
further studies, and those studies suggest that the backfire effect
is unusual and fact-checking does help. One <a href="https://fullfact.org/blog/2019/mar/does-backfire-effect-exist/">summary</a> of the
research concluded: 'generally debunking can make people's beliefs
in specific claims more accurate'. Nyhan himself has quoted this
summary <a href="https://twitter.com/BrendanNyhan/status/1108377656414879744">on Twitter</a> when he sees people relying on his original
paper without considering the follow-ups." (page 135)</p>
</blockquote>
<hr>
<blockquote>
<p>"Many statisticians believe the crisis points to the need to rethink
the standard statistical tests themselves—that the very concept of
'statistical significance' is deeply flawed." (page 135)</p>
</blockquote>
<hr>
<blockquote>
<p>"In general, if the chances of randomly observing data at least as
extreme as you collect are less than 5 per cent, the results are
'significant' enough to overturn the assumption: we can conclude
with a sufficient degree of confidence that the drug works, large
displays of jam discourage people from buying jam, and that
precognition exists.</p>
<p>"The problems are obvious. 5 per cent is an arbitrary cut-off
point—why not 6 per cent, or 4 per cent?—and it encourages us to
think in black-and-white, pass-or-fail terms, instead of embracing
degrees of uncertainty." (page 136)</p>
</blockquote>
<hr>
<p>Page 136 also includes mention of a "journey towards more rigorous
science" which made me think. Statistical rigor is sort of the
problem, isn't it? At least, a certain interpretation of what rigor
is. The attraction of binary decision-making, significant or not
significant, has the feel of "rigor" - using a significance test feels
"rigorous." What we need is science that's more thoughtful, more
circumspect, less focused on reporting results via single-number
summaries. If that can be made to be what "rigor" means, then good.</p>
<hr>
<p>The book introduces <a href="https://en.wikipedia.org/wiki/Cochrane_(organisation)">Cochrane</a> and <a href="https://en.wikipedia.org/wiki/Campbell_Collaboration">Campbell</a>, two neat
collaborations that focus on trying to figure out the truth by looking
at multiple studies.</p>
<hr>
<h3>Chapter 6: <a href="#ch6" name="ch6">Consider what's missing (especially as a result of bias).</a></h3>
<hr>
<blockquote>
<p>"The power to not collect data is one of the most important and
little-understood sources of power that governments have... By
refusing to amass knowledge in the first place, decision-makers
exert power over the rest of us." (page 142, quoting
<a href="https://twitter.com/darkgreener">Anna Powell-Smith</a> of <a href="https://missingnumbers.org/">MissingNumbers.org</a>)</p>
</blockquote>
<hr>
<p><a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-9713.2016.00899.x">Closing the gender data gap</a></p>
<blockquote>
<p>"When Uganda revised its question about labour force participation
in two contiguous surveys in 1992–93 – recording the main activity
in one case, while expanding questions to cover secondary activities
in the other – the percentage of working-age Ugandans in the labour
force increased from 78% to 87%. These additional workers – 702 000
of them, the majority women – went unacknowledged in the first
survey that asked only about primary activities."</p>
</blockquote>
<hr>
<blockquote>
<p>"It is all too tempting to assume that what we do not measure simply
does not exist." (page 149)</p>
</blockquote>
<hr>
<p><a href="http://apps.olin.wustl.edu/faculty/pollak/R_Lundberg_Pollak_Wales_1997_JHR_Do_husbands.pdf">Do Husbands and Wives Pool Their Resources? Evidence from the United Kingdom Child Benefit</a></p>
<blockquote>
<p>"Common preference models of family behavior imply income pooling, a
restriction on family demand functions such that only the sum of
husband's income and wife's income affects the allocation of goods
and time. Testing the pooling hypothesis is difficult because most
family income sources are not exogenous to the allocations being
analyzed. In this paper, we present an alternative test based on a
"natural experiment"-a policy change in the United Kingdom that
transferred a substantial child allowance to wives in the late
1970s. Using Family Expenditure Survey data, we find strong evidence
that a shift toward greater expenditures on women's clothing and
children's clothing relative to men's clothing coincided with this
income redistribution."</p>
</blockquote>
<hr>
<blockquote>
<p>"Big found datasets can seem comprehensive, and may be enormously
useful, but 'N = All' is often a seductive illusion: it's easy to
make unwarranted assumptions that we have everything that matters.
We must always ask who what is missing. And this is only one reason
to approach big data with caution." (page 160)</p>
</blockquote>
<hr>
<h3>Chapter 7: <a href="#ch7" name="ch7">Overfitting can happen; models may be bad; demand transparency.</a></h3>
<hr>
<blockquote>
<p>"We're awestruck by the algorithm in part because we don't
appreciate the mundanity of what's happening underneath the
magician's silk handkerchief." (page 169)</p>
</blockquote>
<hr>
<blockquote>
<p>"In Charles Duhigg's account, Target mixes in random offers, such as
coupons for wine glasses, because pregnant customers would feel
spooked if they realised how intimately the company's computers
understood them. But Kaiser Fung has another explanation: Target
mixes up its offers not because it would be weird to send an
all-baby coupon book to a woman who was pregnant, but because the
company knows that many of those coupon books will be sent to women
who aren't pregnant after all." (page 170)</p>
</blockquote>
<hr>
<blockquote>
<p>"The problem [with Wunderlich's body temperature result] was
exacerbated by a conversion of units. Wunderlich's original
measurements were made in centigrade, and his results concluded that
the typical body temperature was in a range around 37°C—implicitly,
given that degree of precision, a range of up to a degree
centigrade, somewhere above 36.5°C and below 37.5°C. But when
Wunderlich's articles in German were translated into English,
reaching a larger audience, the temperature was converted from
centigrade to Fahrenheit and became 98.6°F—inviting physicians to
assume that the temperature had been measured to one tenth of a
degree Fahrenheit rather than one degree centigrade. The implied
precision was almost twenty times greater—but all that had actually
changed was a conversion between two temperature scales." (page 174)</p>
</blockquote>
<hr>
<p><a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">Amazon scraps secret AI recruiting tool that showed bias against women</a></p>
<hr>
<blockquote>
<p>"Remarkably often, Meehl found, experts faired poorly when compared
with simple checklists. Meehl described his <em>Clinical vs.
Statistical Prediction</em> as 'my disturbing little book'."</p>
</blockquote>
<p>This connects neatly with <a href="https://en.wikipedia.org/wiki/Atul_Gawande">Gawande</a>'s modern checklist advocacy.
It's also a kind of condensed knowledge: automate the things we know
how to do into a checklist.</p>
<hr>
<p><a href="https://statmodeling.stat.columbia.edu/2018/07/03/flaws-stupid-horrible-algorithm-revealed-made-numerical-predictions/">Flaws in stupid horrible algorithm revealed because it made numerical predictions</a></p>
<hr>
<blockquote>
<p>"What accounts for the difference, says David Wootton, a historian
of science, is that alchemy was pursued in secret, while science
depended on open debate." (page 183)</p>
</blockquote>
<hr>
<blockquote>
<p>"Eventually, ProPublica <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">published</a> their conclusions. Although
the COMPAS algorithm did not use an offender's race as a predictor,
it nevertheless was producing racially disparate results. It tended
to produce false positives for black offenders (predicting that they
would re-offend, but then they did not) and false negatives for
white offenders (predicting that they would not re-offend, but then
they did).</p>
<p>"That sounds very worrying: racial discrimination is both immoral
and illegal when coming from a human; we shouldn't tolerate it if it
emerges from an algorithm.</p>
<p>"But then four academic researchers, Sam Corbett-Davies, Emma
Pierson, Avi Feller and Sharad Goel, <a href="https://arxiv.org/abs/1701.08230">pointed out</a> that the
situation wasn't so clear-cut. They used the data laboriously
assembled by ProPublica to show that the algorithm was fair by
another important metric, which was that if the algorithm gave two
criminals—one black, one white—the same risk rating, then the actual
risk that they re-offended was the saem. In that respect the
algorithm was colour-blind.</p>
<p>"What's more, the researchers showed that it was impossible for the
algorithm to be fair in both ways simultaneously. It was possible to
craft an algorithm that would give an equal rate of false positives
for all races, and it was possible to craft an algorithm where the
risk ratings matched the re-offending risk for all races, but it
wasn't possible to do both at the same time: the numbers just
couldn't be made to add up." (pages 187-188)</p>
</blockquote>
<p>At first I thought the incompatibility thing was some deep proof, but
it's unfortunately just a sad fact about empirical base rates not
being equal across groups. References:</p>
<ul>
<li><a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Machine Bias: There’s software used across the country to predict future criminals. And it’s biased against blacks.</a><ul>
<li><a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">How We Analyzed the COMPAS Recidivism Algorithm</a></li>
</ul>
</li>
<li><a href="https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/">A computer program used for bail and sentencing decisions was labeled biased against blacks. It’s actually not that clear.</a></li>
<li><a href="https://arxiv.org/abs/1701.08230">Algorithmic decision making and the cost of fairness</a></li>
<li><a href="https://arxiv.org/abs/1609.05807">Inherent Trade-Offs in the Fair Determination of Risk Scores</a></li>
</ul>
<hr>
<h3>Chapter 8: <a href="#ch8" name="ch8">Value good official statistics.</a></h3>
<p>Yes, do this.</p>
<hr>
<blockquote>
<p>"Without statistics, then, governments would fumble in ignorance.
But there is an intriguing counterargument, which is that
governments are so reliably incompetent that giving them more
information is risky: it will only encourage them.</p>
<p>"One prominent advocate of this view was Sir John Cowperthwaite. Sir
John was the financial secretary of Hong Kong throughout the 1960s,
at a time when it was still under the control of the British—and
when it was experiencing scorchingly rapid economic growth. Exactly
how rapid was hard to say, because Sir John refused to collect basic
information about Hong Kong’s economy. The economist Milton
Friedman, later to win the Nobel Memorial Prize in Economics, met
Sir John at the time and asked him why. ‘Cowperthwaite explained
that he had resisted requests from civil servants to provide such
data because he was convinced that once the data was published there
would be pressure to use them for government intervention in the
economy.’</p>
<p>"There was a logic to this. Hong Kong’s rapid growth was partly
thanks to an influx of immigrants from famine-struck communist
China, but Cowperthwaite and Friedman also believed—with some
reason—that it was flourishing thanks to a laissez-faire approach to
policy. Cowperthwaite’s government levied low taxes and provided
very little in the way of public services. The private sector, he
argued, would tend to solve people’s problems more quickly and
efficiently than the state. Why, the, collect data that would only
encourage meddling from the authorities back in London?
Cowperthwaite figured that the less London’s politicians did, the
better—and the less they knew, the less they would try to do." (page
212)</p>
</blockquote>
<p>(Cites <a href="https://blogs.lse.ac.uk/businessreview/2017/06/30/hong-kongs-postwar-transformation-shows-how-fewer-data-can-sometimes-boost-growth/">Hong Kong’s postwar transformation shows how fewer data can sometimes boost growth</a>.)</p>
<p>Also discusses <em>Seeing Like a State</em>, describing it as more
respect-local-people than free-market-is-only-good...</p>
<p>In the end he thinks bad governments do bad things despite data (or
its absence) rather than because of it.</p>
<hr>
<h3>Chapter 9: <a href="#ch9" name="ch9">Be skeptical of visualizations.</a></h3>
<hr>
<blockquote>
<p>"[Florence Nightingale] corresponded with the great Belgian
statistician Adolphe Quetelet. Quetelet was the person who
popularised the idea of taking the 'average' or 'arithmetic mean' of
a group, which was a revolutionary way to summarise complex data
with a single number." (page 233)</p>
</blockquote>
<p>Two paragraphs just taken from Wikipedia:</p>
<blockquote>
<p>"His most influential book was Sur l'homme et le développement de
ses facultés, ou Essai de physique sociale, published in 1835 (In
English translation, it is titled Treatise on Man, but a literal
translation would be "On Man and the Development of his Faculties,
or Essays on Social Physics"). In it, he outlines the project of a
social physics and describes his concept of the "average man"
(l'homme moyen) who is characterized by the mean values of measured
variables that follow a normal distribution. He collected data about
many such variables."</p>
<p>"Adolphe Quetelet also had a significant influence on Florence
Nightingale who shared with him a religious view of statistics which
saw understanding statistics as revealing the work of God in
addition to statistics being a force of good administration.
Nightingale met Quetelet in person at the 1860 International
Statistical Congress in London, and they corresponded for years
afterwards."</p>
</blockquote>
<p>So it seems from this that he was mostly popularizing quantitative
methods in the social sciences. He had some idea of the "average man"
as a kind of Platonic Ideal (see <a href="https://journalofethics.ama-assn.org/article/median-isnt-message/2013-01">Gould</a>), and (at least in the
interpretation of some) that variation around the mean is "error"...</p>
<hr>
<blockquote>
<p>"without well-defined standards for statistical record-keeping,
nothing adds up. Numbers can easily confuse us when they are
unmoored from a clear definition." (page 235)</p>
</blockquote>
<hr>
<blockquote>
<p>"Trends and patterns will often leap out immediately if plotted in
the right way. For example, visualization expert Robert Kosara
suggests plotting linear data on a spiral. If there's a periodic
pattern to the data—say, repeating every seven days or every three
months—that may be concealed by other fluctuations in a conventional
plot but will leap out in a spiral plot." (page 241)</p>
</blockquote>
<p>See:</p>
<ul>
<li><a href="http://stat-computing.org/newsletter/issues/scgn-22-1.pdf">Visualization: It’s More than Pictures!</a></li>
<li><a href="https://eagereyes.org/blog/2011/information-visualization-vs-statistical-graphics">Information Visualization vs. Statistical Graphics</a></li>
<li><a href="https://eagereyes.org/techniques/spirals">Spirals for Periodic Data</a></li>
</ul>
<p>The main example offered is a weekly pattern, which I think could be
visualized with a calendar plot (like on Github, or as in
<a href="http://bl.ocks.org/ajschumacher/5127001">here</a>).</p>
<hr>
<p><a href="https://www.infoworld.com/article/3088166/why-how-to-lie-with-statistics-did-us-a-disservice.html">Lies, damn lies, and statistics: How to take something positive from the UK’s EU referendum campaign</a></p>
<p>The slug for this article is
"why-how-to-lie-with-statistics-did-us-a-disservice" which isn't
mentioned in the article itself, but is a sentiment Harford presents
early in his book.</p>
<hr>
<h3>Chapter 10: <a href="ch10" name="ch10">Keep an open mind.</a></h3>
<hr>
<blockquote>
<p>"The statistical lens is indeed powerful. Still, I hope that I have
convinced you that for any problem, it takes more than mere numbers
to make the world add up." (page 276)</p>
</blockquote>
<hr>
<blockquote>
<p>"This book has argued that it is possible to gather and to analyse
numbers in ways that help us understand the world. But it has also
argued that very often we make mistakes not because the data aren't
available, but because we refuse to accept what they are telling
us." (pages 277-278)</p>
</blockquote>
<hr>
<h3>Golden rule: <a href="#golden" name="golden">Be curious.</a></h3>
<hr>
<ul>
<li><a href="https://www.vox.com/science-and-health/2017/2/1/14392290/partisan-bias-dan-kahan-curiosity">There may be an antidote to politically motivated reasoning. And it’s wonderfully simple.</a></li>
<li><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/pops.12396">Science Curiosity and Political Information Processing</a></li>
</ul>
<blockquote>
<p>"The scientifically curious people Kahan's team studied were
originally identified with simple questions, buried in a marketing
survey so that people weren't conscious that their curiosity was
being measured. One question, for example, was 'How often do you
read science books?' Scientifically curious people are more
interested in watching a documentary about space travel or penguins
than a basketball game or a celebrity gossip show." (pages 283-284)</p>
</blockquote>
<hr>
<blockquote>
<p>"A surprising statistical claim is a challenge to our existing
world-view. It may provoke an emotional response—even a fearful one.
Neuroscientific studies <a href="https://www.nature.com/articles/srep39589">suggest</a> that the brain responds in much
the same anxious way to facts which threaten our preconceptions as
it does to wild animals which threaten our lives. Yet for someone in
a curious frame of mind, in contrast, a surprising claim need not
provoke anxiety. It can be an engaging mystery, or a puzzle to
solve." (page 285)</p>
</blockquote>
<hr>
<ul>
<li><a href="https://www.amazon.com/Knowledge-Illusion-Never-Think-Alone/dp/039918435X">The Knowledge Illusion</a></li>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3062901/">The misunderstood limits of folk science: an illusion of explanatory depth</a></li>
<li><a href="https://journals.sagepub.com/doi/abs/10.1177/0956797612464058">Political Extremism Is Supported by an Illusion of Understanding</a></li>
</ul>
<p>Abstract for that last one:</p>
<blockquote>
<p>"People often hold extreme political attitudes about complex
policies. We hypothesized that people typically know less about such
policies than they think they do (the illusion of explanatory depth)
and that polarized attitudes are enabled by simplistic causal
models. Asking people to explain policies in detail both undermined
the illusion of explanatory depth and led to attitudes that were
more moderate (Experiments 1 and 2). Although these effects occurred
when people were asked to generate a mechanistic explanation, they
did not occur when people were instead asked to enumerate reasons
for their policy preferences (Experiment 2). Finally, generating
mechanistic explanations reduced donations to relevant political
advocacy groups (Experiment 3). The evidence suggests that people’s
mistaken sense that they understand the causal processes underlying
policies contributes to political polarization."</p>
</blockquote>
<hr>
<p><a href="https://www.pnas.org/content/111/Supplement_4/13614">Using narratives and storytelling to communicate science with nonexpert audiences</a></p>
<blockquote>
<p>"Although storytelling often has negative connotations within
science, narrative formats of communication should not be
disregarded when communicating science to nonexpert audiences.
Narratives offer increased comprehension, interest, and engagement.
Nonexperts get most of their science information from mass media
content, which is itself already biased toward narrative formats.
Narratives are also intrinsically persuasive, which offers science
communicators tactics for persuading otherwise resistant audiences,
although such use also raises ethical considerations. Future
intersections of narrative research with ongoing discussions in
science communication are introduced."</p>
</blockquote>    
    ]]></description>
<link>http://planspace.org/20210330-how_to_make_the_world_add_up_by_harford/</link>
<guid>http://planspace.org/20210330-how_to_make_the_world_add_up_by_harford/</guid>
<pubDate>Tue, 30 Mar 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Everybody Lies, by Stephens-Davidowitz</title>
<description><![CDATA[

<p>I finally read my copy of this <a href="http://sethsd.com/everybodylies">book</a>, which is a final form of the
author's collected <a href="http://sethsd.com/research">research</a> using "non-traditional" data, chiefly
Google search data. The contribution of <a href="https://twitter.com/natesilver538/status/703975062500732932">racism</a> to Trump's election
is a headline claim. I don't know that I'm as optimistic as the author
that these techniques all yield uniformly stronger claims than
"conventional" research.</p>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"As if the tradeoff between tractability and richness weren't bad
enough, scientists of human nature are vexed by the Law of Small
Numbers–Amos Tversky and Daniel Kahneman's name for the fallacy of
thinking that the traits of a population will be reflected in any
sample, no matter how small." (page x, in the foreword by Steven
Pinker)</p>
</blockquote>
<hr>
<blockquote>
<p>"The true divide [of racism in the US], Google search data
suggested, was not South versus North; it was East versus West. You
don't get this sort of thing much west of the Mississippi." (pages
7-8)</p>
</blockquote>
<hr>
<blockquote>
<p>"I am now convinced that Google searches are the most important
dataset ever collected on the human psyche." (page 14)</p>
</blockquote>
<hr>
<blockquote>
<p>"At Google, major decisions are based on only a tiny sampling of all
their data." (page 21)</p>
</blockquote>
<p>This is citing Hal Varian's <a href="https://www.aeaweb.org/articles?id=10.1257/jep.28.2.3">Big Data: New Tricks for Econometrics</a>.</p>
<hr>
<blockquote>
<p>"Good data science is less complicated than people think. The best
data science is, in fact, surprisingly intuitive." (page 26)</p>
</blockquote>
<hr>
<blockquote>
<p>"If you can't understand a study, the problem is probably with the
study, not with you." (page 27)</p>
</blockquote>
<hr>
<blockquote>
<ol>
<li>"Offering up new types of data is the first power of Big Data."</li>
<li>"Providing honest data is the second power of Big Data."</li>
<li>"Allowing us to zoom in on small subsets of people is the third
   power of Big Data."</li>
<li>"Allowing us to do many causal experiments is the fourth power of
   Big Data." (pages 53-54)</li>
</ol>
</blockquote>
<hr>
<p>On page 57 he mentions "<a href="https://research.google/pubs/pub41695/">Google Correlate</a>," which seems neat
("Google Trends in reverse") and was publicly available from 2011 to
2019.</p>
<hr>
<blockquote>
<p>"The Big Data revolution is less about collecting more and more
data. It is about collecting the right data." (page 62)</p>
</blockquote>
<hr>
<blockquote>
<p>"First, and perhaps most important, if you are going to try to use
new data to revolutionize a field, it is best to go into a field
where old methods are lousy."</p>
</blockquote>
<p>He's going through a sort of "Moneyball for X" survey of people:</p>
<ul>
<li>Horse racing: Jeff Seder</li>
<li>Wine: Orley Ashenfelter</li>
</ul>
<blockquote>
<p>"The second lesson is that, when trying to make predictions, you
needn't worry too much about why your models work."</p>
<p>"The final lesson to be learned from Seder's successful attempt to
predict a potential Triple Crown winner is that you have to be open
and flexible in determining what counts as data." (pages 71-74)</p>
</blockquote>
<hr>
<p>On page 91, he references a <a href="https://epjdatascience.springeropen.com/articles/10.1140/epjds/s13688-016-0093-1" title="The emotional arcs of stories are dominated by six basic shapes">study</a> that provides quantitative
evidence for Vonnegut's <a href="https://www.youtube.com/watch?v=oP3c1h8v2ZQ&amp;ab_channel=DavidComberg">Shapes of Stories</a>.</p>
<hr>
<blockquote>
<p>""About one-third of the time, people lie in real life," he
suggests. "The habits carry over to surveys."" (page 107, quoting
Roger Tourangeau)</p>
</blockquote>
<hr>
<blockquote>
<p>"Another reason for lying is simply to mess with surveys. This is a
huge problem for any research regarding teenagers, fundamentally
complicating our ability to understand this age group. Researchers
originally found a correlation between a teenager's being adopted
and a variety of negative behaviors, such as using drugs, drinking
alcohol, and skipping school. In subsequent research, they found
this correlation was entirely explained by the 19 percent of
self-reported adopted teenagers who weren't actually adopted.
Follow-up research has found that a meaningful percent of teenagers
tell surveys they are more than seven feet tall, weigh more than
four hundred pounds, or have three children. One survey found 99
percent of students who reported having an artificial limb to
academic researchers were kidding." (page 108)</p>
</blockquote>
<hr>
<blockquote>
<p>"He has always known he was attracted to men, he says, but thought
that this was universal and something that all men just hid." (page
119)</p>
</blockquote>
<p>This kind of thing is fascinating to me–private conspiracy theories
that are self-protecting and secretly mislead those who form them. I
imagine that many racist people, "proud boys," etc. believe that most
people agree with them but hide their belief. See also expressions
like "He's saying what we're all thinking," which is a statement that is difficult to verify.</p>
<hr>
<blockquote>
<p>"One thing that does not seem to matter
[for explaining Trump support]: economics." (page 139)</p>
</blockquote>
<hr>
<p>Around page 144, he's talking about how the internet is less
segregated than you might think, in terms of people of all political
persuasions reading the most popular news sites and so on. He points
out also that "a surprising amount of the information people get on
Facebook comes from people with opposing views." This makes me wonder
how much the perception/reality of increased polarization is <em>caused
by</em> more communication and exposure to different views. If I never
hear about my aunt's crazy beliefs, I'm less likely to get upset about
them and feel like I need to advocate against them. Maybe hearing
about anti-racism makes some people more racist? Hmm.</p>
<hr>
<blockquote>
<p>"I think it's safe to say that the Great Recession did make child
abuse worse, although the traditional measures did not show it."
(page 147)</p>
</blockquote>
<hr>
<blockquote>
<p>"We can't blindly trust government data. The government may tell us
that child abuse or abortion has fallen and politicians may
celebrate this achievement. But the results we think we're seeing
may be an artifact of flaws in the methods of collection. The truth
may be different–and sometimes, far darker." (pages 149-150)</p>
</blockquote>
<p>This is not a critique that is specific to government data...</p>
<hr>
<blockquote>
<p>"Digital truth serum has revealed an abiding interest in judging
people based on their looks; the continued existence of millions of
closeted gay men; a meaningful percentage of women fantasizing about
rape; widespread animus against African-Americans; a hidden child
abuse and self-induced abortion crisis; and an outbreak of violent
Islamophobic rage that only got worse when the president appealed
for tolerance." (page 158)</p>
</blockquote>
<hr>
<blockquote>
<p>"First, there can be comfort in knowing that you are not alone in
your insecurities and embarrassing behavior."</p>
<p>"The second benefit of digital truth serum is that it alerts us to
people who are suffering."</p>
<p>"The final–and, I think, most powerful–value in this digital truth
serum is indeed its ability to lead us from problems to solutions."
(pages 158-162)</p>
</blockquote>
<hr>
<blockquote>
<p>"Recall that Chetty's team was trying to figure out what areas are
good at allowing people to reach the upper middle class. My study
was trying to figure out what areas are good at allowing people to
reach fame. The results are strikingly different." (page 184)</p>
</blockquote>
<p>This is sort of an interesting look at success for the masses versus
success for the few, or at least at different levels/types of
"success"... A possible hypothesis might be that the two should go
together (more general success, more peak success) but that doesn't
seem to be the case. The ideas of success may be too different?</p>
<hr>
<blockquote>
<p>"On a given day in some schools in rural India, more than 40 percent
of teachers are absent." (page 209)</p>
</blockquote>
<p>That's referencing <a href="https://economics.mit.edu/files/5582">Incentives Work: Getting Teachers to Come to School</a>, which has this abstract:</p>
<blockquote>
<p>"We use a randomized experiment and a structural model to test
whether monitoring and financial incentives can reduce teacher
absence and increase learning in India. In treatment schools,
teachers’ attendance was monitored daily using cameras, and their
salaries were made a nonlinear function of attendance. Teacher
absenteeism in the treatment group fell by 21 percentage points
relative to the control group, and the children’s test scores
increased by 0.17 standard deviations. We estimate a structural
dynamic labor supply model and find that teachers respond strongly
to financial incentives. Our model is used to compute
cost-minimizing compensation policies."</p>
</blockquote>
<hr>
<blockquote>
<p>"Many economists previously leaned toward the view that leaders
largely were impotent figureheads pushed around by external forces.
Not so, according to Jones and Olken's analysis of nature's
experiment." (page 228)</p>
</blockquote>
<p>That's referencing <a href="https://economics.mit.edu/files/3055">Hit or Miss? The Effect of Assassinations on Institutions and War</a>, which has this abstract:</p>
<blockquote>
<p>"Assassinations are a persistent feature of the political landscape.
Using a new dataset of assassination attempts on all world leaders
from 1875 to 2004, we exploit inherent randomness in the success or
failure of assassination attempts to identify the effects of
assassination. We find that, on average, successful assassinations
of autocrats produce sustained moves toward democracy. We also find
that assassinations affect the intensity of small-scale conflicts.
The results document a contemporary source of institutional change,
inform theories of conflict, and show that small sources of
randomness can have a pronounced effect on history."</p>
</blockquote>
<p>Kind of an interesting analysis for <a href="https://en.wikipedia.org/wiki/Great_man_theory">the great man theory</a>...</p>
<hr>
<p>Some discussion around page 238 of the (non-)benefit of going to
Harvard etc... It's more useful to be the kind of person who <em>could</em>
go to Harvard (get in, etc.) - the perceived incremental benefit of
going to Harvard vs. some other school may not be real.</p>
<hr>
<blockquote>
<p>"Generally, if someone tells you he will pay you back, he will not
pay you back." (page 259)</p>
</blockquote>
<p>This is about people writing on microfinance sites. Sounds about
right; interesting to see quantitative support for this kind of thing.</p>
<hr>
<blockquote>
<p>"social science is becoming a real science."</p>
</blockquote>
<p>He says this is the "big point" of his book...</p>
<hr>
<p>Strong praise for Jawbone on page 277, which turned out to be bad
timing as the company went under the year the book came out (2017)...</p>
<hr>
<p>On page 283 there's a reference to Ellenberg's <a href="https://en.wikipedia.org/wiki/Hawking_Index">Hawking Index</a>,
which was amusing to me because I've enjoyed following Ellenberg a
little bit since reading his <a href="/20200925-how_not_to_be_wrong_by_ellenberg/">How Not to Be Wrong</a>.</p>    
    ]]></description>
<link>http://planspace.org/20210314-everybody_lies_by_stephens-davidowitz/</link>
<guid>http://planspace.org/20210314-everybody_lies_by_stephens-davidowitz/</guid>
<pubDate>Sun, 14 Mar 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Intuition, action, and luck (and Harry Potter)</title>
<description><![CDATA[

<p>When work is going well, it feels good. It feels playful. Not like
following a plan or map, but exploring freely with only the loosest
sense of a destination in mind, until you find you've solved your
problem. It feels <a href="https://www.youtube.com/watch?v=sn72qYmsWco">like</a> the <a href="https://harrypotter.fandom.com/wiki/Felix_Felicis">luck potion</a> from the Harry Potter
world:</p>
<blockquote>
<p>“What does it feel like?” whispered Hermione.</p>
<p>Harry did not answer for a moment. Then, slowly but surely, an
exhilarating sense of infinite opportunity stole through him; he
felt as though he could have done anything, anything at all . . .
and getting the memory from Slughorn seemed suddenly not only
possible, but positively easy. . . .</p>
<p>He got to his feet, smiling, brimming with confidence.</p>
<p>“Excellent,” he said. “Really excellent. Right . . . I’m going down
to Hagrid’s.”</p>
<p>...</p>
<p>Why he knew that going to Hagrid’s was the right thing to do, he had
no idea. It was as though the potion was illuminating a few steps of
the path at a time: He could not see the final destination, he could
not see where Slughorn came in, but he knew that he was going the
right way to get that memory. When he reached the entrance hall he
saw that Filch had forgotten to lock the front door. Beaming, Harry
threw it open and breathed in the smell of clean air and grass for a
moment before walking down the steps into the dusk.</p>
<p>It was when he reached the bottom step that it occurred to him how
very pleasant it would be to pass the vegetable patch on his walk to
Hagrid’s. It was not strictly on the way, but it seemed clear to
Harry that this was a whim on which he should act, so he directed
his feet immediately toward the vegetable patch, where he was
pleased, but not altogether surprised, to find Professor Slughorn in
conversation with Professor Sprout. Harry lurked behind a low stone
wall, feeling at peace with the world and listening to their
conversation.</p>
</blockquote>
<p>It's good to have this sense of "feeling at peace with the world" and
trying things even when you don't know for sure, consciously, how
they'll help. It's following your intuition in the sense of
<a href="/20210116-pragmatic_thinking_and_learning/">Pragmatic Thinking and Learning</a>.</p>
<p>It's also doing things because of "how very pleasant" they could be.
It's a bias toward action–playful action–and trying things that are
<a href="/20181204-worth_doing_even_if_it_fails/">worth doing even if they fail</a>.</p>
<p>There aren't any luck potions, but <a href="https://www.instituteforgiving.org/resources-for-fundraisers/fundraising-verities/item/313-verities-65-luck-favors-the-prepared-mind">luck favors the prepared mind</a>.
This kind of intuition-guided flow state isn't a consistent method,
but it's nice when it happens.</p>    
    ]]></description>
<link>http://planspace.org/20210227-intuition_action_and_luck_and_harry_potter/</link>
<guid>http://planspace.org/20210227-intuition_action_and_luck_and_harry_potter/</guid>
<pubDate>Sat, 27 Feb 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Vision and Mission</title>
<description><![CDATA[

<h3>Increasing the awareness of the universe</h3>
<p>I build and share understanding of the world to improve life for the
people I love most, and for everyone. I learn from others and from the
world, communicating and educating in turn to engage growth. I build
systems that contribute to these processes. I make improvements every
day to myself, my relationships, and the world around me.</p>
<hr>
<p>I was <a href="https://smile.amazon.com/gp/product/1642500267/">inspired</a> to "refine" my personal <a href="https://en.wikipedia.org/wiki/Mission_statement">mission</a> statement, but
I had to make one first. I like brief <a href="https://en.wikipedia.org/wiki/Vision_statement">vision</a> statements so I came
up with one of those as well.</p>
<p>I particularly like the vision, which can include lots of things I'm
interested in, including research, data science, and education.
There's a connection to <a href="https://westcoastword.wordpress.com/2013/04/22/chapter-7-the-purpose-of-life-from-breakfast-of-champions-by-kurt-vonnegut/">Vonnegut</a> as well:</p>
<pre>
What is the purpose of life?

To be
the eyes
and ears
and conscience
of the Creator of the Universe,
you fool.
</pre>    
    ]]></description>
<link>http://planspace.org/20210226-vision_and_mission/</link>
<guid>http://planspace.org/20210226-vision_and_mission/</guid>
<pubDate>Fri, 26 Feb 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Elementary Presidents of the US Nations</title>
<description><![CDATA[

<p>There are 10 two-letter codes that correspond to both <a href="https://en.wikipedia.org/wiki/List_of_U.S._state_and_territory_abbreviations">US states</a>
and ISO 3166 <a href="https://www.iso.org/iso-3166-country-codes.html">country codes</a> and (lowercasing the second letter) an
element from the <a href="https://ptable.com/">periodic table</a> with atomic number corresponding
to a <a href="https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States">US president</a>.</p>
<p><a href="https://docs.google.com/spreadsheets/d/1iv8Wdui64jiDkrM3fo5UFzhYFaXdvrl-O1vbJ8nEgYk/edit?usp=sharing"><img alt="table" src="table.png"></a></p>
<p>See all 324 data rows <a href="https://docs.google.com/spreadsheets/d/1iv8Wdui64jiDkrM3fo5UFzhYFaXdvrl-O1vbJ8nEgYk/edit?usp=sharing">as a Google Sheet</a>, or sources and processing
in the <a href="https://github.com/ajschumacher/ajschumacher.github.io/tree/master/20210225-elementary_presidents_of_the_us_nations">README</a>.</p>    
    ]]></description>
<link>http://planspace.org/20210225-elementary_presidents_of_the_us_nations/</link>
<guid>http://planspace.org/20210225-elementary_presidents_of_the_us_nations/</guid>
<pubDate>Thu, 25 Feb 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>Microphones matter</title>
<description><![CDATA[

<table>
<tr>

<td>
MacBook Air built-in mic
<audio controls src="computer_mic.mp3"></audio>
</td>

<td>
Apple wired headphone mic
<audio controls src="wired_apple_headphone_mic.mp3"></audio>
</td>

</tr>
<tr>

<td>
Bose QC35 II wireless headphone mic
<audio controls src="wireless_headphone_mic.mp3"></audio>
</td>

<td>
Blue Yeti USB mic
<audio controls src="new_mic.mp3"></audio>
</td>

</tr>
</table>

<p>These sound different! The laptop mic has <em>tons</em> of room noise. I
think the Bose headphones are trying hard to do clever signal
processing which reduces background noise but also makes my voice more
muted and a little robotic in places. The Yeti is pretty good but
still picks up some unintended nearby sounds despite being in
directional mode.</p>    
    ]]></description>
<link>http://planspace.org/20210218-microphones_matter/</link>
<guid>http://planspace.org/20210218-microphones_matter/</guid>
<pubDate>Thu, 18 Feb 2021 12:00:00 -0500</pubDate>
</item>
<item>
<title>The Big Con, by Maurer</title>
<description><![CDATA[

<p>Published in 1940, WWI was "the War" (page 28), WWII was "the present
European War" (page 311), there were thousand-dollar <a href="https://www.investopedia.com/6-famous-discontinued-and-uncommon-u-s-currency-denominations-4773302#1000-bill">G-notes</a>, and
there was quite a lot of sexism and racism (throughout). Instead of
<a href="https://en.wikipedia.org/wiki/Advance-fee_scam">emails from Nigerian princes</a>, you might see a classified ad in the
paper "For an honest, reliable businessman with $20,000 to invest for
a large return." (page 115) There were elaborate plots! Would you
really not fall for anything like that? What are people falling for
these days? Quite a lot! What a world, what a world.</p>
<p><img alt="cover" src="cover.jpg"></p>
<hr>
<blockquote>
<p>"After all, a look around present-day American institutions should
suffice to demonstrate that the character in question has now fully
emerged from the underworld and entered the mainstream, where he may
be far less colorful and imaginative, but no less on the grift."
(page xv, from the introduction by Luc Sante)</p>
</blockquote>
<hr>
<blockquote>
<p>"Their methods differ more in degree than in kind from those
employed by more legitimate forms of business." (page 3)</p>
</blockquote>
<hr>
<blockquote>
<p>"The three big-con games, the <em>wire</em>, the <em>rag</em>, and the <em>pay-off</em>."
(page 3)</p>
</blockquote>
<ul>
<li><em>the wire</em>: "A big-con game in which the insideman (passing as a
   Western Union official) convinces the mark that he can delay the
   race results going to the book-makers long enough for the mark to
   place a bet after the race is run. The roper makes a mistake and
   the mark loses."</li>
<li><em>the rag</em>: "An intricate big-con game very similar to the pay-off,
   except that stocks are used instead of races. The insideman poses
   as an agent for a broker's syndicate which is trying to break the
   bucket-shops. The mark profits on several investments, is sent for
   a large sum of money, and is fleeced."</li>
<li><em>the pay-off</em>: "The most lucrative of all big-con games, with
   touches running from $10,000 up, with those of $100,000 being
   common. It operates on the principle that a wealthy mark is induced
   to believe that he has been taken into a deal whereby a large
   racing syndicate is to be swindled. At first he pays with money
   furnished him by the confidence men, then is put on the send for
   all the cash he can raise, fleeced, and blown off. The pay-off
   (invented in 1906) evolved from the short-pay at the track and was
   fully developed by 1910, when the big stores appeared in many of
   the larger cities."</li>
</ul>
<hr>
<blockquote>
<p>"Most marks come from the upper strata of society, which, in
America, means that they have made, married, or inherited money.
Because of this, they acquire status which in time they come to
attribute to some inherent superiority, especially as regards
matters of sound judgment in finance and investment. Friends and
associates, themselves social climbers and sycophants, help to
maintain this illusion of superiority. Eventually, the mark comes to
regard himself as a person of vision and even of genius. Thus a
Babbitt who has cleared half a million in a real-estate development
easily forgets the part which luck and chicanery have played in his
financial rise; he accepts his mantle of respectability without
question; he naïvely attributes his success to sound business
judgment. And any confidence man will testify that a real-estate man
is the fattest and juiciest of suckers." (page 104)</p>
</blockquote>
<hr>
<blockquote>
<p>"Religious scruples often seem to fail a mark at the crucial
moment." (page 105)</p>
</blockquote>
<hr>
<blockquote>
<p>""Larceny," or thieves' blood, runs not only in the veins of
professional thieves; it would appear that humanity at large has
just a dash of it–and sometimes more." (page 117)</p>
</blockquote>
<hr>
<blockquote>
<p>"Many con men feel that marks have one characteristic in common–they
are all liars." (page 118)</p>
</blockquote>
<hr>
<blockquote>
<p>"Such institutions [schools for grifters] have long been the delight
of fictioneers, but there is no reliable evidence to indicate that
they ever functioned in the American underworld." (page 160)</p>
</blockquote>
<hr>
<p>The author references on page 164 "Dan the Dude's place at 28 W. 28th
St." as being a hangout for con men. It has been otherwise known as
well, <a href="https://ephemeralnewyork.wordpress.com/tag/28-west-28th-street/">it seems</a>.</p>
<hr>
<blockquote>
<p>"When we think of cheese, it's Wisconsin; when we speak of oil, it's
Pennsylvania; but with grifters, it's Indiana." (page 173)</p>
</blockquote>
<hr>
<blockquote>
<p>"If fifty of them [con men] were selected and mixed indiscriminately
with a group of successful business and professional men, all the
correlations and statistics of a Hooton or a Lombroso would not set
them apart; and, if a census of opinions upon politics, ethics,
religion, or what-not were taken from the entire group, not even a
Solomon could separate the sheep from the goats on the basis of
their social views. If confidence men operate outside the law, it
must be remembered that they are not much further outside than many
of our pillars of society who go under names less sinister. They
only carry to an ultimate and very logical conclusion certain trends
which are often inherent in various forms of legitimate business."
(pages 178-179)</p>
</blockquote>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Earnest_Hooton">Earnest Hooton</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cesare_Lombroso">Cesare Lombroso</a></li>
</ul>
<hr>
<blockquote>
<p>"The <em>short deck</em>. A short-con game operated by a man who drops one
card out of a deck he has offered to sell a mark very cheaply. They
argue over whether or not it is a full deck, then bet. The mark
thinks the deck is short one card, but the operator produces a full
deck." (page 304)</p>
</blockquote>
<hr>
<blockquote>
<p>"... a booming campaign of propaganda designed to rob the criminal
of the sympathetic public opinion he has for so long enjoyed." (page
312, with "federal operatives" behind this campaign)</p>
</blockquote>
<hr>
<h3>Just words</h3>
<ul>
<li><em>appurtenance</em>: an accessory or other item associated with a
   particular activity or style of living</li>
<li><em>blackjack</em>: a short, leather-covered, typically lead-filled club
   with a flexible handle, used as a weapon</li>
<li><em>cackle-bladder</em>: a <a href="https://en.wikipedia.org/wiki/Cackle-bladder">means</a> of faking someone's death through the
   use of a rubber bladder filled with fake blood</li>
<li><em>chary</em>: cautiously or suspiciously reluctant to do something</li>
<li><em>charwoman</em>: a woman employed to clean houses or offices</li>
<li><em>chestnut</em>: a joke or story that has become tedious because of its
   age and constant repetition</li>
<li><em>chicane</em>: (from context) down on one's luck, broke, from (in card
   games) a hand without cards of one particular suit; a void</li>
<li><em>chicanery</em>: the use of trickery to achieve a political, financial,
   or legal purpose</li>
<li><em>connivance</em>: willingness to secretly allow or be involved in
   wrongdoing, especially an immoral or illegal act (as "with the
   connivance of officials")</li>
<li><em>crotchet</em>: a perverse or unfounded belief or notion</li>
<li><em>cupidity</em>: greed for money or possessions</li>
<li><em>demimonde</em>: (in 19th-century France) the class of women considered
   to be of doubtful morality and social standing; a group of people
   considered to be on the fringes of respectable society</li>
<li><em>depredation</em>: an act of attacking or plundering</li>
<li><em>diddle</em>: cheat or swindle (someone) so as to deprive them of
   something; deliberately falsify (something)</li>
<li><em>dissimulation</em>: concealment of one's thoughts, feelings, or
   character; pretense</li>
<li><em>doggerel</em>: comic verse composed in irregular rhythm; verse or
   words that are badly written or expressed</li>
<li><em>entomology</em>: the branch of zoology concerned with the study of
   insects</li>
<li><em>Faro</em>: <a href="https://en.wikipedia.org/wiki/Faro_(card_game)">a specific old card game</a></li>
<li><em>fourflusher</em>: (a person who does this) (in poker) bluff when
   holding a weak hand, particularly a four flush; keep up a pretense;
   bluff</li>
<li><em>Gesamtkunstwerk</em>: a work of art that makes use of all or many art
   forms or strives to do so</li>
<li><em>hare-lip</em>: another term for cleft lip/palate</li>
<li><em>hep</em>: archaic or dialect term for "hip" in the sense of "wise"</li>
<li><em>inveigh</em>: speak or write about (something) with great hostility</li>
<li><em>larceny</em>: theft of personal property</li>
<li><em>much lost motion</em>: inefficiency, wasted busywork</li>
<li><em>obdurate</em>: stubbornly refusing to change one's opinion or course
   of action</li>
<li><em>obstreperous</em>: noisy and difficult to control</li>
<li><em>picaresque</em>: relating to an episodic style of fiction dealing with
   the adventures of a rough and dishonest but appealing hero</li>
<li><em>piker</em>: a gambler who makes only small bets; a stingy or cautious
   person</li>
<li><em>plunger</em>: a person who gambles or spends money recklessly</li>
<li><em>Pullman</em>: (car, couch, case) associated with a railroad car
   affording special comfort, especially one with sleeping berths</li>
<li><em>q.v.</em>: "quod videās" (Latin) "which see" after something to refer
   to additional information for</li>
<li><em>ribald</em>: referring to sexual matters in an amusingly coarse or
   irreverent way</li>
<li><em>roister</em>: enjoy oneself or celebrate in a noisy or boisterous way</li>
<li><em>scapegrace</em>: a mischievous or wayward person, especially a young
   person or child; a rascal</li>
<li><em>shill</em>: an accomplice of a hawker, gambler, or swindler who acts
   as an enthusiastic customer to entice or encourage others (also
   "shillaber")</li>
<li><em>tout</em>: a person soliciting custom or business, typically in an
   aggressive or bold manner; a person who offers racing tips for a
   share of any resulting winnings</li>
<li><em>venire</em>: an entire panel from which a jury is drawn</li>
<li><em>winchell</em>: a confidence trickster’s victim, a sucker (from the
   image of gossip writer Walter Winchell as ‘swallowing’ any story)</li>
</ul>    
    ]]></description>
<link>http://planspace.org/20210214-the_big_con_by_maurer/</link>
<guid>http://planspace.org/20210214-the_big_con_by_maurer/</guid>
<pubDate>Sun, 14 Feb 2021 12:00:00 -0500</pubDate>
</item>
  </channel>
</rss>
