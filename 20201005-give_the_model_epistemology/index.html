<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/styles/csshake.min.css">
    <link rel="stylesheet" type="text/css" href="/styles/zenburn.css">
    <link rel="stylesheet" type="text/css" href="/styles/planspace.css">
    <title>Give the model epistemology</title>
  </head>
  <body>
    <article>
<h1>Give the model epistemology</h1>
<p class="date">Monday October  5, 2020</p>
<p>Jaskie has a nice paper with
<a href="https://ieeexplore.ieee.org/document/9048765">A Modified Logistic Regression for Positive and Unlabeled Learning</a>.
I like that it extends the usual logistic function in a way that
captures the idea that labels may be incorrect. I wonder about
extending the idea to multi-class softmax, and its relationship with
label smoothing.</p>
<p>Here's the usual <a href="https://en.wikipedia.org/wiki/Logistic_function">logistic function</a>.</p>
<p>\[ \frac{ 1 }{ 1 + e^{-x} } \tag{1} \]</p>
<p>What Jaskie does is introduce another term in the denominator:</p>
<p>\[ \frac{ 1 }{ 1 + b^2 + e^{-x} } \tag{2} \]</p>
<p>The \( b \) term is squared to be non-negative, and learned during
model fitting. The effect is that the maximum score for a positive
example is less than one.</p>
<p>This makes sense in the positive unlabeled setting because Jaskie
differentiates between whether an example <em>is</em> positive and whether an
example is <em>labeled</em> positive. We only have the labels, and we know
that some positive examples may not be positively labeled, so the
probability based on the example that it is positively labeled is less
than one.</p>
<p>It's somewhat surprising that this seems to work quite well, as
demonstrated (for example) in Jaskie's Figure 6. (SLR is Standard
Logistic Regression, MLR is Jaskie's Modified Logistic Regression.)</p>
<p><img alt="Figure 6" src="figure_6.png" /></p>
<p>Let's speculate about extending this idea to the multi-class setting.
First, just moving things around, Equation 2 becomes Equation 3.</p>
<p>\[ \frac{ e^x }{ (1 + b^2) e^x + 1 } \tag{3} \]</p>
<p>That form makes it easy to see the analogy between the usual logistic
function and the multi-class <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a>. Then the natural thing to
suggest is Equation 4.</p>
<p>\[ \frac{ e^{x_i} }{ \sum (1 + b_i^2) e^{x_i} } \tag{4} \]</p>
<p>The semi-supervised setting in which there's a pile of unlabeled data
in addition to the labeled data is pretty common, especially when
labeling is expensive, and if something relatively simple like this
were to give similar performance benefits to Jaskie's binary case, it
could easily become very popular. (Assume you have a "garbage" class
as well, in the <a href="https://paperswithcode.com/task/open-set-learning">open set</a> sense.)</p>
<p>There's probably a similar extension to keep the negative example
scores from going all the way to zero, if you think some of the true
negatives might have incorrectly positive labels (or otherwise wrong
labels in the multi-class setting).</p>
<p>I wonder about the relationship between these techniques and
<a href="https://arxiv.org/abs/1906.02629">label smoothing</a>... With smoothed labels you still have fixed (or
at least sort of balanced) target probabilities, whereas the above
techniques allow learning where the targets should be... But I think
you wouldn't get the limits on logit growth, with the above
techniques... It would be neat if the above techniques gave you good
calibration <em>and</em> informative logits in the distillation sense. Hmm!</p>
<!-- mathjax for formulas -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
    </article>
    <footer>
      <hr />
<p><a name="contact"></a><form class="email_updates">
  <input type="email" name="email" placeholder="your@email.address" style="width: 49%" />
  <input type="submit" value="Get monthly updates" style="width: 49%" />
  <input type="hidden" name="_subject" value="planspace.org updates list" />
  <input type="text" name="_honey" style="display:none" />
  <input type="hidden" name="_captcha" value="false" />
</form></p>
<p><a id="back_link2" href="/">This site</a> also has <a href="/rss.xml">RSS</a>. You can connect with <a id="aaron_link2" href="/aaron/">me</a> via <a href="https://twitter.com/planarrowspace">Twitter</a>, <a href="https://www.linkedin.com/in/ajschumacher">LinkedIn</a>, <a href="https://github.com/ajschumacher">GitHub</a>, and <a href="mailto:aaron@planspace.org">email</a>.</p>

      <hr />
    </footer>

<!-- my weird stuff -->
<script src="/scripts/planspace.js"></script>

<!-- syntax highlighting -->
<script src="/scripts/highlight.pack.js"></script>
<script type="text/javascript">hljs.initHighlightingOnLoad();</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-44351009-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Disqus comments -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'planspace';
  (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  </body>
</html>
