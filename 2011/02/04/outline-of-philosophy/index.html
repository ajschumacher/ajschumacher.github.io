<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/styles/csshake.min.css">
    <link rel="stylesheet" type="text/css" href="/styles/zenburn.css">
    <link rel="stylesheet" type="text/css" href="/styles/planspace.css">
    <title>Outline of a Philosophy</title>
  </head>
  <body>
    <article>
<h1>Outline of a Philosophy</h1>
<p class="date">Friday February  4, 2011</p>
<p>There's a book I've been meaning to read, called "What we believe but cannot prove."  I've been thinking about what the heck I believe.  I wanted to find some foundation of certainty from which I could build, as mathematical axioms give rise to whole systems of mathematics.  Descartes did a similar thing, hence "Je pense donc je suis" - I think therefore I am.  But I have reason to doubt that, and while I have retained it in a sort of altered form as a kind of crutch or justification for (1), what I have found in the end as my deepest foundation of belief is the idea that nothing can be known for certain.  Including that very belief.  It occurs to me that this may not be satisfying to everyone.  Somehow, it seems to be satisfying me.  It resonates with what I have heard from others, from romanticized versions of "Eastern philosophy", to Douglas Adams' "42", to perhaps even Kant's "Refutation of Idealism" and Camus's idea of "the absurd."  In the end, everything we believe we cannot prove.  I think I'll go read that book as soon as I finish this outline.  I can get it via the Kindle app on my iPhone.<br><br>Okay I finished it for now.  The later parts are much more drafty than the earlier parts.  Maybe I'll come back later and work it out a little more.  It's kind of including a lot; maybe too much.<br><br><br>0. Fundamental unknowability<br><span class="Apple-tab-span"> </span>a. From limitations of language and the inescapability of the human cognitive/descriptive system.<br><span class="Apple-tab-span"> </span>b. From the insolubility of the prime mover or ultimate cause problem.<br><span class="Apple-tab-span"> </span>c. From the generalization of (0.a) and (0.b), or, "The child asking 'why?' will not be satisfied."<br><br>1. Something exists (∃A)<br><span class="Apple-tab-span"> </span>a. I think, therefore something is going on, but I can't really say more.  I feel like I'm here.<br><span class="Apple-tab-span"> </span>b. (0) holds by (0.a).<br><span class="Apple-tab-span"> </span>c. No claims on A, or, the inclusiveness of A.<br><br>2. Contingent belief; "If it is, it is." (A➞A)<br><span class="Apple-tab-span"> </span>a. A kind of pragmatics for functioning.<br><span class="Apple-tab-span"> </span>b. Imperfect alignment with science. (Maybe?)<br><span class="Apple-tab-span"> </span>c. (1.c) holds.<br><br>3. Belief does not affect A<br><span class="Apple-tab-span"> </span>a. Belief can affect perception.<br><span class="Apple-tab-span"> </span>b. Belief can affect behavior.<br><br>4. Free Will is a vacant concept, or, No Free Will but you won't miss it<br><span class="Apple-tab-span"> </span>a. Shown<br><span class="Apple-tab-span">  </span>i. From completeness of personal history and coin-flipping.<br><span class="Apple-tab-span">  </span>ii. From belief in scientific determinism. (bad argument)<br><span class="Apple-tab-span">  </span>iii. From belief in an omniscient being or beings. (bad argument)<br><span class="Apple-tab-span"> </span>b. Consequences<br><span class="Apple-tab-span">  </span>i. Everyone does exactly what they will.<br><span class="Apple-tab-span">  </span>ii. Does not imply no rewards, no punishment, or no ethics.<br><br>5. Might as well believe in other minds<br><span class="Apple-tab-span"> </span>a. Shaky grounds, but seems like there's no harm.<br><span class="Apple-tab-span"> </span>b. Clones and robots too.<br><span class="Apple-tab-span"> </span>c. Whether by degrees or with a jump at language or both.<br><br>6. Culture is socially constructed<br><span class="Apple-tab-span"> </span>a. Cultural relativism is correct in some respects.<br><span class="Apple-tab-span"> </span>b. Cultural relativism is fundamentally incorrect and humanity should and may move toward a "global modern" culture that is unified by a set of beliefs that happen to be these.<br><br>7. No deities<br><span class="Apple-tab-span"> </span>a. Harmful effects as in the slave religions (Judaism, Christianity, Islam).<br><span class="Apple-tab-span"> </span>b. Harmful effects even in religions that appear to have non-slave aspects (Buddhism, Islam, etc.).<br><br>8. Death is the end<br><br>9. Value, values and ethics arise socially, as (6)<br><span class="Apple-tab-span"> </span>a. Human life has no "intrinsic" value, by (9) etc.<br><span class="Apple-tab-span"> </span>b. Humans should be valued as members of their community, and the appropriate community for this consideration is the global community of all humans.<br><span class="Apple-tab-span">  </span>i. Abortion is good but can be problematic in practice.<br><span class="Apple-tab-span">  </span>ii. The death penalty could be good but is wildly problematic in practice.<br><span class="Apple-tab-span">  </span>iii. Euthanasia is good but can be problematic in practice.<br><span class="Apple-tab-span">  </span>iv. Suicide could be good or bad depending on how selfish surrounding people are.  As attitudes about it mature it will get better.<br><br>10. Science as modeling<br><span class="Apple-tab-span"> </span>a. Appropriate understanding of scientific "truth" re: (2).<br><span class="Apple-tab-span">  </span>i. Scientific statements are not "true" in the same sense that true statements about A would be, assuming they were possible.<br><span class="Apple-tab-span"> </span>b. Not quite "model-dependent realism" as in Hawking.  (Does this need its own point?)<br><br>11. Language<br><span class="Apple-tab-span"> </span>a. The most appropriate locus for understanding language is not a whole language but an individual.<br><span class="Apple-tab-span"> </span>b. Language operates as a kind of operating software over the hardware of the brain; falseness of strong Sapir-Worf hypothesis.<br><span class="Apple-tab-span"> </span>c. Humans will tend toward a single language.<br><br>12. Education<br>Okay I think I'll stop here for now and work on the education bit separately for a while.<br><br><br>Notes and thoughts:<br><br>General ideas that come out of this thinking:<br>Generalizing leads to misunderstanding.<br>Haha, unintentional joke?<br><br>(9.b) is a big problem.  I think I believe it, but I can't come up with a strong justification for universal inclusion.  It seems TOO axiomatic.  Should it include human-equivalent machines?  Near-human animals?  Should it include all of A?  Hmm.  Where is equality in this?  Should it be included because of negative consequences of NOT including it?</p>

<p><em>This post was originally hosted <a href="http://planspace.blogspot.com/2011/02/outline-of-philosophy.html">elsewhere</a>.</em></p>    </article>
    <footer>
      <hr />
<p><a name="contact"></a><form class="email_updates">
  <input type="email" name="email" placeholder="your@email.address" style="width: 49%" />
  <input type="submit" value="Get email updates" style="width: 49%" />
  <input type="hidden" name="_subject" value="planspace.org updates list" />
  <input type="text" name="_honey" style="display:none" />
  <input type="hidden" name="_captcha" value="false" />
</form></p>
<p><a id="back_link2" href="/">This site</a> also has <a href="/rss.xml">RSS</a>. You can connect with <a id="aaron_link2" href="/aaron/">me</a> via <a href="https://twitter.com/planarrowspace">Twitter</a>, <a href="https://www.linkedin.com/in/ajschumacher">LinkedIn</a>, <a href="https://github.com/ajschumacher">GitHub</a>, and <a href="mailto:aaron@planspace.org">email</a>.</p>

      <hr />
    </footer>

<!-- my weird stuff -->
<script src="/scripts/planspace.js"></script>

<!-- syntax highlighting -->
<script src="/scripts/highlight.pack.js"></script>
<script type="text/javascript">hljs.initHighlightingOnLoad();</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-44351009-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Disqus comments -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'planspace';
  (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  </body>
</html>
