<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/styles/csshake.min.css">
    <link rel="stylesheet" type="text/css" href="/styles/zenburn.css">
    <link rel="stylesheet" type="text/css" href="/styles/planspace.css">
    <title>The Scout Mindset, by Galef</title>
  </head>
  <body>
    <article>
<h1>The Scout Mindset, by Galef</h1>
<p class="date">Sunday May  2, 2021</p>
<p>The metaphor is soldier vs. scout. The advice is broadly good. With no
real discussion of epistemology but an implicit (roughly positivist?)
assumed worldview, I felt interesting foundational discussion was
elided. There was also little directly on “hard” (not yet known or
unknowable) questions. My critique is principally that I wanted more.</p>
<ul>
<li><a href="#more">Quotes and notes</a></li>
<li><a href="#outline">Slightly expanded table of contents</a></li>
</ul>
<p><img alt="cover" src="cover.jpg" /></p>
<hr />
<h3><a name="more" href="#more">Quotes and notes</a></h3>
<hr />
<blockquote>
<p>"our judgment isn’t limited by knowledge nearly as much as it’s
limited by attitude." (page x)</p>
</blockquote>
<hr />
<blockquote>
<p>"In “Persuasion,” we saw that law students who are randomly assigned
to one side of a moot court case become confident, after reading the
case materials, that their side is morally and legally in the right.
But that confidence doesn’t help them persuade the judge. On the
contrary, law students who are more confident in the merits of their
own side are significantly <em>less</em> likely to win the case—perhaps
because they fail to consider and prepare for the rebuttals to their
arguments." (page 27)</p>
</blockquote>
<p>This cites <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/667711?journalCode=jls">Eigen and Listokin</a>, and I don’t have access or
inclination to read the paper just now, but it seems like there’s a
claim here like “confidence causes bad performance” and I wonder
whether possible confounds have been considered. To me, “lower quality
lawyer causes both confidence and bad performance” seems plausible.</p>
<hr />
<blockquote>
<p>"Having an accurate map doesn’t help you very much when you’re
allowed to travel only one path." (page 40)</p>
</blockquote>
<hr />
<p>Page 45 starts an exploration of Kahan’s famous paper on
<a href="https://www.nature.com/articles/nclimate1547" title="The polarizing impact of science literacy and numeracy on perceived climate change risks">scientific polarization increasing with education</a>. Perhaps in an
effort to avoid alienating any readers, the tools of the scout are not
applied to settle the question of whether global warming is real. The
opportunity to engage one way or another with the idea of
<a href="https://en.wikipedia.org/wiki/Na%C3%AFve_realism_(psychology)" title="Naïve realism">naive realism</a> is not taken.</p>
<p>In Harford’s <a href="https://planspace.org/20210330-how_to_make_the_world_add_up_by_harford/#golden">treatment</a> of Kahan, I really appreciated the emphasis
on <em>curiosity</em> being essential for “scout-like” thinking.</p>
<hr />
<p>I think I hadn’t seen the idea of Blind Data Analysis mentioned on
page 55, citing <a href="https://www.nature.com/news/how-scientists-fool-themselves-and-how-they-can-stop-1.18517">Nuzzo</a>. Nice! Will keep this in mind.</p>
<hr />
<blockquote>
<p>"It [being critical of a study with undesirable results] prompted me
to go back through the studies I had been planning to cite in my
favor, and scrutinize their methodology for flaws, just as I had
done with the pro-soldier mindset study. (Sadly, this ended up
disqualifying most of them.)" (page 68)</p>
</blockquote>
<p>I’m not sure to what extent this is a joke; I thought it was funny as
I read it. But seriously, I wish people generally would <a href="https://www.paperswithoutcode.com/">say more</a>
about determinations such as this.</p>
<hr />
<p>I might be a soldier on this, but I don’t love quantifying uncertainty
in the manner of the calibration game introduced starting on page 75.
I thought a little bit about why.</p>
<ul>
<li>For simple matters of fact, uncertainty is ignorance. It just isn’t
   that interesting, or useful. You can go check and get 100% (or
   close) confidence.</li>
<li>For predictions about the future, there are interesting questions
   about what confidence means (is the universe deterministic? what is
   knowable?) and I think there’s no way to know whether your
   prediction <em>at a given time</em> is calibrated. The advice is to update
   your estimate over time, after all. If I say event <em>x</em> (to be
   evaluated in a week) is 20% likely today but 10% likely tomorrow,
   was I "right" at those respective times? Did the probability
   change, or just my estimate? Is there such a thing as "correct
   probability given what you know," likely different from true
   probability?</li>
<li>For difficult propositions, there is no oracle; you can’t
   calibrate. Worse, consensus can change over time. When it was
   consensus, what confidence in <a href="https://en.wikipedia.org/wiki/Aether_(classical_element)">aether</a> would have been
   appropriate? How confident should you be in a research result
   before it comes out that an error in analysis invalidates it? How
   confident should you be in a value judgment?</li>
<li>If we’re serious about quantifying confidence, shouldn’t we also
   estimate confidence in our confidence? Like: I’m 60% confident,
   plus or minus 10pp. This seems necessary, to allow for things like
   mistaken beliefs about current evidence. It also seems silly.</li>
</ul>
<p>I’m not sure I have any really coherent argument here. I agree with
the general idea of being aware of how sure you are. Somehow I don’t
like the exercise of writing down numbers for it.</p>
<p>There is an interesting topic of decision-making in the face of low
confidence. What do you do when you know you’re not sure? (Ramble,
seems to be my answer.) Maybe out of scope for the book.</p>
<hr />
<blockquote>
<p>"The reality is that there’s no clear divide between the
“decision-making” and “execution” stages of pursuing a goal. Over
time, your situation will change, or you’ll learn new information,
and you’ll need to revise your estimate of the odds." (page 110)</p>
</blockquote>
<p>I really agree with this. Planning can be valuable, but following the
plan to the letter is often not.</p>
<hr />
<p>Galef discusses low (10%, 30%) early estimates of “success” from Musk
and Bezos (starting page 111). Exploring why they would take such
chances, she mentions both expected value (10% of huge is still big)
and the idea that even “failure” would be fairly positive. I think
expected value is almost always the wrong way to think about
significant choices (especially one-shot choices with unclear odds)
and I don’t really believe it’s how people tend to think (or should).
I think the question of whether something is
<a href="/20181204-worth_doing_even_if_it_fails/">worth doing, even if it fails</a> is the right question. So I think
the balance of emphasis is off here. Expected value is a simple tool,
a hammer that people reach for <a href="/2012/06/04/expected-value-is-not-useful-for-making/">too often</a>, simplifying problems too
far. I wouldn’t even mention it in this setting.</p>
<hr />
<blockquote>
<p>"You might think these principles sound obvious and that you know
them already. But “knowing” a principle, in the sense that you read
it and say, “Yes, I know that,” is different from having
internalized it in a way that actually changes how you think." (page
144)</p>
</blockquote>
<hr />
<blockquote>
<p>"In his book <em>Sources of Power</em>, decision researcher Gary Klein
cites this [explaining away signs of a problem] as one of the top
three causes of bad decisions. He calls it a “de minimus error,” an
attempt to minimize the inconsistency between observations and
theory. Each new piece of evidence that doesn’t fit a doctor’s
medical diagnosis can be explained away or dismissed as a fluke, so
the doctor never realizes her initial diagnosis was wrong." (page
165)</p>
</blockquote>
<hr />
<p><a href="https://www.pnas.org/content/115/37/9216">Exposure to opposing views on social media can increase political polarization</a> cited in chapter 12.</p>
<hr />
<p><a href="http://www.paulgraham.com/identity.html">Keep your identity small</a> cited in chapter 14.</p>
<hr />
<blockquote>
<p>"They [a group of citizen scientists] also dove into the politics of
government research, familiarizing themselves with how funding was
structured and how the drug trials were conducted. The
disorganization they discovered alarmed them. “It sort of felt like
reaching the Wizard of Oz,” said one activist named Mark Harrington.
“You’ve gotten to the center of the whole system and there’s just
this schmuck behind a curtain.”" (page 212)</p>
</blockquote>
<p>Cites <a href="https://www.penguinrandomhouse.com/books/209900/how-to-survive-a-plague-by-david-france/">How to Survive a Plague</a>.</p>
<hr />
<h3><a name="outline" href="#outline">Slightly expanded table of contents</a></h3>
<ul>
<li>Introduction<ul>
<li>Realize that truth isn't in conflict with your other goals</li>
<li>Learn tools that make it easier to see clearly</li>
<li>Appreciate the emotional rewards of scout mindset</li>
</ul>
</li>
<li>Part 1: The case for scout mindset<ul>
<li>Chapter 1: Two types of thinking<ul>
<li>“Can I believe it?” vs. “Must I believe it?”</li>
</ul>
</li>
<li>Chapter 2: What the soldier is protecting</li>
<li>Chapter 3: Why truth is more valuable than we realize</li>
</ul>
</li>
<li>Part 2: Developing self-awareness<ul>
<li>Chapter 4: Signs of a scout<ul>
<li>Do you tell other people when you realize they were right?</li>
<li>How do you react to personal criticism?</li>
<li>Do you ever prove yourself wrong?</li>
<li>Do you take precautions to avoid fooling yourself?</li>
<li>Do you have any good critics?</li>
<li>Can you point to occasions in which you were in soldier
   mindset?</li>
</ul>
</li>
<li>Chapter 5: Noticing bias<ul>
<li>The double standard test</li>
<li>The outsider test</li>
<li>The conformity test</li>
<li>The selective skeptic test</li>
<li>The status quo bias test</li>
<li>Core skill: "a sense that your judgments are
   <em>contingent</em>—that what seems true or reasonable or fair or
   desirable can change when you mentally vary some feature of
   the question that should have been irrelevant." (page 87)</li>
</ul>
</li>
<li>Chapter 6: How sure are you?<ul>
<li>Core skill: "being able to tell the difference between the
   feeling of <em>making a claim</em> and the feeling of <em>actually
   trying to guess what's true</em>." (page 87)</li>
</ul>
</li>
</ul>
</li>
<li>Part 3: Thriving without illusion<ul>
<li>Chapter 7: Coping with reality</li>
<li>Chapter 8: Motivation without self-deception</li>
<li>Chapter 9: Influence without overconfidence</li>
</ul>
</li>
<li>Part 4: Changing your mind<ul>
<li>Chapter 10: How to be wrong</li>
<li>Chapter 11: Lean in to confusion</li>
<li>Chapter 12: Escape your echo chamber</li>
</ul>
</li>
<li>Part 5: Rethinking identity<ul>
<li>Chapter 13: How beliefs become identities</li>
<li>Chapter 14: Hold your identity lightly</li>
<li>Chapter 15: A scout identity</li>
</ul>
</li>
</ul>
<!-- https://twitter.com/planarrowspace/status/1388919415660548102 -->    </article>
    <footer>
      <hr />
<p><a name="contact"></a><form class="email_updates">
  <input type="email" name="email" placeholder="your@email.address" style="width: 49%" />
  <input type="submit" value="Get email updates" style="width: 49%" />
  <input type="hidden" name="_subject" value="planspace.org updates list" />
  <input type="text" name="_honey" style="display:none" />
  <input type="hidden" name="_captcha" value="false" />
</form></p>
<p><a id="back_link2" href="/">This site</a> also has <a href="/rss.xml">RSS</a>. You can connect with <a id="aaron_link2" href="/aaron/">me</a> via <a href="https://twitter.com/planarrowspace">Twitter</a>, <a href="https://www.linkedin.com/in/ajschumacher">LinkedIn</a>, <a href="https://github.com/ajschumacher">GitHub</a>, and <a href="mailto:aaron@planspace.org">email</a>.</p>

      <hr />
    </footer>

<!-- my weird stuff -->
<script src="/scripts/planspace.js"></script>

<!-- syntax highlighting -->
<script src="/scripts/highlight.pack.js"></script>
<script type="text/javascript">hljs.initHighlightingOnLoad();</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-44351009-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Disqus comments -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'planspace';
  (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  </body>
</html>
