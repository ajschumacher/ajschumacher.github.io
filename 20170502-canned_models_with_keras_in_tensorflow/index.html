<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/styles/csshake.min.css">
    <link rel="stylesheet" type="text/css" href="/styles/zenburn.css">
    <link rel="stylesheet" type="text/css" href="/styles/planspace.css">
    <title>Pre-trained Models with Keras in TensorFlow</title>
  </head>
  <body>
    <article>
<h1>Pre-trained Models with Keras in TensorFlow</h1>
<p class="date">Tuesday May  2, 2017</p>
<p>With TensorFlow 1.1, <a href="https://github.com/fchollet/keras">Keras</a> is now at <code>tf.contrib.keras</code>. With TensorFlow 1.3, it should be at <code>tf.keras</code>. This is great for making new models, but we also get the pre-trained models of <a href="https://github.com/fchollet/keras/tree/master/keras/applications"><code>keras.applications</code></a> (<a href="https://github.com/fchollet/deep-learning-models">also seen elsewhere</a>). It's so easy to classify images!</p>
<pre><code class="language-python">import tensorflow as tf

model = tf.contrib.keras.applications.ResNet50()</code></pre>

<p>This will automatically download trained weights for a model based on <a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>. The weights are cached below your home directory, in <code>~/.keras/models/</code>.</p>
<p>Convenient image tools are also included. Let's use an <a href="https://github.com/ajschumacher/imagen/blob/master/imagen/n01882714_4157_koala_bear.jpg">image</a> of a koala from the <a href="https://github.com/ajschumacher/imagen">imagen</a> ImageNet subset.</p>
<p><img alt="original koala" src="n01882714_4157_koala_bear.jpg" /></p>
<pre><code class="language-python">filename = 'n01882714_4157_koala_bear.jpg'
image = tf.contrib.keras.preprocessing.image.load_img(
    filename, target_size=(224, 224))</code></pre>

<p>This model can take input images that are 224 pixels on a side, so we have to make our image that size. We're just doing it by squishing, in this case.</p>
<p><img alt="smaller koala" src="smaller_koala.jpg" /></p>
<p>We'll make that into an array that the model can take as input.</p>
<pre><code class="language-python">import numpy as np

array = tf.contrib.keras.preprocessing.image.img_to_array(image)
array = np.expand_dims(array, axis=0)</code></pre>

<p>Now we can classify the image!</p>
<pre><code class="language-python">probabilities = model.predict(array)</code></pre>

<p>We have one thousand probabilities, one for each class the model knows about. To interpret the result, we can use another helpful function.</p>
<pre><code class="language-python">tf.contrib.keras.applications.resnet50.decode_predictions(probabilities)
## [[(u'n01882714', u'koala', 0.99466419),
##   (u'n02497673', u'Madagascar_cat', 0.0013330306),
##   (u'n01877812', u'wallaby', 0.00085774728),
##   (u'n02137549', u'mongoose', 0.00063530984),
##   (u'n02123045', u'tabby', 0.00056512095)]]</code></pre>

<p>Great success! The model is highly confident that it's looking at a koala. Not bad.</p>
<p>It's pretty fun that this kind of super-easy access to quite good pre-trained models is now available all within the TensorFlow package. Just <code>pip install</code> and go!</p>
<hr />
<p>The thousand ImageNet categories this model knows about include some things that are commonly associated with people, but not a "person" class. Still, just for fun, what will <code>ResNet50</code> say about me?</p>
<pre><code class="language-python">## [[(u'n02883205', u'bow_tie', 0.3144455),
##   (u'n03787032', u'mortarboard', 0.059674311),
##   (u'n02992529', u'cellular_telephone', 0.049916871),
##   (u'n04357314', u'sunscreen', 0.048197504),
##   (u'n04350905', u'suit', 0.03481029)]]</code></pre>

<p>I guess I'll take it?</p>
<p><img alt="Aaron" src="aaron.jpg" /></p>
<hr />
<p><strong>Notes:</strong></p>
<p>The model may have been trained on the very koala picture we're testing it with. I'm okay with that. Feel free to test your own koala pictures!</p>
<p>There's also another function, <code>resnet50.preprocess_input</code>, which in theory should help the model work better, but my tests gave seemingly worse results when using that pre-processing. It would be used like this:</p>
<pre><code class="language-python">array = tf.contrib.keras.applications.resnet50.preprocess_input(array)</code></pre>

<p>Keras in TensorFlow also contains <code>vgg16</code>, <code>vgg19</code>, <code>inception_v3</code>, and <code>xception</code> models as well, along the same lines as <code>resnet50</code>.</p>
<hr />
<p>I'm working on <a href="http://conferences.oreilly.com/oscon/oscon-tx/public/schedule/detail/57823">Building TensorFlow systems from components</a>, a workshop at <a href="https://conferences.oreilly.com/oscon/oscon-tx">OSCON 2017</a>.</p>    </article>
    <footer>
      <hr />
<p>If you sign up, I'll send you an email update at most monthly with new stuff.</p>
<iframe src="https://planspace.substack.com/embed" width="100%" frameborder="0" scrolling="no"></iframe>
<p><a id="back_link2" href="/">This site</a> also has <a href="/rss.xml">RSS</a>. You can connect with <a id="aaron_link2" href="/aaron/">me</a> via <a href="https://twitter.com/planarrowspace">Twitter</a>, <a href="https://www.linkedin.com/in/ajschumacher">LinkedIn</a>, <a href="https://github.com/ajschumacher">GitHub</a>, and <a href="mailto:aaron@planspace.org">email</a>.</p>

      <hr />
    </footer>

<!-- my weird stuff -->
<script src="/scripts/planspace.js"></script>

<!-- syntax highlighting -->
<script src="/scripts/highlight.pack.js"></script>
<script type="text/javascript">hljs.initHighlightingOnLoad();</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-EZBQMHT77F"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-EZBQMHT77F');
</script>

<!-- Disqus comments -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'planspace';
  (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  </body>
</html>
