<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="/styles/csshake.min.css">
    <link rel="stylesheet" type="text/css" href="/styles/zenburn.css">
    <link rel="stylesheet" type="text/css" href="/styles/planspace.css">
    <title>Images and TFRecords</title>
  </head>
  <body>
    <article>
<h1>Images and TFRecords</h1>
<p class="date">Monday April  3, 2017</p>
<p>There are a number of ways to work with images in TensorFlow and, if you wish, with TFRecords. These methods aren't so mysterious if you <a href="/20170323-tfrecords_for_humans/">understand TFRecords</a> and a little bit about how digital images work.</p>
<hr />
<h2>Representations for Images</h2>
<!--

(I kind of like this paragraph, at least in that it gives credit for the image source, but it's not really key to the development here.)

Wikipedia [tells me](https://en.wikipedia.org/wiki/Keep_Calm_and_Carry_On) that this [poster](https://commons.wikimedia.org/wiki/File:Freedom_Is_In_Peril_Defend_It_With_All_Your_Might.svg), and the more widely known "Keep Calm and Carry On," were not very well received [in 1939](img/freedom_in_tube.jpg). Perhaps its time has come.

-->

<p>For example, this image is 600 pixels tall and 400 pixels wide. Every pixel has some intensity in red, green, and blue: three values, or channels, for every pixel. This image has shape [600, 400, 3]. (The order of the dimensions doesn't matter as long as everybody agrees on the convention.) The display on your screen is like a dense matrix; it is a <a href="https://en.wikipedia.org/wiki/Raster_graphics">raster graphic</a>.</p>
<p><img alt="FREEDOM IS IN PERIL / DEFEND IT WITH ALL YOUR MIGHT" src="img/freedom.png" /></p>
<p>Neural networks that work with images typically work with this kind of dense matrix representation. For this image, the matrix will have 600 * 400 * 3 = 720,000 values. If each value is an unsigned 8-bit integer, that's 720,000 bytes, or about three quarters of a megabyte.</p>
<p>Images sometimes also have an alpha transparency channel, which is a fourth channel in a color image, but not necessary if there's nothing else "underneath" the image. And not all images are color; greyscale (black and white) images can have just one channel.</p>
<p>Using unsigned 8-bit integers (256 possible values) for each value in the image array is enough for displaying images to humans. But when working with image data, it isn't uncommon to switch to 32-bit floats, for example. This quadruples the size of the data in memory. As always, remain aware of your data types.</p>
<h3>Dense Array</h3>
<p>One way to store complete raster image data is by serializing a NumPy array to disk with <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html"><code>numpy.save</code></a>.</p>
<pre>720,080 bytes  <a href="img/freedom.npy">freedom.npy</a></pre>

<p>The file <code>freedom.npy</code> has 80 more bytes than the ones required to store the array values. Those extra bytes specify things like the dimensions of the array. If we save raw array values in TFRecords, we'll also have to keep track of this additional information.</p>
<p>Because storing one or more value for every pixel takes so many bytes, file formats for images typically do something cleverer.</p>
<h3>JPEG</h3>
<p><a href="https://en.wikipedia.org/wiki/JPEG">JPEG</a> is lossy. When you save an array as JPG and then read from the JPG, it will generally look about the same, but you won't necessarily get back exactly the same values for your array. JPEG is like <a href="https://en.wikipedia.org/wiki/MP3">MP3</a> for images. JPEG is good for photographs.</p>
<pre> 25,136 bytes  <a href="img/freedom.jpg">freedom.jpg</a></pre>

<p><code>freedom.jpg</code> is less than 4% the size of the NumPy array, and it still looks pretty good. It does have some ringing artifacts around the letter edges. JPEG file size depends on compression parameters when saving, and on the encoder used. For example, Google <a href="https://research.googleblog.com/2017/03/announcing-guetzli-new-open-source-jpeg.html">released</a> their <a href="https://github.com/google/guetzli/">Guetzli</a> JPEG encoder, which can produce smaller files but takes more computation to do so.</p>
<pre> 46,567 bytes  <a href="img/freedom2.jpg">freedom2.jpg</a></pre>

<p><code>freedom2.jpg</code> is another JPEG file, saved with higher quality. Ringing artifacts are pretty much gone. The file is still under 7% the size of the NumPy arrray.</p>
<h3>PNG</h3>
<p><a href="https://en.wikipedia.org/wiki/Portable_Network_Graphics">PNG</a> is lossless. If you save as PNG and then read from the PNG, you can get back exactly what you had originally. PNG is like <a href="https://en.wikipedia.org/wiki/Zip_(file_format)">ZIP</a> for images, but image viewers do the "un-zipping" automatically so they can put a raster image on the screen. PNG is like <a href="https://en.wikipedia.org/wiki/GIF">GIF</a> without animation.</p>
<pre> 33,192 bytes  <a href="img/freedom.png">freedom.png</a></pre>

<p><code>freedom.png</code> is under 5% the size of the NumPy array, and it preserves the image perfectly. It's less often used, but compression parameters can also affect PNG size, and the encoder can make a difference too. PNG uses deflate (zlip) compression, so Google's <a href="https://github.com/google/zopfli">Zopfli</a> algorithm can be used, for example, while <a href="https://github.com/google/brotli">Brotli</a> cannot.</p>
<h3>SVG</h3>
<p><a href="https://en.wikipedia.org/wiki/Scalable_Vector_Graphics">SVG</a> doesn't represent pixels directly at all, but represents in a text format the geometry of shapes in the image. SVG images can look good at any zoom level; they don't suffer from pixelization. They can also be edited with different tools than raster images. And for simple images, an SVG can be quite small. SVG is like <a href="https://en.wikipedia.org/wiki/HTML">HTML</a>; you can look at it as text, but to see it as intended requires a program like a web browser.</p>
<pre> 42,721 bytes  <a href="img/freedom.svg">freedom.svg</a></pre>

<p><code>freedom.svg</code> turns out not be a super efficient encoding of the image; it represents all the letter outlines instead of using plain text in some font, for example. But it represents the image fundamentally differently from just recreating pixels, and it's still under 6% the size of the NumPy array file.</p>
<h3>TFRecords?</h3>
<p>TFRecords don't know anything about image formats. You just put bytes in them. So you have your choice of whether that means you store dense arrays of values or a well-known image format. TensorFlow provides <a href="https://www.tensorflow.org/api_guides/python/image">image format support</a> for JPEG, PNG, and GIF in the computation graph.</p>
<hr />
<h2>Images without TensorFlow</h2>
<p>As always, <a href="/20170312-use_only_what_you_need_from_tensorflow/">you have a choice about whether you need to do everything with TensorFlow</a>. If you're loading data batches with a <code>feed_dict</code>, in particular, feel free to use whatever Python functionality you're comfortable with. Even if you're not, you'll probably want to do some work with your data outside of TensorFlow before you move all your computation into the graph.</p>
<p>The Matplotlib <a href="http://matplotlib.org/users/image_tutorial.html">image tutorial</a> recommends using <a href="http://matplotlib.org/api/image_api.html#matplotlib.image.imread"><code>matplotlib.image.imread</code></a> to read image formats from disk. This function will automatically change image array values to floats between zero and one, and it doesn't give you options about how to read the image.</p>
<p>The <a href="https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.misc.imread.html">scipy.misc.imread</a> function uses the Python Imaging Library (PIL) to support many image formats, including PNG and JPEG. This function also has some useful options. The original <code>freedom.png</code> has an alpha channel which we don't need. Passing <code>mode='RGB'</code> tells the reader to give us just three color channels.</p>
<pre><code class="language-python">>>> import scipy.misc
>>> image = scipy.misc.imread('freedom.png', mode='RGB')
>>> type(image)
## numpy.ndarray
>>> image.shape
## (600, 400, 3)
>>> image.dtype
## dtype('uint8')</code></pre>

<p>Matplotlib's <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.imshow">imshow</a> is good for checking out what image arrays look like. (Also specify <code>%matplotlib inline</code> if you're in a notebook.)</p>
<pre><code class="language-python">>>> import matplotlib.pyplot as plt
>>> plt.imshow(image)</code></pre>

<p>NumPy gives us a way to save and load its arrays.</p>
<pre><code class="language-python">>>> import numpy as np
>>> np.save('freedom.npy', image)
>>> same_image = np.load('freedom.npy')</code></pre>

<p>As long as we have <code>scipy.misc</code> imported, we can use <a href="https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.misc.imsave.html">scipy.misc.imsave</a> to write various image formats as well. For saving, <a href="http://matplotlib.org/api/image_api.html#matplotlib.image.imsave">matplotlib.image.imsave</a> actually has more options. Neither of these offer control over compression level, for example.</p>
<pre><code class="language-python">>>> scipy.misc.imsave('freedom.jpg', image)</code></pre>

<hr />
<h2>PNG and JPEG with TensorFlow</h2>
<p>TensorFlow has ops for decoding and encoding PNGs and JPEGs, so we can put these operations into the computation graph.</p>
<p>Above, <code>imread</code> both read a file from disk and decoded it, and <code>imsave</code> both encoded an image and wrote it to disk. The TensorFlow functionality decouples the decoding and encoding from file reading and writing. This example will avoid using TensorFlow's file reading and writing, to focus just on the encoding and decoding.</p>
<p>The <code>channels=3</code> passed to <code>tf.image.decode_image()</code> is the equivalent of <code>mode='RGB'</code> above. We don't want to get the alpha channel from the PNG file.</p>
<pre><code class="language-python">>>> import tensorflow as tf
>>> with open('freedom.png', 'rb') as f:
...     png_bytes = f.read()
>>> bytes = tf.placeholder(tf.string)
>>> decode_png = tf.image.decode_image(bytes, channels=3)
>>> session = tf.Session()
>>> image = session.run(decode_png, feed_dict={bytes: png_bytes})
>>> type(image)
## numpy.ndarray
>>> image.shape
## (600, 400, 3)
>>> image.dtype
## dtype('uint8')</code></pre>

<p>The <a href="https://www.tensorflow.org/api_docs/python/tf/image/decode_image"><code>tf.image.decode_image</code></a> here intelligently uses <a href="https://www.tensorflow.org/api_docs/python/tf/image/decode_png"><code>tf.image.decode_png</code></a>, <a href="https://www.tensorflow.org/api_docs/python/tf/image/decode_jpeg"><code>tf.image.decode_jpeg</code></a>, or <a href="https://www.tensorflow.org/api_docs/python/tf/image/decode_gif"><code>tf.image.decode_gif</code></a>, similar to how above <code>imread</code> can handle a variety of formats. You can also use the appropriate function directly.</p>
<p>Above, <code>imsave</code> supported writing various formats, choosing the one appropriate for the filename specified. In TensorFlow, you have to use <a href="https://www.tensorflow.org/api_docs/python/tf/image/encode_jpeg"><code>tf.image.encode_jpeg</code></a> or <a href="https://www.tensorflow.org/api_docs/python/tf/image/encode_png"><code>tf.image.encode_png</code></a> directly, and both provide extra arguments controlling compression and more.</p>
<pre><code class="language-python">>>> tensor = tf.placeholder(tf.uint8)
>>> encode_jpeg = tf.image.encode_jpeg(tensor)
>>> jpeg_bytes = session.run(encode_jpeg, feed_dict={tensor: image})
>>> with open('freedom.jpg', 'wb') as f:
...     f.write(jpeg_bytes)</code></pre>

<p>With the default settings, TensorFlow encodes a larger JPEG than <code>imsave</code>, coming in at 46,567 bytes. It looks pretty good.</p>
<hr />
<h2>PNG and JPEG in TFRecords</h2>
<p>We can put plain bytes into <code>Example</code> TFRecords <a href="/20170323-tfrecords_for_humans/">without too much trouble</a>. So PNG or JPEG images are easily handled.</p>
<pre><code class="language-python">my_example = tf.train.Example(features=tf.train.Features(feature={
    'png_bytes': tf.train.Feature(bytes_list=tf.train.BytesList(value=[png_bytes]))
}))

my_example_str = my_example.SerializeToString()
with tf.python_io.TFRecordWriter('my_example.tfrecords') as writer:
    writer.write(my_example_str)

reader = tf.python_io.tf_record_iterator('my_example.tfrecords')
those_examples = [tf.train.Example().FromString(example_str)
                  for example_str in reader]
same_example = those_examples[0]

same_png_bytes = same_example.features.feature['png_bytes'].bytes_list.value[0]</code></pre>

<p>When the <code>same_png_bytes</code> is decoded by <code>tf.image.decode_image</code>, as above, or <code>tf.image.decode_png</code> directly, you'll get back a tensor with the correct dimensions, because PNG (and JPEG) include that information in their encodings.</p>
<hr />
<h2>Image Arrays in TFRecords</h2>
<p>If you want to save dense matrix representations in TFRecords, there's a little bit of bookkeeping to do, but it isn't too bad.</p>
<pre><code>image_bytes = image.tostring()
image_shape = image.shape

my_example = tf.train.Example(features=tf.train.Features(feature={
    'image_bytes': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_bytes])),
    'image_shape': tf.train.Feature(int64_list=tf.train.Int64List(value=image_shape))
}))

my_example_str = my_example.SerializeToString()
with tf.python_io.TFRecordWriter('my_example.tfrecords') as writer:
    writer.write(my_example_str)

reader = tf.python_io.tf_record_iterator('my_example.tfrecords')
those_examples = [tf.train.Example().FromString(example_str)
                  for example_str in reader]
same_example = those_examples[0]

same_image_bytes = same_example.features.feature['image_bytes'].bytes_list.value[0]
same_image_shape = list(
    same_example.features.feature['image_shape'].int64_list.value)</code></pre>

<p>With the information recovered from TFRecord form, it's easy to use NumPy to put the image back together.</p>
<pre><code class="language-python">same_image = np.fromstring(same_image_bytes, dtype=np.uint8)
same_image.shape = same_image_shape</code></pre>

<p>You can do the same using TensorFlow.</p>
<pre><code class="language-python">shape = tf.placeholder(tf.int32)
new_image = tf.reshape(tf.decode_raw(bytes, tf.uint8), shape)
same_image = session.run(encode_jpeg, feed_dict={bytes: same_image_bytes,
                                                 shape: same_image_shape})</code></pre>

<!--

Note it really does have to be `tf.reshape`; `.set_shape` will not work. See:
http://stackoverflow.com/questions/35451948/clarification-on-tf-tensor-set-shape

-->

<p>In this example, however, the parsing of the <code>Example</code> was already done outside the TensorFlow graph, so there isn't a strong reason to stay inside the graph here.</p>
<hr />
<h3>Comparison to Caffe and LMDB</h3>
<p><a href="http://caffe.berkeleyvision.org/">Caffe</a> is an older deep learning framework that can work with data stored in <a href="https://symas.com/offerings/lightning-memory-mapped-database/">LMDB</a> on-disk databases, similar to how TensorFlow can work with data stored in TFRecords files.</p>
<p>Like TensorFlow, Caffe defines a protocol buffer message for training examples. In Caffe, it's called <code>Datum</code>. These are saved just like in TensorFlow, by serializing them and putting them in a file on disk, but instead of a TFRecords file, which just puts records in a row and reads them out in that order, here Caffe will work with LMDB, which has the semantics of a key-value store.</p>
<p>TensorFlow's <code>Example</code> format is super flexible, but the trade-off is that it doesn't automatically do things for you. Caffe's <code>Datum</code>, on the other hand, expects you to put in a dense image array, and an integer class label. So here there isn't any fiddling with array size, for example, but the trade-off is that it won't work easily for arbitrary data structures that we might eventually want to store.</p>
<p>In the TFRecords examples above, we stored only image data, and said nothing about a class label or anything else. This is because TFRecords lets you decide what you want to save, rather than defining a format in advance. You could save an integer label, or a float regression label, or a string of text, or an image mask, and on and on. Here, we're just using the built-in Caffe integer label.</p>
<pre><code class="language-python">import caffe
import lmdb

# `image` was read above
label = 9  # for a classification problem

datum = caffe.io.array_to_datum(arr=image, label=label)
datum_str = datum.SerializeToString()

env = lmdb.open('lmdb_data')
txn = env.begin(write=True)
txn.put(key='my datum', value=datum_str)

cur = txn.cursor()
same_datum_str = cur.get('my datum')

same_datum = caffe.proto.caffe_pb2.Datum().FromString(same_datum_str)
same_image = caffe.io.datum_to_array(same_datum)
same_label = datum.label</code></pre>

<p>To actually work with the Caffe training process, there are some other conditions for the data to satisfy. Caffe expects [channels, height, width] instead of [height, width, channels], for example.</p>
<hr />
<h2>What should you use?</h2>
<p>Prefer doing fewer separate manipulation steps to whatever your original data is, if you can help it: try not to have lots of different versions of your data in different places on disk. This will make your life easier.</p>
<p>If you are choosing a format, JPEG is good for photos.</p>
<p>Think about whether you need to put everything into the TensorFlow computation graph. Think about whether you need to use TFRecords. Try to spend your time on things that help solve your problems.</p>
<p>For two more complete <em>in situ</em> examples of converting images to TFRecords, check out <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py">code for MNIST images</a> and <a href="https://github.com/tensorflow/models/blob/master/research/inception/inception/data/build_imagenet_data.py">code for ImageNet images</a>. The ImageNet code can be run on the command-line.</p>
<hr />
<p>I'm working on <a href="http://conferences.oreilly.com/oscon/oscon-tx/public/schedule/detail/57823">Building TensorFlow systems from components</a>, a workshop at <a href="https://conferences.oreilly.com/oscon/oscon-tx">OSCON 2017</a>.</p>    </article>
    <footer>
      <hr />
      <ul>
        <li id="back_link">
          <a href="/">Plan <span class="rotate180">âž”</span> Space</a>
        </li>
        <li>
          <a id="edit_link" href="https://github.com/ajschumacher/ajschumacher.github.io">Edit</a> this page
        </li>
        <li>
          Find <a id="aaron_link" href="/aaron/">Aaron</a> on
          <ul>
            <li>
              <a href="https://twitter.com/planarrowspace">Twitter</a>
            </li>
            <li>
              <a href="https://www.linkedin.com/in/ajschumacher">LinkedIn</a>
            </li>
            <li>
              <a href="https://plus.google.com/112658546306232777448/">Google+</a>
            </li>
            <li>
              <a href="https://github.com/ajschumacher">GitHub</a>
            </li>
            <li>
              <a href="mailto:ajschumacher@gmail.com">email</a>
            </li>
          </ul>
        </li>
        <li>
          Comment below
        </li>
      </ul>
      <hr />
    </footer>

<!-- my weird stuff -->
<script src="/scripts/planspace.js"></script>

<!-- syntax highlighting -->
<script src="/scripts/highlight.pack.js"></script>
<script type="text/javascript">hljs.initHighlightingOnLoad();</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-44351009-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Disqus comments -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_shortname = 'planspace';
  (function() {
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

  </body>
</html>
